import os
import sys
import argparse
import numpy as np
import pandas as pd
import torch
from torch import nn
from torch import optim
import random
# Whatever other imports you need

# You can implement classes and helper functions here too.

class AuthorPredict(nn.Module):
    def __init__(self, input_size, output_size=1):
        super().__init__()
        self.linear = nn.Linear(input_size, output_size)
        self.sigmoid = nn.Sigmoid()
    def forward(self, x):
        m = self.linear(x)
        n = self.sigmoid(m)
        return n

class AuthorFFNN:
    def __init__(self, lr =0.01):
        self.lr = lr
    def train(self, inputs, samplesize): 
        self.model = AuthorPredict((inputs.shape[1]-2)*2)
        criterion = nn.BCELoss()
        optimizer = optim.SGD(self.model.parameters(), lr=self.lr)

        for i in range(samplesize):
            documents = inputs.drop(inputs.columns[[0,1]], axis=1)
            labels = inputs.iloc[:, 1:2]
            in1 = random.randint(0, len(documents))
            auth = labels.iloc[in1, 0]
            in_same = labels[labels.iloc[:, 0] == auth].index
            in_diff = labels[labels.iloc[:, 0] != auth].index
            coin = random.randint(0, 1)
            if coin == 0:
                in2 = random.choice(in_diff)
            if coin == 1:
                in2 = random.choice(in_same)
            docs = documents.to_numpy()
            doc1 = torch.Tensor(docs[in1])
            doc2 = torch.Tensor(docs[in2])
            instance = torch.cat((doc1, doc2), 0)
            output = self.model(instance)
            label = torch.Tensor([coin])
            loss = criterion(output, label)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            print("it does something")

    def predict(self, inputvec):
Last login: Wed Mar 25 11:09:26 on ttys000

The default interactive shell is now zsh.
To update your account to use zsh, please run `chsh -s /bin/zsh`.
For more details, please visit https://support.apple.com/kb/HT208050.
(base) Julias-MacBook:~ juliaklezl$ ssh -p 62266 gusklezju@mltgpu.flov.gu.se
gusklezju@mltgpu.flov.gu.se's password: 
----------------------------------------
Welcome to the host mltgpu.flov.gu.se
Fedora 30 (Server Edition)
----------------------------------------
Support:

 Robert Adesam, robert.adesam@gu.se
----------------------------------------

Last login: Wed Mar 25 11:09:37 2020 from 46.239.124.106
[gusklezju@GU.GU.SE@mltgpu ~]$ cd lt2212-v20-a3
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ ls
a3_features.py  a3_model.py  enron_sample  README.md
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_features.py enron_sample/ out.csv 200
Reading enron_sample/...
Constructing table with 200 feature dimensions and 20% test instances...
Writing to out.csv...
[['train' 'mccarty-d' '12.569811639968842' ... '1.0440038686736748'
  '0.4142330037533583' '-1.305084634792936']
 ['test' 'mccarty-d' '-8.443630687451487' ... '0.03682738970845072'
  '-0.0136484919403614' '-0.41503346206517994']
 ['test' 'mccarty-d' '-8.38608834923802' ... '0.27092513788638606'
  '0.3964084167586766' '0.24862596174794171']
 ...
 ['train' 'donohoe-t' '-8.855967319962641' ... '-0.00793042205748974'
  '0.12507452741557326' '0.0018554548025994544']
 ['train' 'donohoe-t' '-10.706339205098937' ... '-0.05454900546240792'
  '0.022302551282628893' '-0.04411911903199851']
 ['train' 'donohoe-t' '11.300004481561325' ... '-0.681582932290084'
  '-0.1740279542464459' '-0.13494612402092154']]
Done!
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ ls
a3_features.py  a3_model.py  enron_sample  out.csv  README.md
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
[            nan             nan  1.25698116e+01  7.11666956e+00
  6.72103640e-01  6.00301989e-01 -1.95300283e+00  1.57402432e+00
  2.10112093e+00  1.05639544e+00 -3.68143291e-01 -7.66938640e-02
 -3.47201412e-01  2.19217072e+00  3.03768669e+00  1.20829229e+00
  2.97056091e-01  1.88232334e+00  1.72073307e+00  5.98396894e-01
  2.05640877e+00 -1.63759440e+00 -1.31071539e+00  8.29151666e-01
  4.70058632e-01 -6.94242408e-01  4.04144871e+00  1.52655376e+00
  2.79597585e-01  4.09664641e-01  1.01628311e+00 -2.16110598e+00
  1.73057481e+00 -1.40840588e+00 -2.18088848e+00 -1.02311394e+00
  5.48262048e-01 -3.58579633e-01  2.68813702e+00  6.26226739e-01
  7.03678684e-01 -1.79018074e-01 -1.62419688e+00 -1.10306745e+00
 -7.45586428e-01  7.58321762e-01  6.21099459e-01  9.53821471e-01
 -1.66654737e+00  7.68012040e-01  5.98321415e-01  1.85879160e+00
 -5.97380385e-02 -2.41320972e-01 -2.35287234e-01 -1.34211977e+00
 -4.40365560e-01 -1.13199716e+00  7.02547774e-01 -1.00843030e+00
 -1.81009898e+00  3.21991124e-01  1.98125140e+00  3.28775797e-02
 -5.66995340e-01  6.79603608e-02  1.47498870e+00 -5.26284642e-01
 -1.89482831e+00 -5.16843008e-01  3.18243677e-01 -1.41914140e+00
  6.76416156e-02 -1.13033762e+00  1.47287754e+00  3.01199377e-01
  8.26659251e-01  1.28563257e-01 -4.38001427e-01  1.36733445e+00
  1.45051331e+00 -1.30808429e-01  7.77129098e-01  3.86267146e-02
 -9.13503332e-02 -8.31909984e-01 -2.19713103e+00  1.85374188e+00
  1.05325333e+00  6.08000450e-01  1.04858569e+00  4.98821621e-01
 -1.17644415e+00  5.12187682e-01  2.14841691e-01  2.15852608e+00
 -8.22573071e-01  1.55598431e+00  3.09459465e-02  1.12756933e+00
 -8.77001072e-01  1.22041968e+00  2.96314209e-01  2.52802809e-01
  1.32375167e+00  8.74138029e-01  2.04035973e-01  1.64185794e+00
  3.38611074e-01 -7.53998137e-01 -4.96025009e-02 -3.04644763e-01
 -1.00563987e+00  4.45255881e-01  3.79178840e-01  5.51933424e-02
 -1.10429305e-01  3.67404841e-01 -5.91241419e-01  1.49824263e+00
  1.96979914e+00 -3.42752428e-01  9.12755660e-01  8.51681234e-01
  2.95022768e-01  1.60294080e+00  5.27042862e-01 -7.57455483e-01
 -4.67219656e-01  3.53313046e-01  1.27867884e+00 -6.59526904e-01
  8.63993570e-01  1.39112994e-01 -2.04005467e-01  5.88970126e-01
  1.26039567e+00 -2.22832226e-01 -1.23242644e+00  2.21525993e+00
 -2.49174843e-01 -3.40855958e-01 -5.32572587e-01  2.78710676e-01
 -6.25027259e-01  1.49656541e+00 -7.38154734e-02  3.76849562e-02
  9.00247791e-02  2.24606037e-01 -1.19942960e+00 -3.33058590e+00
  7.24124258e-01  1.07712206e+00  2.98216208e-01 -6.79225619e-02
  5.59348964e-01  7.62962682e-01 -2.80903978e+00 -3.02815349e-01
  1.73014142e+00  1.38069629e-01  4.99274148e-01 -1.47033912e+00
  9.01132165e-01 -1.17928098e+00  7.09686552e-01  2.86712416e-01
  1.51810282e+00 -2.09618793e-01 -5.45075328e-01 -4.30761434e-01
 -7.41436508e-01  6.46796355e-01 -3.42094686e-01  6.20818135e-01
 -8.09459620e-01 -2.66751397e-01 -1.26316277e+00 -9.49234142e-01
 -1.39004962e+00  2.07062593e-01 -7.63808841e-01  1.83282474e+00
 -6.46380063e-01  7.88503675e-01 -1.94189696e-02 -7.23768725e-01
 -1.13963937e+00  1.08738000e+00  4.13491821e-02 -4.79839102e-03
  1.18496456e+00  2.11291126e-01 -4.59598280e-01 -4.67350408e-01
 -2.25917447e-01 -1.29655839e-01  6.90582041e-01  1.04400387e+00
  4.14233004e-01 -1.30508463e+00]
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:23: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
(b'train', b'mccarty-d', 12.56981164, 7.11666956, 0.67210364, 0.60030199, -1.95300283, 1.57402432, 2.10112093, 1.05639544, -0.36814329, -0.07669386, -0.34720141, 2.19217072, 3.03768669, 1.20829229, 0.29705609, 1.88232334, 1.72073307, 0.59839689, 2.05640877, -1.6375944, -1.31071539, 0.82915167, 0.47005863, -0.69424241, 4.04144871, 1.52655376, 0.27959758, 0.40966464, 1.01628311, -2.16110598, 1.73057481, -1.40840588, -2.18088848, -1.02311394, 0.54826205, -0.35857963, 2.68813702, 0.62622674, 0.70367868, -0.17901807, -1.62419688, -1.10306745, -0.74558643, 0.75832176, 0.62109946, 0.95382147, -1.66654737, 0.76801204, 0.59832142, 1.8587916, -0.05973804, -0.24132097, -0.23528723, -1.34211977, -0.44036556, -1.13199716, 0.70254777, -1.0084303, -1.81009898, 0.32199112, 1.9812514, 0.03287758, -0.56699534, 0.06796036, 1.4749887, -0.52628464, -1.89482831, -0.51684301, 0.31824368, -1.4191414, 0.06764162, -1.13033762, 1.47287754, 0.30119938, 0.82665925, 0.12856326, -0.43800143, 1.36733445, 1.45051331, -0.13080843, 0.7771291, 0.03862671, -0.09135033, -0.83190998, -2.19713103, 1.85374188, 1.05325333, 0.60800045, 1.04858569, 0.49882162, -1.17644415, 0.51218768, 0.21484169, 2.15852608, -0.82257307, 1.55598431, 0.03094595, 1.12756933, -0.87700107, 1.22041968, 0.29631421, 0.25280281, 1.32375167, 0.87413803, 0.20403597, 1.64185794, 0.33861107, -0.75399814, -0.0496025, -0.30464476, -1.00563987, 0.44525588, 0.37917884, 0.05519334, -0.11042931, 0.36740484, -0.59124142, 1.49824263, 1.96979914, -0.34275243, 0.91275566, 0.85168123, 0.29502277, 1.6029408, 0.52704286, -0.75745548, -0.46721966, 0.35331305, 1.27867884, -0.6595269, 0.86399357, 0.13911299, -0.20400547, 0.58897013, 1.26039567, -0.22283223, -1.23242644, 2.21525993, -0.24917484, -0.34085596, -0.53257259, 0.27871068, -0.62502726, 1.49656541, -0.07381547, 0.03768496, 0.09002478, 0.22460604, -1.1994296, -3.3305859, 0.72412426, 1.07712206, 0.29821621, -0.06792256, 0.55934896, 0.76296268, -2.80903978, -0.30281535, 1.73014142, 0.13806963, 0.49927415, -1.47033912, 0.90113216, -1.17928098, 0.70968655, 0.28671242, 1.51810282, -0.20961879, -0.54507533, -0.43076143, -0.74143651, 0.64679635, -0.34209469, 0.62081813, -0.80945962, -0.2667514, -1.26316277, -0.94923414, -1.39004962, 0.20706259, -0.76380884, 1.83282474, -0.64638006, 0.78850368, -0.01941897, -0.72376873, -1.13963937, 1.08738, 0.04134918, -0.00479839, 1.18496456, 0.21129113, -0.45959828, -0.46735041, -0.22591745, -0.12965584, 0.69058204, 1.04400387, 0.414233, -1.30508463)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
  File "a3_model.py", line 14
    def __init__(self, input_size, output_size=1)
                                                ^
SyntaxError: invalid syntax
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
  File "a3_model.py", line 26
    def make_model = (self, vector_size):
                   ^
SyntaxError: invalid syntax
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:45: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
Traceback (most recent call last):
  File "a3_model.py", line 47, in <module>
    AuthorFFNN.train(row)
TypeError: train() missing 1 required positional argument: 'inputs'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:46: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
Traceback (most recent call last):
  File "a3_model.py", line 48, in <module>
    AuthorFFNN.train(row)
TypeError: train() missing 1 required positional argument: 'inputs'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:46: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
Traceback (most recent call last):
  File "a3_model.py", line 48, in <module>
    AuthorFFNN.train(row)
  File "a3_model.py", line 29, in train
    self.inputs = inputs
NameError: name 'self' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:45: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
Traceback (most recent call last):
  File "a3_model.py", line 47, in <module>
    AuthorFFNN.train(row, row)
  File "a3_model.py", line 30, in train
    optimizer = optim.SGD(self.model.parameters(), lr=self.lr)
AttributeError: 'numpy.void' object has no attribute 'model'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:45: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
Traceback (most recent call last):
  File "a3_model.py", line 47, in <module>
    AuthorFFNN.train(row, row)
  File "a3_model.py", line 29, in train
    input = torch.Tensor([inputs])
ValueError: expected sequence of length 5 at dim 2 (got 9)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:45: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
Traceback (most recent call last):
  File "a3_model.py", line 47, in <module>
    AuthorFFNN.train(row, row)
  File "a3_model.py", line 29, in train
    input = torch.Tensor(inputs)
ValueError: expected sequence of length 5 at dim 1 (got 9)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:45: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
Traceback (most recent call last):
  File "a3_model.py", line 47, in <module>
    AuthorFFNN.train(row, row)
  File "a3_model.py", line 29, in train
    input = torch.LongTensor(inputs)
ValueError: expected sequence of length 5 at dim 1 (got 9)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:45: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
Traceback (most recent call last):
  File "a3_model.py", line 47, in <module>
    AuthorFFNN.train(row, row)
  File "a3_model.py", line 29, in train
    input = torch.LongTensor([inputs])
ValueError: expected sequence of length 5 at dim 2 (got 9)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:46: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
Traceback (most recent call last):
  File "a3_model.py", line 48, in <module>
    AuthorFFNN.train(row, row)
  File "a3_model.py", line 29, in train
    print(shape(inputs))
NameError: name 'shape' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:46: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
()
Traceback (most recent call last):
  File "a3_model.py", line 48, in <module>
    AuthorFFNN.train(row, row)
  File "a3_model.py", line 30, in train
    input = torch.LongTensor([inputs])
ValueError: expected sequence of length 5 at dim 2 (got 9)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:46: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
()
()
Traceback (most recent call last):
  File "a3_model.py", line 49, in <module>
    AuthorFFNN.train(row, row)
  File "a3_model.py", line 30, in train
    input = torch.LongTensor([inputs])
ValueError: expected sequence of length 5 at dim 2 (got 9)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:46: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
()
()
Traceback (most recent call last):
  File "a3_model.py", line 49, in <module>
    AuthorFFNN.train(row, row)
  File "a3_model.py", line 30, in train
    input = torch.LongTensor([inputs])
ValueError: expected sequence of length 5 at dim 2 (got 9)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:46: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
[(b'train', b'mccarty-d',  12.56981164,  7.11666956,  0.67210364,  0.60030199, -1.95300283,  1.57402432,  2.10112093,  1.05639544, -0.36814329, -0.07669386, -0.34720141,  2.19217072,  3.03768669,  1.20829229,  2.97056091e-01,  1.88232334,  1.72073307, 0.59839689,  2.05640877, -1.6375944 , -1.31071539,  0.82915167,  0.47005863, -0.69424241,  4.04144871, 1.52655376,  0.27959758,  0.40966464,  1.01628311, -2.16110598,  1.73057481, -1.40840588, -2.18088848, -1.02311394,  0.54826205, -0.35857963,  2.68813702,  0.62622674,  0.70367868, -0.17901807, -1.62419688e+00, -1.10306745, -7.45586428e-01,  0.75832176,  0.62109946,  9.53821471e-01, -1.66654737, 0.76801204,  0.59832142,  1.8587916 , -0.05973804, -0.24132097, -0.23528723, -1.34211977, -0.44036556, -1.13199716,  0.70254777, -1.0084303 , -1.81009898,  0.32199112,  1.9812514 ,  0.03287758, -0.56699534,  0.06796036,  1.4749887 , -0.52628464, -1.89482831, -0.51684301, 0.31824368, -1.4191414 ,  0.06764162, -1.13033762,  1.47287754,  0.30119938,  0.82665925,  0.12856326, -0.43800143,  1.36733445,  1.45051331, -0.13080843, 0.7771291 ,  0.03862671, -0.09135033, -0.83190998, -2.19713103,  1.85374188, 1.05325333,  0.60800045,  1.04858569,  4.98821621e-01, -1.17644415,  5.12187682e-01,  0.21484169,  2.15852608, -0.82257307,  1.55598431,  0.03094595,  1.12756933, -0.87700107,  1.22041968, 0.29631421,  0.25280281,  1.32375167,  0.87413803,  0.20403597,  1.64185794,  0.33861107, -0.75399814, -0.0496025 , -0.30464476, -1.00563987,  0.44525588, 0.37917884,  0.05519334, -0.11042931,  0.36740484, -0.59124142,  1.49824263,  1.96979914e+00, -0.34275243,  0.91275566,  0.85168123,  0.29502277,  1.6029408 ,  0.52704286, -0.75745548, -0.46721966,  0.35331305,  1.27867884, -0.6595269 ,  0.86399357,  0.13911299, -0.20400547,  0.58897013,  1.26039567, -0.22283223, -1.23242644,  2.21525993, -0.24917484, -0.34085596, -0.53257259,  0.27871068, -0.62502726,  1.49656541, -0.07381547,  0.03768496,  0.09002478,  0.22460604, -1.1994296 , -3.3305859 ,  0.72412426,  1.07712206,  0.29821621, -0.06792256,  0.55934896,  0.76296268, -2.80903978, -0.30281535,  1.73014142,  0.13806963,  0.49927415, -1.47033912e+00,  0.90113216, -1.17928098,  0.70968655,  0.28671242,  1.51810282, -0.20961879, -0.54507533, -0.43076143, -0.74143651,  0.64679635, -0.34209469,  0.62081813, -0.80945962, -0.2667514 , -1.26316277, -0.94923414, -1.39004962,  0.20706259, -0.76380884,  1.83282474, -0.64638006,  0.78850368, -0.01941897, -0.72376873, -1.13963937,  1.08738   ,  0.04134918, -0.00479839,  1.18496456,  2.11291126e-01, -0.45959828, -4.67350408e-01, -0.22591745, -0.12965584,  0.69058204,  1.04400387,  0.414233  , -1.30508463)
 (b'test', b'mccarty-d',  -8.44363069,  2.15865771,  1.64768541,  1.10203271, -1.66989358, -1.4336923 ,  0.51072713,  0.08935927, -0.60816733, -0.2551188 ,  1.23458467, -0.04584151, -0.89607055, -1.40115643, -1.10258618e-01,  0.02088841, -0.73290266, 0.06340862, -0.22295432,  0.37243618,  0.0288886 ,  0.65497607,  0.51244309,  0.24835868,  0.15603568, 0.04084805,  0.15750147,  0.91707914, -0.02997604, -0.29857548,  0.85306556, -0.84089346, -0.50462125, -0.13980021, -0.2882999 ,  0.26136371,  0.69767486,  0.21671422, -0.82742267, -0.16606583,  6.18818811e-01,  0.28105083, -1.81025032e-01, -0.25222594,  1.14888334,  1.37387420e-01,  0.04183802, 0.07662032, -0.15484248, -0.80886113, -0.48446773,  0.50663025, -0.8633283 ,  0.26764746,  0.06775974, -0.72421705,  0.45438221, -0.61521629,  0.30108503, -0.19857538,  0.04906677,  0.20416433,  0.52188952,  0.37967934,  1.0782982 ,  0.24863556,  0.33952338, -0.11651086, 0.76930693, -0.50869123,  0.33482045,  0.2879147 ,  0.40331262,  0.41195195, -0.25758357,  0.33021356, -0.17163388,  0.24785293, -0.54233248, -0.34628293, 0.03174483, -0.58333548,  0.02636928,  0.58540149, -0.39821562,  0.22286123, 0.56608987, -0.14487236, -0.14059437, -2.11273594e-01, -0.03943499, -8.79854918e-04,  0.35951175, -0.0782116 ,  0.00803571, -0.2164304 , -0.09724502, -0.3730208 , -0.36446101, -0.40389285, 0.56014871,  0.18104456,  0.27746854, -0.63744187,  0.1576057 ,  0.11086314,  0.20246753, -0.16888205, -0.13387245, -0.41153305, -0.10654914, -0.51506346, 0.14514245,  0.31315386,  0.13743439, -0.3527579 , -0.64507704, -0.11549552, -3.00467229e-05, -0.26565104, -0.50173213,  0.44809713, -0.1517272 ,  0.02129014,  0.03042886, -0.43568285, -0.72761712,  0.28305787,  0.20658691, -0.24342153, -0.06920583,  0.09904414,  0.06324874, -0.09915112, -0.54305145,  0.06414791, -0.9804048 , -0.29332889, -0.23938353, -0.00620682, -0.22220857,  0.1200325 , -0.06584629, -0.23408935, -0.10939799, -0.39070923,  0.47192387,  0.07126552, -0.2834255 , -0.4698761 , -0.03017593,  0.09975555, -0.12278509, -0.27211878,  0.46883207,  0.54700091, -0.26688232, -0.14638583,  0.13444312, -0.25778383, -0.42493044, -2.25789087e-01,  0.06531258,  0.14200567, -0.45574557,  0.12944482, -0.27049699, -0.19657204, -0.08358831,  0.38947344,  0.33927928,  0.36048515, -0.07685012, -0.58067335,  0.31978546, -0.08512084,  0.14672467,  0.20847777, -0.0775235 ,  0.10074919, -0.00082116,  0.47929651, -0.30593078,  0.17755226,  0.49695034,  0.0840655 ,  0.07746223, -0.10444047, -0.13083098,  0.19213164, -0.04036212,  6.67659946e-04, -0.46433204, -2.45242367e-01,  0.01318533,  0.2739388 ,  0.22814741,  0.03682739, -0.01364849, -0.41503346)
 (b'test', b'mccarty-d',  -8.38608835,  2.85373953,  1.33536598, -0.3161415 , -1.98143013,  0.54901845, -0.17882405, -0.51964403, -0.58105188,  0.35632787, -0.21762029,  0.19081553,  0.77856119, -1.39646938, -9.46885650e-03, -0.62673434, -1.378111  , 0.52936158,  2.20888408, -0.1061436 , -0.86509435, -1.00022677,  0.29818307,  1.65435178,  1.69191799, 0.39629959,  0.6385065 ,  0.0140905 ,  0.49360722,  1.15431927,  0.28163667,  0.09198537,  0.18987307,  0.52860907, -0.32658327,  0.20431831, -0.7081282 , -0.32490474, -0.15748787, -1.14828859,  1.95910878e+00, -0.80850206,  3.61056505e-01,  0.81995955,  0.61542363, -4.37129884e-01,  1.10951799, 0.55485917, -1.45917203,  0.07204979, -0.85549765, -1.07356272,  0.59665864,  1.60643649,  0.628011  ,  0.78199425,  0.36758962,  0.03270665, -0.11384386, -1.42414745,  0.50527099, -0.27671712,  0.17945113, -2.02536364, -0.07415495,  2.17053357, -0.12891998,  0.1569681 , 1.00287   , -1.94301282, -0.10368067,  0.02765045,  1.86485446, -0.13019288, -0.76208797, -0.04894366, -0.81748477,  0.27360713,  0.04331925,  0.67392243, 0.2363943 ,  0.17779683,  1.46936159,  2.70091601, -0.94429776,  0.08111145, 0.33364244,  1.10281203, -1.81655858, -5.53677561e-01, -0.37106427, -1.72923102e-01,  0.84741482,  0.23131864,  0.39276285,  0.20354492, -0.35868654,  0.20949538,  0.35957498, -0.13330569, 0.35662961,  0.35178974,  0.74374127,  0.37755005, -0.2597564 ,  1.64891267,  0.4340872 ,  1.07743942, -0.24613421, -0.1112949 , -0.03036533,  0.56666839, 0.12089813, -0.11719883, -0.05889652, -0.39538916,  0.49251872,  0.15871616,  5.07265223e-01, -0.15305131, -0.65704841,  0.51138272, -0.37156739, -0.59941021, -0.45247911,  0.51759338, -0.32904796, -0.79197003, -0.29217653,  0.00853179,  0.21808776,  0.07581323,  0.78491454, -0.62797225,  0.28083147, -0.04886866, -0.07189046, -0.40120845,  0.33079088,  0.34423451,  0.34343164, -0.56961534,  0.47719395, -0.69415764,  0.23561453, -0.41447585, -0.25502302,  0.53353591, -0.15375924, -0.07271304,  0.19620404, -0.18321546, -0.6797669 ,  0.58687089, -0.40376713, -0.6654095 ,  0.47280829,  0.15414853, -0.40573566, -0.53091242,  0.7155285 , -3.56365171e-01,  0.02939189,  1.52614931, -1.21682585, -0.53242747, -0.89497196, -1.72279133, -0.35095618, -0.98359664,  0.08012857,  0.06518562,  0.55112407,  0.18579887, -0.367888  , -0.46591173,  0.42429371,  0.25344814,  0.20047532, -0.81297523,  0.28081228, -0.34209741,  0.51995343,  1.01445339,  1.24886708, -0.49652476, -0.56110906, -0.79630903,  0.43199364,  0.1266458 ,  0.21875114, -7.34419330e-01,  0.19270971, -5.51629446e-01, -0.57970719, -0.45776598,  0.66700472,  0.27092514,  0.39640842,  0.24862596)
 ...
 (b'train', b'donohoe-t',  -8.85596732,  3.06220608,  1.08228247,  2.05196218,  1.52224307, -1.13377862,  0.24366528,  1.28894228, -0.42587121,  0.07321956, -0.28282229,  0.74876029, -0.20477054, -0.27937394,  5.41648693e-01, -0.23104429, -0.68265297, 0.00223226,  0.43316979, -0.0092101 , -0.17693233,  0.1241229 , -0.38815648,  0.66649317,  0.1342102 , 0.31849021, -0.04854111,  0.27572433, -0.29958935,  0.16031283, -0.28713549, -0.27449103, -0.30842485,  0.04267763, -0.200676  , -0.04455972, -0.09707512,  0.25208224, -0.06274931, -0.3018282 , -3.42291547e-04, -0.08381864,  2.53802172e-01, -0.65040797,  0.24451182, -5.35105728e-04, -0.05417639, 0.16347764, -0.11960161,  0.2087732 ,  0.29825752,  0.30515875,  0.16629555, -0.17657099, -0.24940602, -0.6326101 ,  0.47578766,  0.25221405, -0.18123075, -0.20940245,  0.25706809, -0.03259547, -0.11625392, -0.11293304,  0.06725202, -0.03628116, -0.2535356 , -0.33865144, 0.4499625 ,  0.02614411, -0.05457078, -0.05315289, -0.00551104, -0.17719963, -0.10482257, -0.15669462,  0.05849032, -0.30996984, -0.29717642,  0.07652056, 0.12077035, -0.3678123 , -0.42934208, -0.32218829,  0.1496298 , -0.33169353, 0.34751383, -0.25433503,  0.32334527,  1.13868677e-03, -0.00337893, -1.07955859e-01, -0.0913964 , -0.0067886 , -0.48943613, -0.022198  , -0.25513051,  0.11569247, -0.09090684, -0.01332676, 0.07610899, -0.1760369 , -0.1468709 , -0.11497682, -0.23695805,  0.10665422, -0.40672784, -0.08335584,  0.23668098, -0.08693247,  0.3066951 ,  0.31663858, 0.15038875,  0.06797926,  0.15715035, -0.24710689, -0.12184183, -0.31715571,  3.34898989e-01,  0.37046832, -0.24109084, -0.01788229,  0.26288433, -0.16198575, -0.11568269,  0.27615991,  0.02896349,  0.15595544,  0.22235165, -0.2458876 ,  0.14851793, -0.12624811,  0.0540494 ,  0.36199043,  0.1407542 , -0.46903632, -0.07868064, -0.0678318 ,  0.26319599,  0.26823883, -0.31622744, -0.22271658,  0.06617616, -0.05292798, -0.16138561, -0.24961014, -0.09270154, -0.07813747, -0.08450705,  0.28895236,  0.12921576, -0.05933047,  0.04555508, -0.37528023, -0.16855977,  0.25370943,  0.00374413, -0.15359096,  0.11920583, -0.05164607, -0.13021527,  1.20278873e-01, -0.06329861, -0.36655251, -0.2123104 , -0.1519708 , -0.20194306, -0.32587562, -0.05433914,  0.00131278,  0.05348228, -0.40366639, -0.17333033,  0.13878179,  0.06239766,  0.03873171,  0.0360756 , -0.20795184, -0.22363355, -0.20841181,  0.00972225,  0.20931692,  0.10041575,  0.14606271, -0.13132743,  0.06154965, -0.01530586, -0.09615954, -0.04218803, -0.01998132,  0.1919004 ,  1.77814442e-02,  0.11622699,  1.74157488e-01,  0.22204391, -0.21694062, -0.00819721, -0.00793042,  0.12507453,  0.00185545)
 (b'train', b'donohoe-t', -10.70633921,  2.92571163,  2.38256314,  0.82725296,  1.69753521,  0.5233887 ,  0.11529209,  0.83022757, -0.50527232,  0.52690596, -0.31700613, -0.15427668,  0.46127291, -0.28786691, -1.70569035e-01,  0.3007537 , -0.26909209, 0.88511975, -0.1339296 , -0.45658702, -0.21894321, -0.33732484, -0.14778225, -0.69714617, -0.04511788, 0.35137575,  0.32433587,  0.23550762,  0.37573403,  0.13727227,  0.66055415,  0.25463175, -0.26797747, -0.24433017, -0.19131084,  0.42496347,  0.06276173, -0.19346002, -0.14989293, -0.06678492, -4.71759408e-01,  0.09654821,  2.61239221e-03, -0.31527041,  0.24379748, -3.84353320e-01, -0.44700928, 0.11196582, -0.01557322,  0.31200032,  0.10476322,  0.14451626, -0.25082806,  0.21918777, -0.14119725, -0.01475411, -0.20340953,  0.0376813 , -0.00946694, -0.01341149, -0.09052725,  0.22571492,  0.10182263,  0.14461768, -0.18145682,  0.20781414, -0.0107848 , -0.16501542, 0.08652009, -0.06393093, -0.12429571, -0.04549153,  0.22503862, -0.16615349,  0.079682  , -0.21487914,  0.29690772, -0.08225436, -0.10229976, -0.23040117, 0.03043874,  0.00364834, -0.03348361,  0.26309478,  0.08039576, -0.08892385, 0.23897774, -0.31107259, -0.01965908,  3.58822092e-01,  0.24208283,  3.50198135e-02,  0.15366691,  0.10627602,  0.0075611 ,  0.18668791, -0.14903594, -0.20333518, -0.17322174,  0.15832356, 0.1941937 , -0.0380541 , -0.14274048, -0.33773582, -0.22354312, -0.01393656,  0.26028814,  0.04246061, -0.1553711 , -0.15845114, -0.14860349,  0.16045209, 0.01276104,  0.28913311, -0.06546221, -0.0225797 ,  0.04485469, -0.22894223, -6.40510878e-02,  0.09369658, -0.38638711,  0.09155065, -0.02034475,  0.19845422, -0.03549269, -0.01100393,  0.02298318, -0.20761726, -0.03935967, -0.216163  , -0.2222094 , -0.16142523, -0.11803145,  0.02168535, -0.27447979, -0.0652234 ,  0.1822665 ,  0.07160499,  0.22580121, -0.13753517, -0.08876215,  0.01895244,  0.11298549,  0.11308582, -0.02563247, -0.33320986, -0.15696276, -0.0184484 , -0.03756076, -0.09336458,  0.07976561, -0.0833361 ,  0.09297862, -0.00341332,  0.04874357,  0.0923416 ,  0.07191248, -0.13066039,  0.044271  , -0.16881976,  0.04585116,  7.83872420e-04,  0.0422678 , -0.34125869, -0.15637158,  0.20577379,  0.0715845 ,  0.0922595 , -0.03117927, -0.04153573,  0.15900446, -0.16123515,  0.1024818 , -0.02316264, -0.01376422, -0.08655137, -0.02594853, -0.16999944,  0.11695494,  0.0815875 , -0.13662503,  0.07676383,  0.11054433,  0.08567626, -0.01672995,  0.09596518,  0.19334905, -0.03842375, -0.06319933,  0.00430524, -0.16742358,  8.69310134e-02,  0.27516431,  3.54378584e-04,  0.10009312, -0.02485518, -0.05177192, -0.05454901,  0.02230255, -0.04411912)
 (b'train', b'donohoe-t',  11.30000448, -4.14237484, -5.7034437 , -2.06402278, -1.19556592, -0.67090291, -1.70350215,  0.72985941,  3.52890703, -0.96349759, -7.52174488, -8.02539357,  2.09213368, -0.33843692,  9.73668919e+00,  0.72761653, -1.12334307, 1.17151447,  2.5195447 ,  1.12159932,  0.90140023,  0.84407537, -0.64555319, -2.54958839,  2.50839613, 3.56503721,  0.12256078, -0.25722534,  8.64383495,  1.77431828,  0.18119942, -6.91885649,  3.64289634,  2.36348915, -4.13564762, -4.02754016,  0.37888518,  0.87378518,  5.02787591,  4.82976067,  1.45706127e+00,  1.01991771, -8.94305512e+00, -2.12945187, -1.38096591,  7.48431447e+00, -4.10483534, 2.31432559,  2.70039899,  7.44967274, -3.41052005,  3.75361813, -1.81358686,  9.7949236 , -6.78210378, -1.52299882, -0.99235072, -2.2661746 , -0.45470609,  0.29735189, -0.71927647,  0.53851997,  0.87761698,  3.65907926,  2.17491603, -1.472557  , -3.74455536, -0.59922628, 3.06928244, -2.81294546, -2.52537532, -3.14862599,  0.95882384,  0.47533088,  0.89544693, -5.35202781,  0.50749829,  0.86628164, -2.20899345, -0.69040562, 4.96291807,  3.14471795, -1.97866337,  0.325702  ,  0.78630856,  0.62249265, 1.96112679, -1.37521518, -0.33463671,  1.17201227e+00,  3.37821446,  9.33328058e-01,  0.55325839,  0.41948674, -2.36411673, -0.44498439,  1.96505803, -0.73195578,  0.64424049,  0.08408526, 0.73057884, -1.34488342, -0.36033545, -0.96242817, -1.67150521,  0.8220491 , -0.24178305,  0.22055757, -1.94881786, -0.37756614,  0.63172935, -0.13521893, 0.34595056,  1.38934281, -0.8694838 , -1.82320138, -1.06351301, -0.40747137,  5.12357341e-01,  0.75233444,  1.29928367, -0.93093475,  0.68461757, -0.72893953,  0.6854137 ,  1.18173739,  0.14576231, -0.31526333, -0.39900965, -0.40051449, -0.07930317, -0.4387255 ,  0.53226285, -0.01651948, -0.20339442, -0.07056107,  0.03749561,  0.43518358,  0.55045566,  0.03392457,  0.82496511,  0.51913958,  0.17414963, -0.90130548, -0.72048321, -1.07794683, -0.26385589,  0.02152393,  0.19492747,  0.97408193, -0.12415293,  0.54269894,  0.6142857 ,  0.51090037,  0.30447384,  0.14780483,  0.44137854,  0.20531939, -0.47367894, -0.0120034 ,  0.2278092 ,  6.91219666e-01,  0.14550907, -0.22708918,  0.05226129, -0.37671832, -0.56841889,  0.34995297,  0.52937222,  0.49987136, -0.55359715, -0.97737757, -0.5914951 ,  0.30502067, -0.11065874, -0.07627141, -0.41456979,  0.621935  , -0.42285186,  0.01235818,  0.35734086,  0.56175742,  0.30339608, -0.15443758, -0.31644012,  0.2348128 , -0.2680476 , -0.43775691, -0.21312861, -0.46244121, -0.08103561, -9.43193033e-02,  0.23974454,  2.30581325e-03,  0.29874296, -0.66784326,  0.52838098, -0.68158293, -0.17402795, -0.13494612)]
()
()
Traceback (most recent call last):
  File "a3_model.py", line 50, in <module>
    AuthorFFNN.train(row, row)
  File "a3_model.py", line 30, in train
    input = torch.LongTensor([inputs])
ValueError: expected sequence of length 5 at dim 2 (got 9)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:46: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
this is a row
()
()
Traceback (most recent call last):
  File "a3_model.py", line 50, in <module>
    AuthorFFNN.train(row, row)
  File "a3_model.py", line 30, in train
    input = torch.LongTensor([inputs])
ValueError: expected sequence of length 5 at dim 2 (got 9)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:46: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
this is a row
202
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:42: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
Traceback (most recent call last):
  File "a3_model.py", line 43, in <module>
    AuthorFFNN.train(data)    
TypeError: train() missing 1 required positional argument: 'inputs'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:42: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
Traceback (most recent call last):
  File "a3_model.py", line 43, in <module>
    AuthorFFNN.train(self, data)    
NameError: name 'self' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:42: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
Traceback (most recent call last):
  File "a3_model.py", line 43, in <module>
    x = AuthorFFNN()
TypeError: __init__() missing 1 required positional argument: 'inputvector'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:40: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
[(b'train', b'mccarty-d',  12.56981164,  7.11666956,  0.67210364,  0.60030199, -1.95300283,  1.57402432,  2.10112093,  1.05639544, -0.36814329, -0.07669386, -0.34720141,  2.19217072,  3.03768669,  1.20829229,  2.97056091e-01,  1.88232334,  1.72073307, 0.59839689,  2.05640877, -1.6375944 , -1.31071539,  0.82915167,  0.47005863, -0.69424241,  4.04144871, 1.52655376,  0.27959758,  0.40966464,  1.01628311, -2.16110598,  1.73057481, -1.40840588, -2.18088848, -1.02311394,  0.54826205, -0.35857963,  2.68813702,  0.62622674,  0.70367868, -0.17901807, -1.62419688e+00, -1.10306745, -7.45586428e-01,  0.75832176,  0.62109946,  9.53821471e-01, -1.66654737, 0.76801204,  0.59832142,  1.8587916 , -0.05973804, -0.24132097, -0.23528723, -1.34211977, -0.44036556, -1.13199716,  0.70254777, -1.0084303 , -1.81009898,  0.32199112,  1.9812514 ,  0.03287758, -0.56699534,  0.06796036,  1.4749887 , -0.52628464, -1.89482831, -0.51684301, 0.31824368, -1.4191414 ,  0.06764162, -1.13033762,  1.47287754,  0.30119938,  0.82665925,  0.12856326, -0.43800143,  1.36733445,  1.45051331, -0.13080843, 0.7771291 ,  0.03862671, -0.09135033, -0.83190998, -2.19713103,  1.85374188, 1.05325333,  0.60800045,  1.04858569,  4.98821621e-01, -1.17644415,  5.12187682e-01,  0.21484169,  2.15852608, -0.82257307,  1.55598431,  0.03094595,  1.12756933, -0.87700107,  1.22041968, 0.29631421,  0.25280281,  1.32375167,  0.87413803,  0.20403597,  1.64185794,  0.33861107, -0.75399814, -0.0496025 , -0.30464476, -1.00563987,  0.44525588, 0.37917884,  0.05519334, -0.11042931,  0.36740484, -0.59124142,  1.49824263,  1.96979914e+00, -0.34275243,  0.91275566,  0.85168123,  0.29502277,  1.6029408 ,  0.52704286, -0.75745548, -0.46721966,  0.35331305,  1.27867884, -0.6595269 ,  0.86399357,  0.13911299, -0.20400547,  0.58897013,  1.26039567, -0.22283223, -1.23242644,  2.21525993, -0.24917484, -0.34085596, -0.53257259,  0.27871068, -0.62502726,  1.49656541, -0.07381547,  0.03768496,  0.09002478,  0.22460604, -1.1994296 , -3.3305859 ,  0.72412426,  1.07712206,  0.29821621, -0.06792256,  0.55934896,  0.76296268, -2.80903978, -0.30281535,  1.73014142,  0.13806963,  0.49927415, -1.47033912e+00,  0.90113216, -1.17928098,  0.70968655,  0.28671242,  1.51810282, -0.20961879, -0.54507533, -0.43076143, -0.74143651,  0.64679635, -0.34209469,  0.62081813, -0.80945962, -0.2667514 , -1.26316277, -0.94923414, -1.39004962,  0.20706259, -0.76380884,  1.83282474, -0.64638006,  0.78850368, -0.01941897, -0.72376873, -1.13963937,  1.08738   ,  0.04134918, -0.00479839,  1.18496456,  2.11291126e-01, -0.45959828, -4.67350408e-01, -0.22591745, -0.12965584,  0.69058204,  1.04400387,  0.414233  , -1.30508463)
 (b'test', b'mccarty-d',  -8.44363069,  2.15865771,  1.64768541,  1.10203271, -1.66989358, -1.4336923 ,  0.51072713,  0.08935927, -0.60816733, -0.2551188 ,  1.23458467, -0.04584151, -0.89607055, -1.40115643, -1.10258618e-01,  0.02088841, -0.73290266, 0.06340862, -0.22295432,  0.37243618,  0.0288886 ,  0.65497607,  0.51244309,  0.24835868,  0.15603568, 0.04084805,  0.15750147,  0.91707914, -0.02997604, -0.29857548,  0.85306556, -0.84089346, -0.50462125, -0.13980021, -0.2882999 ,  0.26136371,  0.69767486,  0.21671422, -0.82742267, -0.16606583,  6.18818811e-01,  0.28105083, -1.81025032e-01, -0.25222594,  1.14888334,  1.37387420e-01,  0.04183802, 0.07662032, -0.15484248, -0.80886113, -0.48446773,  0.50663025, -0.8633283 ,  0.26764746,  0.06775974, -0.72421705,  0.45438221, -0.61521629,  0.30108503, -0.19857538,  0.04906677,  0.20416433,  0.52188952,  0.37967934,  1.0782982 ,  0.24863556,  0.33952338, -0.11651086, 0.76930693, -0.50869123,  0.33482045,  0.2879147 ,  0.40331262,  0.41195195, -0.25758357,  0.33021356, -0.17163388,  0.24785293, -0.54233248, -0.34628293, 0.03174483, -0.58333548,  0.02636928,  0.58540149, -0.39821562,  0.22286123, 0.56608987, -0.14487236, -0.14059437, -2.11273594e-01, -0.03943499, -8.79854918e-04,  0.35951175, -0.0782116 ,  0.00803571, -0.2164304 , -0.09724502, -0.3730208 , -0.36446101, -0.40389285, 0.56014871,  0.18104456,  0.27746854, -0.63744187,  0.1576057 ,  0.11086314,  0.20246753, -0.16888205, -0.13387245, -0.41153305, -0.10654914, -0.51506346, 0.14514245,  0.31315386,  0.13743439, -0.3527579 , -0.64507704, -0.11549552, -3.00467229e-05, -0.26565104, -0.50173213,  0.44809713, -0.1517272 ,  0.02129014,  0.03042886, -0.43568285, -0.72761712,  0.28305787,  0.20658691, -0.24342153, -0.06920583,  0.09904414,  0.06324874, -0.09915112, -0.54305145,  0.06414791, -0.9804048 , -0.29332889, -0.23938353, -0.00620682, -0.22220857,  0.1200325 , -0.06584629, -0.23408935, -0.10939799, -0.39070923,  0.47192387,  0.07126552, -0.2834255 , -0.4698761 , -0.03017593,  0.09975555, -0.12278509, -0.27211878,  0.46883207,  0.54700091, -0.26688232, -0.14638583,  0.13444312, -0.25778383, -0.42493044, -2.25789087e-01,  0.06531258,  0.14200567, -0.45574557,  0.12944482, -0.27049699, -0.19657204, -0.08358831,  0.38947344,  0.33927928,  0.36048515, -0.07685012, -0.58067335,  0.31978546, -0.08512084,  0.14672467,  0.20847777, -0.0775235 ,  0.10074919, -0.00082116,  0.47929651, -0.30593078,  0.17755226,  0.49695034,  0.0840655 ,  0.07746223, -0.10444047, -0.13083098,  0.19213164, -0.04036212,  6.67659946e-04, -0.46433204, -2.45242367e-01,  0.01318533,  0.2739388 ,  0.22814741,  0.03682739, -0.01364849, -0.41503346)
 (b'test', b'mccarty-d',  -8.38608835,  2.85373953,  1.33536598, -0.3161415 , -1.98143013,  0.54901845, -0.17882405, -0.51964403, -0.58105188,  0.35632787, -0.21762029,  0.19081553,  0.77856119, -1.39646938, -9.46885650e-03, -0.62673434, -1.378111  , 0.52936158,  2.20888408, -0.1061436 , -0.86509435, -1.00022677,  0.29818307,  1.65435178,  1.69191799, 0.39629959,  0.6385065 ,  0.0140905 ,  0.49360722,  1.15431927,  0.28163667,  0.09198537,  0.18987307,  0.52860907, -0.32658327,  0.20431831, -0.7081282 , -0.32490474, -0.15748787, -1.14828859,  1.95910878e+00, -0.80850206,  3.61056505e-01,  0.81995955,  0.61542363, -4.37129884e-01,  1.10951799, 0.55485917, -1.45917203,  0.07204979, -0.85549765, -1.07356272,  0.59665864,  1.60643649,  0.628011  ,  0.78199425,  0.36758962,  0.03270665, -0.11384386, -1.42414745,  0.50527099, -0.27671712,  0.17945113, -2.02536364, -0.07415495,  2.17053357, -0.12891998,  0.1569681 , 1.00287   , -1.94301282, -0.10368067,  0.02765045,  1.86485446, -0.13019288, -0.76208797, -0.04894366, -0.81748477,  0.27360713,  0.04331925,  0.67392243, 0.2363943 ,  0.17779683,  1.46936159,  2.70091601, -0.94429776,  0.08111145, 0.33364244,  1.10281203, -1.81655858, -5.53677561e-01, -0.37106427, -1.72923102e-01,  0.84741482,  0.23131864,  0.39276285,  0.20354492, -0.35868654,  0.20949538,  0.35957498, -0.13330569, 0.35662961,  0.35178974,  0.74374127,  0.37755005, -0.2597564 ,  1.64891267,  0.4340872 ,  1.07743942, -0.24613421, -0.1112949 , -0.03036533,  0.56666839, 0.12089813, -0.11719883, -0.05889652, -0.39538916,  0.49251872,  0.15871616,  5.07265223e-01, -0.15305131, -0.65704841,  0.51138272, -0.37156739, -0.59941021, -0.45247911,  0.51759338, -0.32904796, -0.79197003, -0.29217653,  0.00853179,  0.21808776,  0.07581323,  0.78491454, -0.62797225,  0.28083147, -0.04886866, -0.07189046, -0.40120845,  0.33079088,  0.34423451,  0.34343164, -0.56961534,  0.47719395, -0.69415764,  0.23561453, -0.41447585, -0.25502302,  0.53353591, -0.15375924, -0.07271304,  0.19620404, -0.18321546, -0.6797669 ,  0.58687089, -0.40376713, -0.6654095 ,  0.47280829,  0.15414853, -0.40573566, -0.53091242,  0.7155285 , -3.56365171e-01,  0.02939189,  1.52614931, -1.21682585, -0.53242747, -0.89497196, -1.72279133, -0.35095618, -0.98359664,  0.08012857,  0.06518562,  0.55112407,  0.18579887, -0.367888  , -0.46591173,  0.42429371,  0.25344814,  0.20047532, -0.81297523,  0.28081228, -0.34209741,  0.51995343,  1.01445339,  1.24886708, -0.49652476, -0.56110906, -0.79630903,  0.43199364,  0.1266458 ,  0.21875114, -7.34419330e-01,  0.19270971, -5.51629446e-01, -0.57970719, -0.45776598,  0.66700472,  0.27092514,  0.39640842,  0.24862596)
 ...
 (b'train', b'donohoe-t',  -8.85596732,  3.06220608,  1.08228247,  2.05196218,  1.52224307, -1.13377862,  0.24366528,  1.28894228, -0.42587121,  0.07321956, -0.28282229,  0.74876029, -0.20477054, -0.27937394,  5.41648693e-01, -0.23104429, -0.68265297, 0.00223226,  0.43316979, -0.0092101 , -0.17693233,  0.1241229 , -0.38815648,  0.66649317,  0.1342102 , 0.31849021, -0.04854111,  0.27572433, -0.29958935,  0.16031283, -0.28713549, -0.27449103, -0.30842485,  0.04267763, -0.200676  , -0.04455972, -0.09707512,  0.25208224, -0.06274931, -0.3018282 , -3.42291547e-04, -0.08381864,  2.53802172e-01, -0.65040797,  0.24451182, -5.35105728e-04, -0.05417639, 0.16347764, -0.11960161,  0.2087732 ,  0.29825752,  0.30515875,  0.16629555, -0.17657099, -0.24940602, -0.6326101 ,  0.47578766,  0.25221405, -0.18123075, -0.20940245,  0.25706809, -0.03259547, -0.11625392, -0.11293304,  0.06725202, -0.03628116, -0.2535356 , -0.33865144, 0.4499625 ,  0.02614411, -0.05457078, -0.05315289, -0.00551104, -0.17719963, -0.10482257, -0.15669462,  0.05849032, -0.30996984, -0.29717642,  0.07652056, 0.12077035, -0.3678123 , -0.42934208, -0.32218829,  0.1496298 , -0.33169353, 0.34751383, -0.25433503,  0.32334527,  1.13868677e-03, -0.00337893, -1.07955859e-01, -0.0913964 , -0.0067886 , -0.48943613, -0.022198  , -0.25513051,  0.11569247, -0.09090684, -0.01332676, 0.07610899, -0.1760369 , -0.1468709 , -0.11497682, -0.23695805,  0.10665422, -0.40672784, -0.08335584,  0.23668098, -0.08693247,  0.3066951 ,  0.31663858, 0.15038875,  0.06797926,  0.15715035, -0.24710689, -0.12184183, -0.31715571,  3.34898989e-01,  0.37046832, -0.24109084, -0.01788229,  0.26288433, -0.16198575, -0.11568269,  0.27615991,  0.02896349,  0.15595544,  0.22235165, -0.2458876 ,  0.14851793, -0.12624811,  0.0540494 ,  0.36199043,  0.1407542 , -0.46903632, -0.07868064, -0.0678318 ,  0.26319599,  0.26823883, -0.31622744, -0.22271658,  0.06617616, -0.05292798, -0.16138561, -0.24961014, -0.09270154, -0.07813747, -0.08450705,  0.28895236,  0.12921576, -0.05933047,  0.04555508, -0.37528023, -0.16855977,  0.25370943,  0.00374413, -0.15359096,  0.11920583, -0.05164607, -0.13021527,  1.20278873e-01, -0.06329861, -0.36655251, -0.2123104 , -0.1519708 , -0.20194306, -0.32587562, -0.05433914,  0.00131278,  0.05348228, -0.40366639, -0.17333033,  0.13878179,  0.06239766,  0.03873171,  0.0360756 , -0.20795184, -0.22363355, -0.20841181,  0.00972225,  0.20931692,  0.10041575,  0.14606271, -0.13132743,  0.06154965, -0.01530586, -0.09615954, -0.04218803, -0.01998132,  0.1919004 ,  1.77814442e-02,  0.11622699,  1.74157488e-01,  0.22204391, -0.21694062, -0.00819721, -0.00793042,  0.12507453,  0.00185545)
 (b'train', b'donohoe-t', -10.70633921,  2.92571163,  2.38256314,  0.82725296,  1.69753521,  0.5233887 ,  0.11529209,  0.83022757, -0.50527232,  0.52690596, -0.31700613, -0.15427668,  0.46127291, -0.28786691, -1.70569035e-01,  0.3007537 , -0.26909209, 0.88511975, -0.1339296 , -0.45658702, -0.21894321, -0.33732484, -0.14778225, -0.69714617, -0.04511788, 0.35137575,  0.32433587,  0.23550762,  0.37573403,  0.13727227,  0.66055415,  0.25463175, -0.26797747, -0.24433017, -0.19131084,  0.42496347,  0.06276173, -0.19346002, -0.14989293, -0.06678492, -4.71759408e-01,  0.09654821,  2.61239221e-03, -0.31527041,  0.24379748, -3.84353320e-01, -0.44700928, 0.11196582, -0.01557322,  0.31200032,  0.10476322,  0.14451626, -0.25082806,  0.21918777, -0.14119725, -0.01475411, -0.20340953,  0.0376813 , -0.00946694, -0.01341149, -0.09052725,  0.22571492,  0.10182263,  0.14461768, -0.18145682,  0.20781414, -0.0107848 , -0.16501542, 0.08652009, -0.06393093, -0.12429571, -0.04549153,  0.22503862, -0.16615349,  0.079682  , -0.21487914,  0.29690772, -0.08225436, -0.10229976, -0.23040117, 0.03043874,  0.00364834, -0.03348361,  0.26309478,  0.08039576, -0.08892385, 0.23897774, -0.31107259, -0.01965908,  3.58822092e-01,  0.24208283,  3.50198135e-02,  0.15366691,  0.10627602,  0.0075611 ,  0.18668791, -0.14903594, -0.20333518, -0.17322174,  0.15832356, 0.1941937 , -0.0380541 , -0.14274048, -0.33773582, -0.22354312, -0.01393656,  0.26028814,  0.04246061, -0.1553711 , -0.15845114, -0.14860349,  0.16045209, 0.01276104,  0.28913311, -0.06546221, -0.0225797 ,  0.04485469, -0.22894223, -6.40510878e-02,  0.09369658, -0.38638711,  0.09155065, -0.02034475,  0.19845422, -0.03549269, -0.01100393,  0.02298318, -0.20761726, -0.03935967, -0.216163  , -0.2222094 , -0.16142523, -0.11803145,  0.02168535, -0.27447979, -0.0652234 ,  0.1822665 ,  0.07160499,  0.22580121, -0.13753517, -0.08876215,  0.01895244,  0.11298549,  0.11308582, -0.02563247, -0.33320986, -0.15696276, -0.0184484 , -0.03756076, -0.09336458,  0.07976561, -0.0833361 ,  0.09297862, -0.00341332,  0.04874357,  0.0923416 ,  0.07191248, -0.13066039,  0.044271  , -0.16881976,  0.04585116,  7.83872420e-04,  0.0422678 , -0.34125869, -0.15637158,  0.20577379,  0.0715845 ,  0.0922595 , -0.03117927, -0.04153573,  0.15900446, -0.16123515,  0.1024818 , -0.02316264, -0.01376422, -0.08655137, -0.02594853, -0.16999944,  0.11695494,  0.0815875 , -0.13662503,  0.07676383,  0.11054433,  0.08567626, -0.01672995,  0.09596518,  0.19334905, -0.03842375, -0.06319933,  0.00430524, -0.16742358,  8.69310134e-02,  0.27516431,  3.54378584e-04,  0.10009312, -0.02485518, -0.05177192, -0.05454901,  0.02230255, -0.04411912)
 (b'train', b'donohoe-t',  11.30000448, -4.14237484, -5.7034437 , -2.06402278, -1.19556592, -0.67090291, -1.70350215,  0.72985941,  3.52890703, -0.96349759, -7.52174488, -8.02539357,  2.09213368, -0.33843692,  9.73668919e+00,  0.72761653, -1.12334307, 1.17151447,  2.5195447 ,  1.12159932,  0.90140023,  0.84407537, -0.64555319, -2.54958839,  2.50839613, 3.56503721,  0.12256078, -0.25722534,  8.64383495,  1.77431828,  0.18119942, -6.91885649,  3.64289634,  2.36348915, -4.13564762, -4.02754016,  0.37888518,  0.87378518,  5.02787591,  4.82976067,  1.45706127e+00,  1.01991771, -8.94305512e+00, -2.12945187, -1.38096591,  7.48431447e+00, -4.10483534, 2.31432559,  2.70039899,  7.44967274, -3.41052005,  3.75361813, -1.81358686,  9.7949236 , -6.78210378, -1.52299882, -0.99235072, -2.2661746 , -0.45470609,  0.29735189, -0.71927647,  0.53851997,  0.87761698,  3.65907926,  2.17491603, -1.472557  , -3.74455536, -0.59922628, 3.06928244, -2.81294546, -2.52537532, -3.14862599,  0.95882384,  0.47533088,  0.89544693, -5.35202781,  0.50749829,  0.86628164, -2.20899345, -0.69040562, 4.96291807,  3.14471795, -1.97866337,  0.325702  ,  0.78630856,  0.62249265, 1.96112679, -1.37521518, -0.33463671,  1.17201227e+00,  3.37821446,  9.33328058e-01,  0.55325839,  0.41948674, -2.36411673, -0.44498439,  1.96505803, -0.73195578,  0.64424049,  0.08408526, 0.73057884, -1.34488342, -0.36033545, -0.96242817, -1.67150521,  0.8220491 , -0.24178305,  0.22055757, -1.94881786, -0.37756614,  0.63172935, -0.13521893, 0.34595056,  1.38934281, -0.8694838 , -1.82320138, -1.06351301, -0.40747137,  5.12357341e-01,  0.75233444,  1.29928367, -0.93093475,  0.68461757, -0.72893953,  0.6854137 ,  1.18173739,  0.14576231, -0.31526333, -0.39900965, -0.40051449, -0.07930317, -0.4387255 ,  0.53226285, -0.01651948, -0.20339442, -0.07056107,  0.03749561,  0.43518358,  0.55045566,  0.03392457,  0.82496511,  0.51913958,  0.17414963, -0.90130548, -0.72048321, -1.07794683, -0.26385589,  0.02152393,  0.19492747,  0.97408193, -0.12415293,  0.54269894,  0.6142857 ,  0.51090037,  0.30447384,  0.14780483,  0.44137854,  0.20531939, -0.47367894, -0.0120034 ,  0.2278092 ,  6.91219666e-01,  0.14550907, -0.22708918,  0.05226129, -0.37671832, -0.56841889,  0.34995297,  0.52937222,  0.49987136, -0.55359715, -0.97737757, -0.5914951 ,  0.30502067, -0.11065874, -0.07627141, -0.41456979,  0.621935  , -0.42285186,  0.01235818,  0.35734086,  0.56175742,  0.30339608, -0.15443758, -0.31644012,  0.2348128 , -0.2680476 , -0.43775691, -0.21312861, -0.46244121, -0.08103561, -9.43193033e-02,  0.23974454,  2.30581325e-03,  0.29874296, -0.66784326,  0.52838098, -0.68158293, -0.17402795, -0.13494612)]
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:40: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
Traceback (most recent call last):
  File "a3_model.py", line 42, in <module>
    x.train(data)
  File "a3_model.py", line 28, in train
    optimizer = optim.SGD(self.model.parameters(), lr=self.lr)
AttributeError: 'AuthorFFNN' object has no attribute 'model'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:41: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
Traceback (most recent call last):
  File "a3_model.py", line 44, in <module>
    x.train(data)
  File "a3_model.py", line 29, in train
    optimizer = optim.SGD(self.model.parameters(), lr=self.lr)
AttributeError: 'AuthorFFNN' object has no attribute 'lr'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
  File "a3_model.py", line 24
    def __init__(self, lr =0.01)
                               ^
SyntaxError: invalid syntax
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:43: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
  File "a3_model.py", line 31
    for i in range
                 ^
SyntaxError: invalid syntax
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:42: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
a3_model.py:43: FutureWarning: elementwise == comparison failed and returning scalar instead; this will raise an error or perform elementwise comparison in the future.
  ar_train = data[0] == "train"
False
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:42: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
Traceback (most recent call last):
  File "a3_model.py", line 43, in <module>
    ar_train = data[:, 0] == "train"
IndexError: too many indices for array
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:42: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
Traceback (most recent call last):
  File "a3_model.py", line 44, in <module>
    ar_train = data[np.in1d(a[:, 1], filter)]
NameError: name 'a' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:42: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
Traceback (most recent call last):
  File "a3_model.py", line 44, in <module>
    ar_train = data[np.in1d(data[:, 1], filter)]
IndexError: too many indices for array
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:42: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
(2929,)
Traceback (most recent call last):
  File "a3_model.py", line 45, in <module>
    ar_train = data[np.in1d(data[:, 1], filter)]
IndexError: too many indices for array
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:42: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
(2929,)
(b'train', b'mccarty-d', 12.56981164, 7.11666956, 0.67210364, 0.60030199, -1.95300283, 1.57402432, 2.10112093, 1.05639544, -0.36814329, -0.07669386, -0.34720141, 2.19217072, 3.03768669, 1.20829229, 0.29705609, 1.88232334, 1.72073307, 0.59839689, 2.05640877, -1.6375944, -1.31071539, 0.82915167, 0.47005863, -0.69424241, 4.04144871, 1.52655376, 0.27959758, 0.40966464, 1.01628311, -2.16110598, 1.73057481, -1.40840588, -2.18088848, -1.02311394, 0.54826205, -0.35857963, 2.68813702, 0.62622674, 0.70367868, -0.17901807, -1.62419688, -1.10306745, -0.74558643, 0.75832176, 0.62109946, 0.95382147, -1.66654737, 0.76801204, 0.59832142, 1.8587916, -0.05973804, -0.24132097, -0.23528723, -1.34211977, -0.44036556, -1.13199716, 0.70254777, -1.0084303, -1.81009898, 0.32199112, 1.9812514, 0.03287758, -0.56699534, 0.06796036, 1.4749887, -0.52628464, -1.89482831, -0.51684301, 0.31824368, -1.4191414, 0.06764162, -1.13033762, 1.47287754, 0.30119938, 0.82665925, 0.12856326, -0.43800143, 1.36733445, 1.45051331, -0.13080843, 0.7771291, 0.03862671, -0.09135033, -0.83190998, -2.19713103, 1.85374188, 1.05325333, 0.60800045, 1.04858569, 0.49882162, -1.17644415, 0.51218768, 0.21484169, 2.15852608, -0.82257307, 1.55598431, 0.03094595, 1.12756933, -0.87700107, 1.22041968, 0.29631421, 0.25280281, 1.32375167, 0.87413803, 0.20403597, 1.64185794, 0.33861107, -0.75399814, -0.0496025, -0.30464476, -1.00563987, 0.44525588, 0.37917884, 0.05519334, -0.11042931, 0.36740484, -0.59124142, 1.49824263, 1.96979914, -0.34275243, 0.91275566, 0.85168123, 0.29502277, 1.6029408, 0.52704286, -0.75745548, -0.46721966, 0.35331305, 1.27867884, -0.6595269, 0.86399357, 0.13911299, -0.20400547, 0.58897013, 1.26039567, -0.22283223, -1.23242644, 2.21525993, -0.24917484, -0.34085596, -0.53257259, 0.27871068, -0.62502726, 1.49656541, -0.07381547, 0.03768496, 0.09002478, 0.22460604, -1.1994296, -3.3305859, 0.72412426, 1.07712206, 0.29821621, -0.06792256, 0.55934896, 0.76296268, -2.80903978, -0.30281535, 1.73014142, 0.13806963, 0.49927415, -1.47033912, 0.90113216, -1.17928098, 0.70968655, 0.28671242, 1.51810282, -0.20961879, -0.54507533, -0.43076143, -0.74143651, 0.64679635, -0.34209469, 0.62081813, -0.80945962, -0.2667514, -1.26316277, -0.94923414, -1.39004962, 0.20706259, -0.76380884, 1.83282474, -0.64638006, 0.78850368, -0.01941897, -0.72376873, -1.13963937, 1.08738, 0.04134918, -0.00479839, 1.18496456, 0.21129113, -0.45959828, -0.46735041, -0.22591745, -0.12965584, 0.69058204, 1.04400387, 0.414233, -1.30508463)
Traceback (most recent call last):
  File "a3_model.py", line 46, in <module>
    ar_train = data[np.in1d(data[:, 1], filter)]
IndexError: too many indices for array
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:42: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
(2929,)
(b'train', b'mccarty-d', 12.56981164, 7.11666956, 0.67210364, 0.60030199, -1.95300283, 1.57402432, 2.10112093, 1.05639544, -0.36814329, -0.07669386, -0.34720141, 2.19217072, 3.03768669, 1.20829229, 0.29705609, 1.88232334, 1.72073307, 0.59839689, 2.05640877, -1.6375944, -1.31071539, 0.82915167, 0.47005863, -0.69424241, 4.04144871, 1.52655376, 0.27959758, 0.40966464, 1.01628311, -2.16110598, 1.73057481, -1.40840588, -2.18088848, -1.02311394, 0.54826205, -0.35857963, 2.68813702, 0.62622674, 0.70367868, -0.17901807, -1.62419688, -1.10306745, -0.74558643, 0.75832176, 0.62109946, 0.95382147, -1.66654737, 0.76801204, 0.59832142, 1.8587916, -0.05973804, -0.24132097, -0.23528723, -1.34211977, -0.44036556, -1.13199716, 0.70254777, -1.0084303, -1.81009898, 0.32199112, 1.9812514, 0.03287758, -0.56699534, 0.06796036, 1.4749887, -0.52628464, -1.89482831, -0.51684301, 0.31824368, -1.4191414, 0.06764162, -1.13033762, 1.47287754, 0.30119938, 0.82665925, 0.12856326, -0.43800143, 1.36733445, 1.45051331, -0.13080843, 0.7771291, 0.03862671, -0.09135033, -0.83190998, -2.19713103, 1.85374188, 1.05325333, 0.60800045, 1.04858569, 0.49882162, -1.17644415, 0.51218768, 0.21484169, 2.15852608, -0.82257307, 1.55598431, 0.03094595, 1.12756933, -0.87700107, 1.22041968, 0.29631421, 0.25280281, 1.32375167, 0.87413803, 0.20403597, 1.64185794, 0.33861107, -0.75399814, -0.0496025, -0.30464476, -1.00563987, 0.44525588, 0.37917884, 0.05519334, -0.11042931, 0.36740484, -0.59124142, 1.49824263, 1.96979914, -0.34275243, 0.91275566, 0.85168123, 0.29502277, 1.6029408, 0.52704286, -0.75745548, -0.46721966, 0.35331305, 1.27867884, -0.6595269, 0.86399357, 0.13911299, -0.20400547, 0.58897013, 1.26039567, -0.22283223, -1.23242644, 2.21525993, -0.24917484, -0.34085596, -0.53257259, 0.27871068, -0.62502726, 1.49656541, -0.07381547, 0.03768496, 0.09002478, 0.22460604, -1.1994296, -3.3305859, 0.72412426, 1.07712206, 0.29821621, -0.06792256, 0.55934896, 0.76296268, -2.80903978, -0.30281535, 1.73014142, 0.13806963, 0.49927415, -1.47033912, 0.90113216, -1.17928098, 0.70968655, 0.28671242, 1.51810282, -0.20961879, -0.54507533, -0.43076143, -0.74143651, 0.64679635, -0.34209469, 0.62081813, -0.80945962, -0.2667514, -1.26316277, -0.94923414, -1.39004962, 0.20706259, -0.76380884, 1.83282474, -0.64638006, 0.78850368, -0.01941897, -0.72376873, -1.13963937, 1.08738, 0.04134918, -0.00479839, 1.18496456, 0.21129113, -0.45959828, -0.46735041, -0.22591745, -0.12965584, 0.69058204, 1.04400387, 0.414233, -1.30508463)
Traceback (most recent call last):
  File "a3_model.py", line 46, in <module>
    ar_train = data[np.in1d(data[:, 0], filter)]
IndexError: too many indices for array
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
  File "a3_model.py", line 44
    filter = np.asarray(['train'])
         ^
SyntaxError: invalid syntax
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:42: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None)
<class 'numpy.void'>
Traceback (most recent call last):
  File "a3_model.py", line 45, in <module>
    ar_train = data[np.in1d(data[:, 0], filter)]
IndexError: too many indices for array
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
a3_model.py:42: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.
  data = np.genfromtxt(args.featurefile, delimiter=',', dtype=None, unpack = True)
<class 'numpy.void'>
Traceback (most recent call last):
  File "a3_model.py", line 45, in <module>
    ar_train = data[np.in1d(data[:, 0], filter)]
IndexError: too many indices for array
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
  File "a3_model.py", line 44
    print list(row)
             ^
SyntaxError: invalid syntax
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
  File "a3_model.py", line 44
    print list(row)
             ^
SyntaxError: invalid syntax
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
  File "a3_model.py", line 44
    print list(row)
             ^
SyntaxError: invalid syntax
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
<class 'numpy.ndarray'>
/usr/local/lib64/python3.7/site-packages/numpy/lib/arraysetops.py:571: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison
  mask |= (ar1 == a)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
[            nan             nan  1.25698116e+01  7.11666956e+00
  6.72103640e-01  6.00301989e-01 -1.95300283e+00  1.57402432e+00
  2.10112093e+00  1.05639544e+00 -3.68143291e-01 -7.66938640e-02
 -3.47201412e-01  2.19217072e+00  3.03768669e+00  1.20829229e+00
  2.97056091e-01  1.88232334e+00  1.72073307e+00  5.98396894e-01
  2.05640877e+00 -1.63759440e+00 -1.31071539e+00  8.29151666e-01
  4.70058632e-01 -6.94242408e-01  4.04144871e+00  1.52655376e+00
  2.79597585e-01  4.09664641e-01  1.01628311e+00 -2.16110598e+00
  1.73057481e+00 -1.40840588e+00 -2.18088848e+00 -1.02311394e+00
  5.48262048e-01 -3.58579633e-01  2.68813702e+00  6.26226739e-01
  7.03678684e-01 -1.79018074e-01 -1.62419688e+00 -1.10306745e+00
 -7.45586428e-01  7.58321762e-01  6.21099459e-01  9.53821471e-01
 -1.66654737e+00  7.68012040e-01  5.98321415e-01  1.85879160e+00
 -5.97380385e-02 -2.41320972e-01 -2.35287234e-01 -1.34211977e+00
 -4.40365560e-01 -1.13199716e+00  7.02547774e-01 -1.00843030e+00
 -1.81009898e+00  3.21991124e-01  1.98125140e+00  3.28775797e-02
 -5.66995340e-01  6.79603608e-02  1.47498870e+00 -5.26284642e-01
 -1.89482831e+00 -5.16843008e-01  3.18243677e-01 -1.41914140e+00
  6.76416156e-02 -1.13033762e+00  1.47287754e+00  3.01199377e-01
  8.26659251e-01  1.28563257e-01 -4.38001427e-01  1.36733445e+00
  1.45051331e+00 -1.30808429e-01  7.77129098e-01  3.86267146e-02
 -9.13503332e-02 -8.31909984e-01 -2.19713103e+00  1.85374188e+00
  1.05325333e+00  6.08000450e-01  1.04858569e+00  4.98821621e-01
 -1.17644415e+00  5.12187682e-01  2.14841691e-01  2.15852608e+00
 -8.22573071e-01  1.55598431e+00  3.09459465e-02  1.12756933e+00
 -8.77001072e-01  1.22041968e+00  2.96314209e-01  2.52802809e-01
  1.32375167e+00  8.74138029e-01  2.04035973e-01  1.64185794e+00
  3.38611074e-01 -7.53998137e-01 -4.96025009e-02 -3.04644763e-01
 -1.00563987e+00  4.45255881e-01  3.79178840e-01  5.51933424e-02
 -1.10429305e-01  3.67404841e-01 -5.91241419e-01  1.49824263e+00
  1.96979914e+00 -3.42752428e-01  9.12755660e-01  8.51681234e-01
  2.95022768e-01  1.60294080e+00  5.27042862e-01 -7.57455483e-01
 -4.67219656e-01  3.53313046e-01  1.27867884e+00 -6.59526904e-01
  8.63993570e-01  1.39112994e-01 -2.04005467e-01  5.88970126e-01
  1.26039567e+00 -2.22832226e-01 -1.23242644e+00  2.21525993e+00
 -2.49174843e-01 -3.40855958e-01 -5.32572587e-01  2.78710676e-01
 -6.25027259e-01  1.49656541e+00 -7.38154734e-02  3.76849562e-02
  9.00247791e-02  2.24606037e-01 -1.19942960e+00 -3.33058590e+00
  7.24124258e-01  1.07712206e+00  2.98216208e-01 -6.79225619e-02
  5.59348964e-01  7.62962682e-01 -2.80903978e+00 -3.02815349e-01
  1.73014142e+00  1.38069629e-01  4.99274148e-01 -1.47033912e+00
  9.01132165e-01 -1.17928098e+00  7.09686552e-01  2.86712416e-01
  1.51810282e+00 -2.09618793e-01 -5.45075328e-01 -4.30761434e-01
 -7.41436508e-01  6.46796355e-01 -3.42094686e-01  6.20818135e-01
 -8.09459620e-01 -2.66751397e-01 -1.26316277e+00 -9.49234142e-01
 -1.39004962e+00  2.07062593e-01 -7.63808841e-01  1.83282474e+00
 -6.46380063e-01  7.88503675e-01 -1.94189696e-02 -7.23768725e-01
 -1.13963937e+00  1.08738000e+00  4.13491821e-02 -4.79839102e-03
  1.18496456e+00  2.11291126e-01 -4.59598280e-01 -4.67350408e-01
 -2.25917447e-01 -1.29655839e-01  6.90582041e-01  1.04400387e+00
  4.14233004e-01 -1.30508463e+00]
/usr/local/lib64/python3.7/site-packages/numpy/lib/arraysetops.py:571: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison
  mask |= (ar1 == a)
[]
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
      train  mccarty-d  ...  0.4142330037533583  -1.305084634792936
0      test  mccarty-d  ...           -0.013648           -0.415033
1      test  mccarty-d  ...            0.396408            0.248626
2     train  mccarty-d  ...            0.003828            0.008953
3     train  mccarty-d  ...            0.159112           -0.108517
4     train  mccarty-d  ...           -0.149677            0.318996
...     ...        ...  ...                 ...                 ...
2923  train  donohoe-t  ...            0.201126            0.018585
2924  train  donohoe-t  ...            0.140847           -0.209329
2925  train  donohoe-t  ...            0.125075            0.001855
2926  train  donohoe-t  ...            0.022303           -0.044119
2927  train  donohoe-t  ...           -0.174028           -0.134946

[2928 rows x 202 columns]
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
        0          1          2    ...       199       200       201
0     train  mccarty-d  12.569812  ...  1.044004  0.414233 -1.305085
1      test  mccarty-d  -8.443631  ...  0.036827 -0.013648 -0.415033
2      test  mccarty-d  -8.386088  ...  0.270925  0.396408  0.248626
3     train  mccarty-d -10.287848  ... -0.120575  0.003828  0.008953
4     train  mccarty-d -12.165009  ... -0.043131  0.159112 -0.108517
...     ...        ...        ...  ...       ...       ...       ...
2924  train  donohoe-t  -9.629141  ...  0.038196  0.201126  0.018585
2925  train  donohoe-t  -9.029024  ...  0.069299  0.140847 -0.209329
2926  train  donohoe-t  -8.855967  ... -0.007930  0.125075  0.001855
2927  train  donohoe-t -10.706339  ... -0.054549  0.022303 -0.044119
2928  train  donohoe-t  11.300004  ... -0.681583 -0.174028 -0.134946

[2929 rows x 202 columns]
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
0        True
1       False
2       False
3        True
4        True
        ...  
2924     True
2925     True
2926     True
2927     True
2928     True
Name: 0, Length: 2929, dtype: bool
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
        0          1          2    ...       199       200       201
0     train  mccarty-d  12.569812  ...  1.044004  0.414233 -1.305085
3     train  mccarty-d -10.287848  ... -0.120575  0.003828  0.008953
4     train  mccarty-d -12.165009  ... -0.043131  0.159112 -0.108517
5     train  mccarty-d  33.162786  ... -0.307094 -0.149677  0.318996
6     train  mccarty-d -12.175201  ... -0.021838  0.119506 -0.097123
...     ...        ...        ...  ...       ...       ...       ...
2924  train  donohoe-t  -9.629141  ...  0.038196  0.201126  0.018585
2925  train  donohoe-t  -9.029024  ...  0.069299  0.140847 -0.209329
2926  train  donohoe-t  -8.855967  ... -0.007930  0.125075  0.001855
2927  train  donohoe-t -10.706339  ... -0.054549  0.022303 -0.044119
2928  train  donohoe-t  11.300004  ... -0.681583 -0.174028 -0.134946

[2347 rows x 202 columns]
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
        0          1          2    ...       199       200       201
0     train  mccarty-d  12.569812  ...  1.044004  0.414233 -1.305085
3     train  mccarty-d -10.287848  ... -0.120575  0.003828  0.008953
4     train  mccarty-d -12.165009  ... -0.043131  0.159112 -0.108517
5     train  mccarty-d  33.162786  ... -0.307094 -0.149677  0.318996
6     train  mccarty-d -12.175201  ... -0.021838  0.119506 -0.097123
...     ...        ...        ...  ...       ...       ...       ...
2924  train  donohoe-t  -9.629141  ...  0.038196  0.201126  0.018585
2925  train  donohoe-t  -9.029024  ...  0.069299  0.140847 -0.209329
2926  train  donohoe-t  -8.855967  ... -0.007930  0.125075  0.001855
2927  train  donohoe-t -10.706339  ... -0.054549  0.022303 -0.044119
2928  train  donohoe-t  11.300004  ... -0.681583 -0.174028 -0.134946

[2347 rows x 202 columns]
       0          1          2    ...       199       200       201
1     test  mccarty-d  -8.443631  ...  0.036827 -0.013648 -0.415033
2     test  mccarty-d  -8.386088  ...  0.270925  0.396408  0.248626
7     test  mccarty-d -12.174444  ... -0.041690  0.119905 -0.123443
11    test  mccarty-d  -0.422181  ... -0.151828  0.317484 -0.509751
28    test  mccarty-d -10.466471  ... -0.064823 -0.004328  0.085550
...    ...        ...        ...  ...       ...       ...       ...
2909  test  donohoe-t  17.610443  ... -0.861018 -0.293128 -0.110205
2912  test  donohoe-t -12.259460  ...  0.075717  0.161276 -0.061932
2914  test  donohoe-t -11.373855  ...  0.014874  0.151582  0.004391
2921  test  donohoe-t  -8.782898  ...  0.040084  0.135797 -0.106547
2923  test  donohoe-t  -4.862819  ... -0.202486  0.362504 -0.120091

[582 rows x 202 columns]
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 50, in <module>
    ffnn.train(train)
  File "a3_model.py", line 30, in train
    optimizer = optim.SGD(self.model.parameters(), lr=self.lr)
AttributeError: 'AuthorFFNN' object has no attribute 'model'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 51, in <module>
    ffnn.train(train)
  File "a3_model.py", line 31, in train
    data = torch.Tensor(inputs)
ValueError: too many dimensions 'str'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 51, in <module>
    ffnn.train(train)
  File "a3_model.py", line 31, in train
    data = torch.Tensor([inputs])
ValueError: too many dimensions 'str'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
  File "a3_model.py", line 34
    if documents[0;1] == documents[1;1]:
                  ^
SyntaxError: invalid syntax
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 
usage: a3_model.py [-h] featurefile samplesize
a3_model.py: error: the following arguments are required: samplesize
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 5
Reading out.csv...
Traceback (most recent call last):
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexes/base.py", line 2890, in get_loc
    return self._engine.get_loc(key)
  File "pandas/_libs/index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 128, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index_class_helper.pxi", line 91, in pandas._libs.index.Int64Engine._check_type
KeyError: (0, 1)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "a3_model.py", line 57, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 34, in train
    if documents[0,1] == documents[1,1]:
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/frame.py", line 2975, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexes/base.py", line 2892, in get_loc
    return self._engine.get_loc(self._maybe_cast_indexer(key))
  File "pandas/_libs/index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 128, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index_class_helper.pxi", line 91, in pandas._libs.index.Int64Engine._check_type
KeyError: (0, 1)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 5
Reading out.csv...
Traceback (most recent call last):
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexes/base.py", line 2890, in get_loc
    return self._engine.get_loc(key)
  File "pandas/_libs/index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 128, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index_class_helper.pxi", line 91, in pandas._libs.index.Int64Engine._check_type
KeyError: (1, 1)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "a3_model.py", line 57, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 34, in train
    if documents.iloc[0,1] == documents[1,1]:
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/frame.py", line 2975, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexes/base.py", line 2892, in get_loc
    return self._engine.get_loc(self._maybe_cast_indexer(key))
  File "pandas/_libs/index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 128, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index_class_helper.pxi", line 91, in pandas._libs.index.Int64Engine._check_type
KeyError: (1, 1)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 5
Reading out.csv...
0
0
0
0
0
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 5
Reading out.csv...
lenhart-m keiser-k
0
lenhart-m keiser-k
0
lenhart-m keiser-k
0
corman-s quigley-d
0
mccarty-d lenhart-m
0
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 5
Reading out.csv...
        0          1         2    ...       199       200       201
1670  train  quigley-d  9.174360  ... -0.952782  0.308333 -0.018452
1733  train  quigley-d -1.558058  ...  0.281117 -0.083159 -0.268102

[2 rows x 202 columns]
        0            1          2    ...       199       200       201
489   train  salisbury-h   6.727326  ...  0.170898 -0.619896 -0.864806
1973  train    quigley-d -11.623431  ... -0.007244 -0.103156  0.167564

[2 rows x 202 columns]
        0          1          2    ...       199       200       201
65    train  mccarty-d  14.668314  ... -0.651946  1.106573 -1.466704
2365  train  lenhart-m  89.792380  ...  0.187380 -0.073709  0.261057

[2 rows x 202 columns]
       0            1          2    ...       199       200       201
624  train     keiser-k -11.776026  ...  0.046685 -0.080107  0.124047
316  train  schwieger-j  -3.706521  ... -0.567974  0.687731 -0.639691

[2 rows x 202 columns]
        0          1          2    ...       199       200       201
2541  train  lenhart-m -10.093520  ... -0.175099 -0.105902  0.002714
1936  train  quigley-d  -7.585029  ... -0.555521 -0.339894  0.583010

[2 rows x 202 columns]
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 5
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 59, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 38, in train
    documents.drop(df.columns[0,1], axis = 1, inplace=True)
NameError: name 'df' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 5
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 59, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 38, in train
    documents.drop(documents.columns[0,1], axis = 1, inplace=True)
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexes/base.py", line 4284, in __getitem__
    result = getitem(key)
IndexError: too many indices for array
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 5
Reading out.csv...
            1          2         3    ...       199       200       201
2351  lenhart-m -11.167597  2.952538  ...  0.016023  0.022516 -0.032222
1638  quigley-d  -1.297324 -3.078406  ... -0.083353  0.426451  0.237592

[2 rows x 201 columns]
            1          2         3    ...       199       200       201
1697  quigley-d -11.328506  3.058160  ... -0.058327  0.067950  0.019992
2469  lenhart-m  -5.259163  1.585634  ...  0.303788 -0.441218 -0.040272

[2 rows x 201 columns]
            1          2         3    ...       199       200       201
2209  lenhart-m -10.032176  1.714648  ... -0.091170  0.192525  0.109029
2015  quigley-d  -2.843467  3.987055  ...  0.036514  0.061677  0.192292

[2 rows x 201 columns]
            1          2          3    ...       199       200       201
2208  lenhart-m  16.466710 -19.462021  ...  0.205313  0.378597 -0.079230
2817  lenhart-m  51.154373 -67.701382  ... -0.004276 -0.069158 -0.248205

[2 rows x 201 columns]
            1          2         3    ...       199       200       201
1928  quigley-d  13.395158 -1.867070  ...  0.243264 -0.861325 -1.081545
2555  lenhart-m  10.512221 -0.527198  ... -0.024138  0.172279  0.267758

[2 rows x 201 columns]
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 5
Reading out.csv...
           2         3         4    ...       199       200       201
1249 -9.311575  4.239359  2.810622  ...  0.044539  0.339916  0.063934
1411 -8.862423  3.503601  2.017454  ...  0.180977 -0.001679  0.051714

[2 rows x 200 columns]
            2         3         4    ...       199       200       201
105    1.874776  2.334584 -1.281326  ...  0.057976  0.216506 -0.405392
1652 -11.285780  3.461972  2.181494  ...  0.064335  0.006614  0.048320

[2 rows x 200 columns]
           2         3         4    ...       199       200       201
2744 -6.594307 -0.337375  0.343578  ... -0.176864  0.002402  0.244475
1118  0.483647  3.234165 -2.634922  ...  0.353342 -0.319278 -0.250020

[2 rows x 200 columns]
            2         3          4    ...       199       200       201
1530  -3.335216 -0.751076   1.515463  ... -0.289744 -0.744870  0.035265
1518  38.548848  3.238481 -11.049594  ... -0.397950  0.489465 -0.065099

[2 rows x 200 columns]
            2          3         4    ...       199       200       201
1468  -6.929073   0.491048 -0.208912  ... -0.040474 -0.065182 -0.138429
2250  21.176352 -16.749201 -4.254752  ... -0.024926  0.038506  0.158431

[2 rows x 200 columns]
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 5
Reading out.csv...
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 5
Reading out.csv...
tensor([-1.0039e+01,  2.9369e+00,  1.1601e+00, -1.0398e-01,  5.8566e-01,
         1.9923e-01,  7.3356e-01,  7.1924e-01, -7.8232e-01,  6.9076e-01,
        -5.9078e-02,  8.1044e-01,  1.0245e-01,  1.1923e+00,  1.0494e-01,
         6.9030e-01,  6.7478e-01,  6.2553e-01,  1.5194e+00,  6.7267e-01,
        -1.5217e+00, -8.3730e-01, -5.7262e-01, -1.0774e+00, -1.8081e+00,
        -2.2493e-01,  1.7704e-01, -9.9103e-01,  1.3715e+00,  1.5790e-01,
         3.6945e-02,  3.1526e-01, -5.7518e-01,  1.3735e+00,  1.8493e+00,
        -6.7409e-02, -7.6104e-01, -9.8559e-01, -1.0484e+00, -2.7155e-01,
         5.0178e-01,  8.0605e-01, -4.7028e-01, -1.4070e-01, -2.8538e-01,
         1.3621e-01, -9.9033e-02,  3.6763e-01, -1.6264e-02,  6.7212e-01,
         2.3628e-01, -5.1302e-01, -1.7469e-01, -6.6339e-01,  2.9627e-01,
        -6.7866e-01,  2.2407e-02, -5.3908e-01,  3.7000e-01,  3.7362e-01,
         1.1577e-01,  4.5300e-01,  1.0995e-01, -8.0211e-01, -8.6227e-01,
         2.5575e-01,  1.0709e-01,  5.3193e-01,  7.0459e-01, -4.1161e-01,
        -1.8125e-01, -1.0276e+00, -1.3360e+00, -3.1689e-02,  4.8817e-02,
         1.2180e-01, -2.9253e-02,  6.5238e-02, -6.7123e-01,  5.0701e-01,
         1.7608e-01, -4.2658e-01, -1.4690e-01,  1.7797e-01, -6.5179e-01,
         2.5222e-01, -3.5758e-01, -3.7581e-01,  4.8459e-01,  7.8087e-01,
        -6.1039e-01, -4.2840e-01, -6.0601e-01,  1.3418e-01,  1.0296e-01,
         9.9606e-02,  6.0471e-01, -7.4335e-01,  1.1420e-01,  5.9349e-02,
        -1.9327e-01,  6.5098e-03, -2.5142e-01,  3.5792e-01,  4.1619e-01,
        -1.5551e-01,  7.0665e-02,  4.9876e-01, -6.4110e-01,  2.3769e-01,
        -6.7414e-01, -2.2263e-01,  3.2895e-01, -7.3510e-02,  1.2055e+00,
        -9.3205e-01,  9.1677e-01,  2.5118e-01, -6.5067e-01,  4.6914e-01,
         1.2061e-01,  6.9385e-01, -8.5315e-03,  6.6550e-01,  2.0280e-01,
        -4.0137e-01,  3.2600e-02,  1.6512e+00, -1.1293e-01,  6.2599e-01,
         6.0644e-01,  2.9706e-01, -4.8688e-01, -8.8089e-01,  1.5084e+00,
         2.2744e-01,  1.0846e+00, -1.6896e-01,  8.6716e-01, -2.6081e-02,
        -4.3405e-01, -7.5479e-02,  1.6552e-01, -3.7270e-02, -3.7694e-01,
         2.0245e+00,  4.4830e-01, -2.8647e-01,  2.1548e-01,  4.1212e-02,
         3.0633e-01, -6.4531e-02,  5.4636e-02, -4.7938e-01,  1.5873e-01,
         1.7633e-01,  1.0014e-01, -8.0641e-01,  1.1972e-03,  1.4751e-01,
        -2.4435e-02, -1.7227e-01, -1.7763e-01, -3.0376e-01,  1.0130e-01,
         5.4845e-01, -1.3983e-01,  3.0049e-01,  1.2290e+00,  8.4587e-02,
        -3.8800e-01, -2.0730e-03, -2.8066e-01,  4.7044e-01, -2.0386e-01,
        -3.6372e-01, -2.5142e-01, -7.8525e-02,  1.1778e-01, -3.6539e-01,
         2.3704e-01,  6.4701e-02,  2.1575e-01, -4.0164e-01, -3.9592e-01,
         5.6899e-01, -8.0878e-02, -2.5307e-01,  3.8973e-01, -5.6429e-01,
        -2.6336e-01,  3.1257e-01, -5.7720e-01, -6.0032e-01, -1.1151e-01,
        -3.0031e-01,  2.1701e-01, -4.1975e-01, -3.2785e-01,  5.1605e-01])
tensor([-8.8895e+00,  3.3139e+00,  1.3708e+00,  1.5122e+00,  1.7342e-01,
        -7.3053e-02,  3.1127e-01,  1.0279e+00, -8.1414e-01,  5.9867e-01,
         9.4628e-01, -5.3402e-01,  3.0322e-01,  9.7007e-01,  7.6760e-01,
        -8.3597e-01, -6.2546e-01,  7.5532e-02, -5.2056e-01,  5.5395e-01,
        -8.8931e-01,  3.5737e-01,  1.6773e-01,  2.0617e-01,  2.2566e-01,
        -5.0993e-01,  5.7727e-01,  1.3468e-01,  8.4245e-01, -4.6361e-01,
        -4.1150e-01, -7.5372e-01, -3.5565e-01,  4.1757e-01,  5.7093e-01,
         5.8273e-02, -5.2916e-01, -8.3945e-01,  4.2623e-02,  1.5897e+00,
         1.0009e+00,  1.3515e-01,  7.8137e-01, -1.8537e-01,  7.7043e-01,
        -7.8005e-01,  5.4885e-01, -2.3360e-01,  6.7080e-01,  1.1075e-01,
         4.9540e-01, -1.4446e-01, -4.0201e-01,  1.3319e-01, -2.9848e-02,
        -8.1473e-02, -1.0681e+00, -7.0220e-01,  1.4290e-01, -8.2241e-02,
         9.9527e-02,  1.9541e-01,  2.9129e-01,  2.4933e-01, -9.9439e-02,
         8.8353e-03,  3.9239e-01, -3.2075e-01,  6.2527e-01, -8.8000e-01,
         2.3730e-01, -1.0790e+00,  1.1952e-01,  4.4044e-01,  2.7839e-01,
         2.1208e-01,  2.1364e-01, -1.3765e-01,  2.8885e-01,  2.2134e-03,
         5.5603e-01, -4.6084e-01, -1.0391e-01,  2.0671e-01, -3.2534e-01,
         4.4484e-02, -2.0738e-01,  7.1367e-01, -7.5578e-03, -5.8205e-01,
        -1.6816e-01,  8.9673e-01,  1.3422e-02, -3.3538e-01, -1.7117e-01,
        -3.7371e-01,  2.4664e-01,  7.0674e-02,  7.8267e-02,  3.8315e-01,
        -2.3595e-01,  2.3668e-02, -4.5486e-01, -1.5074e-01,  2.9737e-01,
        -1.8283e-01, -1.6137e-01, -3.0445e-02,  2.2726e-01,  6.0520e-01,
        -4.3160e-02,  5.1594e-01, -1.2344e-01, -7.8278e-02, -7.6531e-02,
         1.1852e-01,  3.2250e-02, -2.4500e-01, -3.4330e-01, -2.1129e-01,
         2.8762e-01, -2.8528e-02, -6.6609e-02, -4.1417e-01,  2.7585e-01,
        -4.7990e-02, -1.6560e-01,  2.3563e-01,  2.7700e-02,  6.7075e-01,
         2.4092e-02, -1.3251e-01, -1.3883e-01,  3.0535e-01, -2.2699e-01,
        -2.8387e-02,  2.7969e-01,  5.2237e-01, -1.2991e-01,  6.1979e-01,
        -1.0652e-01, -3.9228e-01, -3.3112e-01,  1.6323e-01, -2.5923e-01,
        -5.7080e-02,  2.5702e-01,  1.8254e-01,  4.4944e-01,  7.4513e-02,
        -3.5775e-01,  2.2960e-01,  2.8058e-01,  8.7494e-04,  1.9656e-01,
        -8.4893e-02, -2.8366e-03,  2.0526e-01, -1.3632e-01, -1.7961e-01,
         1.5357e-01, -1.0212e-01,  1.6915e-01, -1.8378e-01,  1.4951e-01,
         1.5100e-01, -2.4465e-01, -5.1789e-02,  7.0025e-02,  1.4019e-02,
         1.6881e-01,  1.9457e-01,  1.7352e-01,  8.4313e-02,  3.9029e-02,
         3.6065e-01, -2.0396e-01, -4.3962e-02, -8.7406e-03,  8.5271e-02,
        -3.1292e-01,  7.8591e-02, -3.3966e-01,  1.7442e-01,  1.0757e-01,
         3.0651e-02, -1.4264e-01, -3.1536e-01,  3.2813e-01, -1.3661e-02,
         2.8792e-01, -2.3180e-01,  4.7891e-02,  1.0559e-01,  1.9977e-01,
        -2.6520e-02, -8.7568e-02,  7.2293e-02,  9.8968e-02,  2.4881e-01])
tensor([ 2.2128e+01,  3.3391e+00, -7.3624e+00,  2.0248e+00, -1.6380e+00,
         2.4971e+00, -4.8702e+00,  7.2131e-01,  2.4404e+00, -8.7141e-01,
         1.8312e+00, -6.7965e-01,  1.9993e+00,  8.8091e+00,  6.0798e-02,
         5.4334e-01,  8.1951e-01,  8.1118e+00, -3.3638e+00,  3.0346e+00,
        -2.1182e+00,  2.0971e+00,  1.7333e+00,  1.2696e+00, -2.8577e+00,
        -2.2013e+00,  1.7556e+00, -3.4173e+00, -2.3455e+00, -2.6799e+00,
        -1.7061e+00, -3.2455e-01, -2.4504e-01,  9.8934e-01,  8.4216e-01,
        -2.8874e-01, -1.3081e-01,  2.6544e+00,  3.3087e-01, -2.3865e+00,
         9.0000e-01, -2.1861e+00, -2.1662e+00, -6.6467e+00, -9.4139e-01,
         2.2973e+00,  7.7588e-01, -8.7962e-01, -3.4974e+00, -3.1282e-01,
         1.8786e+00,  3.6262e-01, -3.0038e+00, -1.3942e+00,  3.4752e-01,
         1.7478e+00,  4.9011e+00,  9.3313e-01, -1.6837e-01,  4.0873e-01,
         1.1085e+00, -3.9001e+00,  6.2610e-01, -1.5671e-01, -3.9016e+00,
        -1.4122e-01,  3.3088e+00,  2.1221e+00,  3.4044e+00, -1.8955e+00,
         6.5062e-01, -2.9991e-01,  5.4393e-01,  6.0356e-01, -2.1331e+00,
        -1.4583e-01,  1.6054e+00,  1.7625e+00,  8.9665e-01, -2.3789e-01,
         1.8920e+00,  2.5294e+00, -1.3181e+00, -9.7175e-01,  7.5102e-01,
         1.5688e+00, -1.2187e+00,  1.4340e+00,  3.8006e-01, -9.3219e-01,
        -1.3388e+00, -1.9572e-02,  4.4582e-01, -7.7895e-01, -8.6915e-01,
        -8.0832e-01,  8.7399e-01,  6.7590e-01,  1.0511e+00,  8.6407e-01,
        -1.6614e+00, -6.9238e-01,  8.6246e-02, -9.1090e-01,  9.7171e-02,
        -1.0295e+00,  2.3115e-02, -1.6133e-01,  5.8478e-01, -1.3166e-01,
        -5.0077e-01, -2.3022e-01,  9.3808e-01, -1.4924e-01, -1.9588e+00,
        -1.5695e+00,  4.0955e-01, -6.2324e-01,  2.7237e-02,  1.0750e+00,
         2.6655e-01, -5.8342e-01,  2.3826e-01, -3.5706e-01,  2.0226e-01,
        -5.2146e-01, -8.6617e-02, -1.2847e+00, -7.1761e-01, -8.6564e-01,
        -8.8342e-01, -4.6508e-02,  1.0253e+00, -1.0494e+00, -1.6569e-01,
         1.2182e-01, -7.1356e-01,  1.8637e-01, -1.5122e-01, -4.8729e-01,
        -8.4645e-01, -1.6758e-01, -1.8162e-01, -5.2642e-01, -1.7629e-01,
         2.0379e-01, -5.4586e-02, -1.3815e-01, -2.4775e-01,  8.4131e-01,
         8.5455e-02, -6.3708e-03, -4.0813e-01, -4.5886e-01, -2.1587e-02,
        -4.0054e-01,  2.2012e-01,  3.4363e-02,  4.6823e-01, -2.3735e-01,
         4.4217e-01,  6.6695e-01, -2.5446e-01, -4.0818e-01, -8.6660e-01,
        -1.0538e-01, -8.9422e-02,  5.7895e-02, -8.0090e-02, -3.4101e-01,
         5.8301e-01, -5.6795e-02,  1.4031e-02,  2.1618e-01, -2.0167e-01,
        -5.6111e-01, -7.5651e-01, -3.0149e-01, -4.2146e-01, -8.0074e-01,
        -3.0318e-01,  1.7014e-01,  2.8693e-02,  4.8180e-01,  6.8940e-02,
         1.8695e-01,  2.3056e-01,  7.2310e-02, -5.5587e-01,  6.9694e-01,
        -9.5074e-01, -1.7128e-01,  2.1833e-01,  2.7421e-01,  5.2289e-01,
         5.8445e-01,  5.7008e-01,  5.5098e-01,  2.5805e-01, -6.2008e-02])
tensor([-3.6477e+00,  1.5811e+00, -1.2471e+00,  8.2173e-01, -1.3787e+00,
         2.3846e-01,  1.9379e+00,  1.5260e+00,  2.7296e-01,  6.1775e-01,
         2.4021e-01,  6.9438e-02,  1.1081e-01,  9.7074e-01, -2.0900e+00,
         2.5493e-01,  1.8586e-01,  1.3890e+00, -3.3962e-01,  1.2417e+00,
        -9.0520e-01, -6.2862e-02,  2.9466e-01,  7.8379e-01, -3.0522e-01,
        -2.5597e+00,  4.1969e-01, -9.3233e-01,  9.4269e-01, -1.4154e+00,
         2.8464e-01,  1.3314e+00, -1.5180e-01,  4.2165e-01,  1.0359e+00,
        -1.2756e+00, -9.7004e-01, -4.9240e-01, -5.1907e-01,  8.0574e-01,
        -5.1432e-01,  9.2436e-01,  8.3625e-01, -1.9639e+00, -5.1631e-02,
         4.5021e-01,  7.3305e-01,  8.5950e-01,  2.7957e-01, -1.0542e+00,
        -5.3939e-01, -1.0251e-01, -1.3521e+00,  9.7532e-03,  8.7226e-01,
         3.3339e-01, -4.3534e-01,  2.7299e-01,  7.9978e-01,  3.5206e-01,
         9.4847e-02, -1.0344e+00,  1.6934e-01, -4.4851e-01, -3.6804e-01,
         3.0952e-01, -6.1241e-01,  6.1972e-02, -1.2133e+00, -4.1868e-01,
         6.0667e-01, -5.3505e-01,  3.1167e-01,  4.4587e-01, -3.2003e-01,
         4.4406e-02,  3.2700e-02,  3.3369e-01,  1.8225e-02, -1.4707e-02,
        -3.7783e-01,  8.2361e-01,  8.9423e-02,  4.0045e-01, -1.0685e+00,
         2.0203e-01,  4.4739e-01,  1.4888e-02, -6.3898e-01,  8.2027e-02,
         3.5859e-01, -1.5546e-01, -5.0824e-01,  8.2970e-01, -2.2903e-01,
         2.0943e-02, -4.0985e-01, -5.5034e-01,  8.4102e-01, -1.0903e+00,
         1.2329e-01,  5.2332e-01,  5.5940e-01,  3.9399e-01,  1.5553e-01,
         1.7646e-01, -1.5075e-01,  6.1782e-02, -5.6910e-01,  2.6687e-01,
        -1.8272e-01, -6.8006e-01, -1.6047e+00,  1.9114e-01,  1.1957e+00,
         2.8052e-01,  1.1582e-01, -7.2836e-02, -7.6082e-01, -3.3922e-01,
        -1.0601e-01, -6.2450e-01,  5.1977e-03, -6.8717e-01, -6.9474e-02,
         2.8562e-01, -8.4155e-02,  2.6821e-01,  4.8124e-01,  2.2652e-01,
         6.7930e-01, -6.7424e-01,  6.7556e-01,  6.3674e-01,  2.0553e-01,
         5.5228e-01,  5.2012e-01, -1.0219e-01,  3.3932e-01, -5.6890e-02,
         2.4652e-01,  1.2365e-01, -3.1439e-02, -1.6100e-01,  2.9517e-01,
         4.3374e-01,  1.1481e-01,  5.1583e-01,  3.0521e-01,  4.6167e-02,
         2.0522e-01,  7.1803e-01,  3.5209e-01, -1.9440e-01, -1.3490e-01,
        -4.9758e-01, -2.3618e-01,  1.6500e-01,  5.3013e-01,  3.5201e-01,
         9.9391e-01, -1.8979e-02, -5.7154e-01, -2.9243e-01,  2.8057e-01,
        -5.3287e-02,  1.7219e-01,  5.0950e-01, -6.1954e-01, -1.1853e+00,
         1.7592e-01, -5.4534e-01,  8.8114e-04,  5.1567e-02, -1.3355e-01,
        -6.5111e-02,  3.3446e-01,  5.5698e-01, -3.5790e-01,  1.7785e-01,
        -1.7546e-01, -2.8785e-01, -4.0662e-01, -4.0537e-01, -3.4591e-01,
        -1.2274e-01,  1.6950e-01,  7.4587e-01, -9.5215e-02,  3.4325e-01,
         1.6310e-01, -2.9443e-01, -4.6958e-01,  3.9560e-01,  7.1908e-01,
         1.1227e-03, -1.3518e-02,  2.8764e-01,  6.1688e-01, -1.5792e-01])
tensor([ 3.1111e+00,  3.9820e+00, -1.3424e+00,  2.4173e+00,  9.5446e-01,
         3.0124e-01, -1.8833e+00,  3.6295e-01,  2.0904e-01,  9.7690e-01,
         5.9241e-01, -6.0873e-01,  1.6327e+00,  8.5422e-01,  1.7139e+00,
        -1.8147e+00, -2.4312e+00, -8.3516e-01, -1.1324e+00,  3.2219e+00,
         1.0883e-01, -3.0415e-01, -1.0571e+00, -9.7542e-01, -1.2586e+00,
         5.6481e-02, -8.5150e-01,  1.9635e+00,  7.6658e-01,  1.0464e-01,
        -1.0373e+00, -3.3443e-01,  5.3298e-01, -2.8219e-01, -2.4839e+00,
         1.7996e+00, -5.0513e-01,  6.7902e-01, -9.1113e-02, -4.4063e-01,
         1.5698e+00, -7.7585e-01, -4.4666e-01, -5.3894e-01,  8.2538e-02,
        -2.5747e-01,  9.7640e-01, -1.2302e+00, -6.2073e-01,  1.0066e+00,
         9.5310e-03,  8.1850e-01,  2.0272e-01, -1.6882e+00, -1.3257e-01,
         5.0920e-01,  3.2122e-01,  2.0673e-01, -1.4034e+00, -1.6208e+00,
         1.3498e-01,  9.4362e-01, -7.5154e-01,  2.4762e-01, -1.9730e-01,
        -3.2567e-01,  3.2105e-01, -8.8956e-02, -4.2184e-02,  1.0540e-01,
        -6.3650e-01, -2.4455e-01, -3.8915e-01,  4.0986e-01,  5.3002e-01,
        -5.0984e-01,  4.6945e-01,  4.4941e-01, -3.9428e-01, -2.0241e-01,
         4.2273e-01, -6.0321e-01, -2.7859e-01,  2.4920e-01,  7.3866e-01,
         5.4842e-01, -7.0107e-01,  1.5700e-01,  3.7664e-01, -2.9093e-01,
         7.7343e-01, -3.0994e-01,  1.3347e-01,  6.4687e-01,  5.0430e-01,
        -7.0051e-01,  5.3807e-01,  1.8206e-01, -1.4034e-01,  1.6556e-01,
         3.3659e-01, -9.6681e-01,  2.3068e-01, -7.9820e-01, -4.7389e-01,
         5.4417e-01, -4.5838e-01, -2.3448e-01,  1.4213e+00, -7.2673e-01,
        -3.9208e-01,  1.9201e-01,  5.7950e-01,  2.2491e-01, -3.2002e-01,
        -6.1500e-01, -1.4560e-01,  6.3290e-01,  1.0372e-03,  6.0300e-01,
         3.6031e-01,  8.6433e-01, -2.8831e-01, -1.7949e-01,  8.9469e-01,
         9.8885e-01,  4.6518e-02,  8.6621e-02, -4.0922e-01,  1.0339e+00,
         8.1970e-01,  1.9267e-01,  3.9842e-01, -5.5546e-01, -8.7678e-01,
        -2.9655e-01, -3.6048e-01, -5.3411e-04, -9.1354e-01,  1.1449e+00,
         1.4256e-01,  2.2486e-01, -6.0588e-01,  7.7682e-02,  5.2781e-01,
        -4.0948e-01,  3.1659e-01,  6.6975e-01, -2.0021e-01, -5.0928e-01,
        -8.7947e-01, -1.6181e-01,  2.0304e-01, -4.0187e-01, -1.9005e-02,
         7.3003e-01, -8.6319e-01, -5.1308e-01, -1.3248e-01,  5.8485e-02,
        -1.5134e-01, -4.5732e-01, -4.4544e-01,  2.6844e-01, -1.7836e-01,
        -1.2428e-01, -9.0265e-01,  5.5331e-01,  4.6996e-01,  2.5837e-02,
        -4.8286e-01,  3.7793e-01,  7.0964e-01,  4.8676e-01, -1.1255e+00,
         1.2203e-01, -9.8635e-01,  3.7953e-01,  5.9932e-01, -5.9222e-01,
         4.2166e-01, -4.1742e-01,  1.3121e-01, -7.4985e-01, -4.5446e-01,
         2.8345e-01,  5.4799e-01, -6.4843e-01, -5.0443e-01,  6.7782e-02,
        -4.8491e-01,  2.2515e-02,  1.5513e-01, -5.1949e-01, -6.2515e-03,
         7.4406e-01, -4.0275e-01, -3.9307e-01,  2.9463e-01, -7.5981e-01])
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 5
Reading out.csv...
(tensor([ 1.5316e+01,  3.2530e+00, -3.9125e+00,  3.6576e+00, -1.8902e+00,
        -2.9863e+00,  1.9176e+00,  7.4125e-01, -1.4569e+00,  4.2933e-01,
         4.1487e+00,  1.4910e+00,  2.6681e+00, -8.0646e-01, -1.6342e+00,
        -2.0758e+00,  2.7688e+00, -5.3270e-04, -1.8278e+00,  1.3784e+00,
        -1.0191e+00,  5.3815e-01,  3.4283e-01,  9.5250e-02, -3.0212e+00,
         1.3734e-02, -1.1787e+00,  3.4583e-01,  1.2904e+00, -6.5327e-01,
         1.7558e+00, -7.8850e-01,  2.6188e+00, -7.7269e-01, -6.4065e-01,
        -4.9204e-01,  2.6434e+00, -2.7078e+00, -1.2804e+00, -2.3499e-01,
         1.6373e+00,  9.2794e-01, -9.2041e-01, -7.0752e-02,  1.7942e-01,
         1.4807e+00,  2.0426e+00,  8.3475e-01, -1.5156e+00, -8.7420e-02,
         1.8418e+00,  2.6704e+00, -5.1512e-01,  8.8844e-01,  8.8279e-01,
         2.0039e+00,  3.2465e-01,  1.0559e+00,  2.8720e-01, -2.3695e+00,
        -6.8256e-01, -7.8122e-01,  2.5635e-01, -3.8381e-01, -5.0023e-01,
         1.2779e+00, -1.1718e+00,  4.8811e-01,  6.9807e-01,  1.8137e-01,
         8.9180e-01,  2.8676e-01,  1.1133e+00,  2.2886e-01,  4.0529e-01,
         9.0171e-02, -8.5253e-01,  6.6824e-01, -7.8804e-01,  4.3318e-01,
        -1.5788e+00,  6.3630e-01, -1.8274e-01,  1.3092e+00, -1.3050e+00,
        -1.1351e+00,  4.9401e-01,  1.2202e+00, -2.9240e-01,  1.8887e-01,
         7.4000e-01, -2.9650e-01, -5.8809e-01, -2.0389e-01, -7.5475e-01,
        -4.1257e-01,  4.1809e-01,  7.4372e-01, -1.1004e-01, -1.0200e-01,
        -1.0110e+00,  8.1978e-01, -7.6236e-01, -7.8718e-02, -1.5491e+00,
         3.1952e+00,  9.1985e-01,  8.8806e-01,  2.2048e-01,  5.5567e-01,
        -3.4970e-01,  1.5540e-01,  1.4768e+00, -1.2628e+00, -3.7236e-01,
        -3.9949e-01, -9.4967e-01, -4.0922e-02, -3.0587e-01, -7.7694e-01,
        -1.0084e-01,  4.3792e-01, -2.8354e-01, -9.5095e-01,  8.0524e-01,
         4.4174e-02,  9.5737e-01,  7.8598e-01, -7.9434e-03,  7.9142e-01,
        -5.4942e-01,  1.1080e+00, -1.0093e+00, -5.3704e-01, -4.0040e-01,
         3.5291e-01,  6.5448e-01,  7.4121e-01, -2.8937e-01, -5.2926e-01,
        -2.1760e-01,  1.1702e+00,  3.5704e-01, -3.8391e-01, -3.4629e-01,
        -5.6261e-01, -7.0956e-01, -2.0445e-01,  5.1133e-01,  2.7315e-01,
        -5.2783e-01,  1.5171e+00,  8.7820e-01,  4.3293e-01, -1.1303e+00,
        -1.3622e-01, -1.0192e-01,  2.1663e-01, -1.2866e-01, -1.2735e+00,
        -4.9979e-01, -5.4655e-01, -4.0037e-01,  8.7144e-01, -1.4341e+00,
        -3.8551e-01,  1.8400e-02,  5.4684e-02, -8.2715e-01,  1.1754e-02,
         5.2456e-01, -2.4593e-01, -2.0281e-01,  5.2429e-01,  1.4912e+00,
         2.2119e+00, -1.7301e+00, -6.2340e-01,  3.8441e-01, -1.7786e+00,
         1.2733e+00, -1.2399e-01,  3.9153e-01,  5.7156e-01, -3.5916e-01,
        -1.2583e+00,  4.6050e-01,  3.8232e-01,  4.6419e-01, -8.5381e-01,
         6.5195e-01,  1.6973e+00,  1.1616e+00,  1.0138e+00, -5.5382e-01,
         4.9209e-01, -1.0529e+00, -8.2204e-02, -6.5040e-01,  3.2742e-01,
        -1.0514e+01,  1.7437e+00,  1.7867e+00,  7.8462e-01,  3.3103e-01,
        -1.2089e-01,  4.3101e-01,  7.3286e-01, -2.3059e-01,  2.9415e-01,
        -7.3587e-01, -3.8089e-01,  1.6909e-01, -4.9444e-01,  1.1636e-01,
        -5.1240e-01, -7.3506e-01, -1.5524e-01, -7.8250e-01,  2.8926e-01,
        -7.0309e-01, -1.9530e-01, -7.7758e-02, -5.0438e-01,  1.3403e-01,
        -1.6815e-01,  3.9491e-01,  7.3416e-01,  6.1454e-01, -1.0750e+00,
        -5.1489e-01, -3.0185e-02, -4.2495e-02,  8.8046e-01,  1.6898e-01,
        -6.2375e-01, -1.3176e+00,  8.3174e-02,  5.7607e-02,  5.9589e-01,
         6.5900e-01,  8.7619e-02,  6.4360e-01, -8.6658e-01,  5.3966e-02,
        -6.6472e-01, -2.0581e-01, -9.3393e-02, -1.5737e-01,  2.9020e-02,
         1.0717e-01, -2.3563e-01, -3.6456e-01,  1.0408e-01, -2.1526e-01,
         2.1517e-01, -4.2765e-01, -8.4062e-01,  2.0231e-01,  6.3684e-02,
         3.5683e-01,  2.5031e-01,  1.2147e-01,  2.1761e-01, -4.1312e-01,
        -1.0778e-01,  4.1902e-01, -3.6851e-01,  1.4558e-01,  1.2422e-01,
         2.5578e-02, -2.3482e-01, -6.2258e-02, -3.9137e-02,  3.8542e-02,
        -2.2663e-01,  1.3302e-01,  1.1361e-01, -6.8278e-02,  1.2200e-01,
        -2.8561e-02, -3.7579e-01, -4.4239e-02,  3.9244e-01, -1.7722e-01,
        -3.4861e-02,  1.2754e-01, -1.2652e-01,  1.2895e-01,  2.2051e-01,
         7.2986e-02,  8.7814e-02,  2.5312e-02,  2.4894e-01, -3.0073e-01,
         1.9010e-01, -7.5231e-02, -2.2403e-01,  2.0125e-01,  2.0795e-01,
        -4.8310e-02, -6.8155e-02,  4.4450e-02, -2.1664e-02,  4.5653e-02,
        -2.7623e-01, -7.9462e-03, -2.4869e-01,  2.9181e-01, -2.3503e-01,
        -2.2981e-01, -4.0168e-02,  1.2982e-01,  1.1134e-01,  8.0559e-02,
        -7.4367e-02,  2.2404e-01, -2.5109e-01, -1.9750e-01, -4.8611e-02,
        -1.4601e-02,  1.0535e-01, -1.7861e-01, -1.4486e-01,  2.3241e-01,
        -5.3114e-02, -1.0146e-01, -5.0113e-01, -4.3301e-01,  2.1428e-01,
         1.5975e-02, -1.4431e-01,  4.2070e-03,  2.3598e-02,  4.1198e-02,
         1.3500e-01,  8.0659e-02,  9.1640e-02, -5.6138e-02, -2.2720e-01,
        -1.9534e-01, -1.9543e-01, -2.7259e-01,  1.3853e-01, -2.1519e-02,
        -1.2818e-01,  5.5943e-02,  5.0734e-02, -9.0012e-02,  2.1827e-02,
        -1.0003e-01, -1.5148e-01, -3.1442e-02,  2.0494e-02,  1.9486e-01,
        -6.1218e-02,  8.7366e-02,  4.2108e-02,  1.3652e-01,  1.5926e-01,
         3.0135e-01,  7.8080e-02,  5.0351e-02, -9.2057e-02,  2.9638e-02,
        -2.2210e-03, -6.2258e-02,  1.8287e-02, -1.8606e-01, -1.3972e-01,
        -1.8404e-02,  8.9866e-02,  2.6143e-01,  2.1527e-01, -1.2237e-01,
         1.8274e-01, -9.6774e-02, -1.8904e-01, -1.7860e-01, -6.1228e-02,
         8.5090e-02,  9.6345e-02, -4.8131e-03,  4.7769e-02,  6.2655e-03,
         2.4813e-01,  1.0025e-01,  2.4029e-02, -2.0271e-01,  2.8396e-02,
        -3.9586e-02,  9.2055e-02, -4.6281e-03, -1.8754e-02, -2.3733e-02,
         1.8433e-01,  2.1339e-02,  8.1157e-02, -1.2973e-01, -3.6689e-02]), 0)
(tensor([-1.0226e+01,  2.8110e+00,  2.2932e+00,  7.8955e-01, -1.6482e+00,
         3.0639e-01,  6.6252e-01,  6.0753e-02, -1.9961e-01, -3.2952e-01,
        -5.4320e-01,  5.4235e-01,  9.8744e-01, -6.1576e-01,  6.0318e-01,
        -4.0984e-01, -3.9775e-01,  2.2637e-01,  1.1485e+00, -1.4076e-01,
        -8.5673e-01,  1.0396e-01,  3.4793e-01,  1.5616e+00,  9.0315e-01,
        -1.4370e-01, -4.8311e-01,  1.3723e+00, -9.2412e-01, -2.7406e-01,
         5.3206e-01, -2.4880e-01,  1.1781e+00, -5.4123e-01, -6.4562e-01,
        -1.4588e-01,  1.1916e-02,  3.7878e-01, -5.4505e-01, -4.2522e-01,
         1.0872e+00, -4.1163e-01, -2.2415e-01,  5.2011e-01, -1.7813e+00,
         4.5331e-01,  6.2236e-01,  1.0296e-01,  3.7901e-01, -9.3980e-02,
        -2.3315e-01, -1.9323e-01,  4.6241e-01, -3.7389e-01,  1.3728e-01,
         6.8039e-02,  1.9375e-01, -5.4793e-01, -6.1319e-02, -2.1282e-01,
        -7.1389e-01,  4.7341e-01, -1.4911e+00, -1.2420e-01,  1.0063e-01,
        -1.1535e+00,  6.9521e-01,  4.6454e-01, -8.8927e-01, -5.1154e-01,
         9.2695e-02,  7.5255e-01,  3.9939e-01, -2.3014e-02,  1.2176e-01,
        -2.7656e-01, -4.7922e-02, -2.1096e-01, -1.0169e-01, -1.0705e-01,
         5.3585e-01, -2.8942e-01, -4.3248e-01, -3.1204e-01,  2.7659e-01,
        -2.4612e-01,  3.5717e-03,  5.7474e-01, -1.0578e-01,  4.3393e-01,
        -4.4046e-02,  1.2714e-01, -1.2365e-01,  2.2462e-01,  1.3669e-01,
        -1.4664e-01,  5.6474e-02, -2.1166e-01, -2.8448e-01,  3.4337e-01,
        -3.9038e-01,  1.0627e-01,  2.3429e-01,  6.6131e-02, -4.0758e-02,
         2.8328e-01, -3.1955e-01,  2.2438e-01,  5.2058e-02, -1.6231e-01,
        -9.4868e-02, -1.0138e-01, -1.0322e-01, -4.9679e-01, -1.0932e-01,
        -2.9684e-01,  2.2933e-01,  4.1101e-02, -6.7585e-02,  4.0079e-04,
         7.2257e-01,  1.7979e-02, -2.0189e-01, -2.4989e-01, -2.1494e-01,
         1.5083e-01, -1.9770e-02,  5.8483e-02, -6.1886e-02,  1.5707e-02,
         1.7623e-01, -1.1751e-01, -2.1237e-02, -9.6441e-02, -8.6133e-02,
        -2.3563e-01, -3.6349e-01, -1.3236e-01, -2.2196e-01, -6.5094e-02,
         1.7209e-01, -2.4650e-01, -8.8343e-02, -5.7069e-02, -2.6568e-01,
         2.5491e-02,  5.0426e-01,  4.2152e-02, -1.5446e-01, -6.3889e-02,
        -3.8621e-02, -2.5344e-02, -2.1988e-01, -1.5557e-01, -2.3934e-01,
        -1.3966e-01, -1.3786e-01,  1.6096e-01,  2.7911e-01, -2.6894e-02,
        -2.1007e-01, -1.4423e-01,  3.0885e-02, -1.4756e-01,  2.3108e-01,
         1.2807e-02, -1.7330e-01,  8.9855e-02,  1.0940e-01,  1.9839e-01,
         2.6136e-01,  2.2968e-01, -2.8566e-01, -2.4566e-01,  1.4337e-01,
         6.0862e-02,  4.9867e-02,  1.0277e-01,  3.1328e-01, -1.9742e-01,
         2.7952e-01, -1.8061e-01, -4.6626e-02,  2.4191e-01, -1.2657e-01,
         2.6039e-01,  1.5306e-01, -6.9399e-02, -1.3700e-01, -5.5124e-02,
         5.4393e-02, -2.8142e-01, -2.6752e-02,  9.0902e-02,  2.0530e-01,
        -1.3673e-02,  1.4397e-01, -2.7262e-01,  6.0053e-02,  3.9086e-02,
        -9.6937e+00,  4.2216e+00,  3.4028e+00,  3.7099e-01,  8.8015e-01,
        -5.5032e-01,  4.7884e-01,  6.8588e-01, -5.3692e-01,  7.5046e-01,
        -4.5586e-01,  2.4990e-01,  3.2741e-02, -5.6363e-02, -8.9374e-01,
         3.3148e-01,  1.5445e-01,  7.5799e-01,  8.5326e-01,  6.1313e-01,
         2.2647e-01,  2.1401e-01, -5.3418e-01,  8.6341e-01,  4.7593e-01,
         5.3153e-01,  5.9899e-01,  3.1224e-01,  3.2626e-01,  7.5217e-01,
         7.2443e-01,  6.5191e-01, -4.9305e-03,  7.6832e-01,  2.1681e-01,
        -8.5883e-02,  5.9712e-01, -1.8417e-01, -4.5090e-01, -4.1609e-01,
         3.2970e-01,  6.3279e-01, -1.5089e-01, -3.1037e-01,  2.3563e-01,
        -2.1396e-01, -2.8004e-01,  6.9112e-01,  5.3168e-02,  5.7583e-02,
        -3.1079e-01, -1.1108e-01, -3.1989e-01,  6.3849e-01, -6.6199e-01,
        -1.5896e-02,  4.5412e-01, -2.3292e-01, -1.4318e-01,  3.8194e-01,
         5.5842e-01,  5.7885e-01, -1.0771e-01, -1.9703e-01,  1.4350e-01,
         7.6580e-02, -2.6458e-01,  5.2749e-04, -2.7657e-01,  3.3811e-02,
        -6.6522e-01,  4.6048e-01, -3.0618e-01, -2.4424e-01,  3.4677e-01,
         2.0513e-01,  1.6295e-01, -1.8466e-01,  1.8624e-01, -1.8675e-01,
        -2.3117e-01, -2.3248e-01,  2.1125e-01, -3.4085e-02,  2.5191e-01,
         6.8712e-01,  1.0150e-01,  6.6251e-01,  4.9493e-01, -3.9237e-01,
        -6.6849e-01, -2.7487e-01, -4.8445e-01,  2.6501e-01,  7.1216e-01,
         8.0066e-02,  9.5801e-02, -2.4121e-01, -2.3197e-02,  2.5775e-01,
         2.9243e-01, -4.4521e-01,  3.8621e-01,  3.1140e-02,  1.9317e-01,
         2.0131e-01, -3.9775e-01, -1.7575e-01, -2.1283e-01, -6.3620e-02,
         6.3682e-01,  3.1028e-01,  3.5548e-01,  3.9877e-02,  1.9261e-01,
         1.0920e-01,  1.4261e-01,  8.3484e-02,  6.3558e-01, -2.3333e-01,
        -9.2966e-02,  1.7499e-01,  4.3980e-01, -4.4319e-01,  1.0247e-01,
        -3.2162e-01,  1.4621e-01,  2.1625e-01, -1.1654e-01, -2.5523e-01,
        -3.7366e-01, -3.7382e-01, -6.0374e-01,  2.0677e-01,  2.7990e-01,
         2.0839e-01,  2.3428e-01, -3.6917e-04,  8.2966e-02,  2.4246e-02,
        -8.0809e-02, -8.1455e-02, -5.4378e-01,  1.2529e-01,  4.8981e-01,
        -2.8048e-01, -2.0287e-01,  2.2806e-02, -1.3891e-01,  3.1513e-01,
         9.1143e-02, -2.3054e-01, -6.5594e-02, -1.9305e-02, -4.2194e-04,
        -2.7885e-01,  4.6807e-01,  1.3333e-01,  3.8211e-01, -4.7589e-01,
        -5.4578e-02, -5.6254e-01, -7.2945e-02, -5.0508e-01,  7.0159e-01,
         7.3643e-02,  1.4049e-01, -2.3286e-01,  5.9580e-01, -2.8898e-01,
         2.4709e-01,  5.0606e-02, -2.5039e-01, -4.8887e-02, -3.5919e-01,
        -1.2120e-02, -9.8497e-02,  1.6838e-01, -1.6016e-01, -2.3459e-01,
        -9.3417e-02, -2.5437e-02, -1.6375e-01,  4.3975e-02, -1.1185e-01,
        -9.8988e-02,  1.1676e-01, -2.8001e-01, -2.1863e-01, -5.5401e-02,
         1.4795e-01,  1.3746e-01,  4.2413e-02,  1.1636e-01, -1.6436e-01,
         4.1234e-01,  2.6635e-01,  3.3680e-01,  2.7185e-01, -2.2567e-01]), 0)
(tensor([ 2.1948e+01, -3.2545e+01, -3.4077e+00, -3.2684e-01, -5.2425e-01,
        -6.0455e+00,  5.0721e+00,  2.0981e+00,  1.3712e-01,  2.1531e+00,
         1.3721e+00, -2.5498e+00, -3.6018e+00,  4.7009e+00,  1.2430e+00,
        -5.2964e+00,  9.8198e-01,  6.8036e+00,  1.6299e+00,  1.3258e+00,
         1.8424e+00,  5.1453e+00, -1.9501e+00, -1.5609e+00,  1.1750e+00,
         1.0792e+00, -2.1197e+00, -2.5501e+00, -1.6844e+00,  3.3923e+00,
        -3.1047e+00,  3.6266e+00, -8.2536e-01,  2.8147e+00, -3.0719e+00,
         1.6530e+00, -2.3531e-01, -4.1750e-01,  2.0066e+00,  3.5904e-01,
        -4.0119e-01, -9.8252e-01,  2.8388e-01, -1.4962e-02, -1.7637e+00,
         5.3113e-01, -1.3445e-01, -2.3397e-01,  2.3540e+00,  9.3093e-02,
         3.8674e-01, -4.1444e-01,  1.4770e+00, -5.3321e-01, -3.0625e-01,
         1.6685e+00,  2.7749e+00, -8.7889e-01, -6.4862e-01, -3.6938e+00,
        -7.1377e-01,  6.7566e-01,  2.9685e+00,  4.9175e+00, -1.6321e+00,
         1.7252e+00,  1.1111e+00, -4.5892e-01,  7.1848e-01, -6.1042e-01,
        -1.6781e+00,  1.7792e+00, -1.0014e+00,  1.7547e+00,  1.2397e+00,
         2.7934e+00, -3.5603e-01, -2.2675e+00,  1.8021e-01,  2.6099e+00,
        -1.1181e-01, -6.6183e-01, -2.7218e-01,  1.1742e+00, -1.2172e+00,
        -2.4127e-02, -8.5333e-01, -2.8707e+00,  6.6548e-02, -1.2044e-01,
         8.9091e-02, -7.0383e-01,  4.7897e-01,  9.7860e-01,  5.1441e-01,
         1.4451e+00,  2.6912e-01, -2.0754e-01, -1.1564e+00, -2.6216e-01,
         5.4358e-01, -4.7269e-02, -5.9043e-01,  1.1499e+00,  2.7447e+00,
        -3.7594e-01, -2.3629e-01, -5.5555e-01, -1.3333e+00, -1.0502e+00,
        -7.3719e-01,  3.1297e-02,  7.8345e-01, -1.1187e+00,  1.5278e-01,
         8.9945e-02, -5.0868e-01,  1.3053e+00,  8.1992e-01,  1.7870e-02,
         3.6938e-01, -1.0600e+00, -4.5520e-01, -6.5290e-01,  6.9680e-01,
         1.3918e+00,  1.1063e+00, -7.8383e-01, -9.8473e-02, -9.3601e-01,
        -2.6941e-01,  9.8172e-02, -3.0665e-01, -1.2113e+00, -2.0809e+00,
         8.4275e-01,  5.7831e-01,  1.7509e-01,  4.4567e-01,  5.7147e-01,
        -2.4974e-02, -8.3915e-01, -1.2664e-01,  7.1237e-02,  3.2920e-01,
         1.0751e+00,  6.4568e-01,  3.4506e-01,  1.4855e-01,  9.8544e-01,
         1.4772e-01, -1.7728e-01,  5.1344e-01, -5.5180e-01, -1.1559e+00,
         5.5954e-01,  4.2718e-01,  1.2897e-01,  8.2093e-01,  1.5116e-01,
         2.4778e-01,  7.2466e-01, -4.7368e-01,  3.1098e-01, -8.8005e-01,
         2.4109e-01,  4.9142e-01,  3.0612e-01,  4.6532e-01,  3.7594e-01,
         7.4330e-01, -4.5831e-01,  2.5446e-01,  9.7616e-01,  3.9613e-01,
        -3.7668e-01, -1.1908e-01, -2.0663e-01, -2.9321e-01,  3.7514e-01,
        -7.5075e-01, -9.3100e-02, -4.5329e-01,  1.1514e+00,  5.8262e-01,
        -9.4278e-01, -1.3315e-01,  5.0194e-01,  6.8605e-01,  1.8395e-02,
        -1.4540e-01, -7.0967e-01,  4.1853e-01,  8.2285e-01,  7.2367e-01,
        -2.0764e-01, -9.1688e-01, -4.7440e-01, -1.8503e-01,  4.9312e-01,
        -3.6185e+00,  2.9521e+00,  4.8843e-01, -1.1675e-01, -3.6256e+00,
        -7.3186e-01, -2.3023e+00, -8.7571e-01, -1.0481e+00, -1.6033e+00,
         2.5412e-01, -9.4896e-01, -6.8986e-01, -4.2125e+00,  1.3052e+00,
        -2.8725e-01, -9.2397e-01, -1.0587e+00,  5.9854e-01,  6.2550e-01,
        -1.7760e+00,  1.1670e+00,  2.2898e-01, -5.1437e-01, -1.1824e+00,
         7.7723e-01,  3.9522e-01, -5.7465e-01, -3.1950e-01, -8.4319e-03,
         8.6198e-01,  2.4429e-01,  8.8016e-01,  6.6745e-01,  2.7781e+00,
        -1.7975e+00, -1.5653e+00, -6.7875e-01,  2.7656e-01, -3.8787e-01,
         1.0661e+00,  1.0826e+00,  1.1570e+00, -4.5989e-01, -2.1617e-01,
         1.6213e-01,  1.0211e+00, -5.7698e-01, -5.8872e-01, -8.9568e-01,
        -2.0412e+00, -1.4294e+00, -3.2609e-01, -3.0577e-02, -4.0256e-01,
         1.2865e+00,  7.9796e-01, -1.1639e+00,  4.6760e-01, -7.0828e-01,
         1.1467e+00,  7.4680e-01,  4.2242e-01,  4.6334e-01, -9.2971e-01,
        -6.6337e-02, -1.0064e+00, -1.1133e+00,  5.8544e-01, -2.2772e-01,
         1.7045e+00, -9.4469e-01,  9.2911e-01, -1.4314e+00, -1.5772e-02,
         4.2352e-01, -3.5984e-01, -3.5848e-01,  2.5428e-02,  6.9409e-01,
        -5.4271e-01, -1.5933e-02, -9.6375e-01,  4.6150e-01, -5.1291e-02,
         5.4024e-01,  3.6009e-01,  3.4091e-02,  1.3663e-01,  3.6148e-01,
         6.5037e-01, -8.8114e-01, -9.3121e-01, -4.0694e-01, -6.2275e-03,
         2.1781e-01,  2.6739e-01, -2.7772e-01, -5.0975e-01, -6.2868e-01,
         7.6451e-03,  2.1224e-01,  1.0287e+00,  1.2300e-01,  4.3215e-02,
         2.7163e-01, -1.5894e-01, -4.8309e-01,  4.7170e-01, -4.3045e-01,
         6.3131e-02, -7.6573e-01, -3.2288e-02, -8.6764e-02, -5.8138e-01,
        -2.3720e-01,  2.9147e-02, -9.3290e-02, -1.2910e-01,  2.5071e-01,
        -8.4821e-01,  2.3685e-01, -1.0826e-01, -9.8178e-01, -5.5373e-01,
         3.0015e-01, -3.4651e-01, -4.9653e-01, -4.3501e-01, -2.5141e-01,
         3.6964e-02,  5.6499e-01, -1.3131e-01,  5.8511e-02,  2.1138e-01,
         6.9238e-01, -3.8842e-02,  3.0958e-01, -1.8821e-02, -1.5389e-01,
        -3.4245e-01,  8.1402e-02, -7.7239e-01,  1.5349e-01, -1.2323e-01,
         1.9544e-01,  5.2540e-01, -9.8639e-02, -1.2673e+00,  1.6026e-01,
        -2.9608e-01,  9.8844e-02,  1.1896e-01, -2.1106e-01, -3.1521e-02,
        -1.0742e-01, -9.4285e-01, -8.0493e-03,  8.5345e-03, -1.2975e-02,
         3.6261e-01,  5.6022e-01, -2.7612e-01,  3.3595e-01,  2.7350e-01,
        -8.0073e-01, -5.5944e-02, -6.1707e-01, -1.6800e-01,  1.2089e-01,
        -2.0923e-01,  6.4563e-01,  9.0344e-01,  2.9309e-01, -1.5546e-01,
         3.6063e-01,  6.4969e-01, -3.2763e-01, -1.8316e-01, -1.7310e-01,
        -2.7109e-01, -1.6915e-01, -4.6566e-02, -3.5503e-01,  1.2521e+00,
         6.3279e-02,  7.5143e-01, -2.0092e-01, -6.5864e-01,  8.8912e-02,
        -9.8091e-02, -5.7597e-01, -3.3827e-01, -4.4907e-01,  8.5612e-02,
         1.0935e-01,  1.4720e-01, -3.2653e-01, -2.7041e-01,  4.7740e-02]), 0)
(tensor([-7.0236e+00,  1.8529e+00,  5.5779e-01,  8.3364e-01, -7.8141e-01,
        -3.1995e-01,  1.4054e+00, -2.1032e+00,  4.8685e-01, -1.0343e+00,
        -9.6171e-01,  5.9625e-01,  3.0390e-01,  4.1567e-02, -2.3743e-01,
         4.3280e-01,  7.5873e-01,  1.8725e+00,  1.7519e-01, -8.2106e-01,
        -7.1419e-01, -5.5723e-01, -7.0928e-01, -7.7921e-01, -9.8217e-01,
         2.3091e-01, -1.4409e-02,  5.8133e-01,  4.3239e-01,  1.6726e-01,
         8.9962e-02,  1.3947e+00, -2.9465e-01, -9.8617e-01, -9.1461e-01,
         1.3548e+00,  2.2327e-01,  2.4281e-02, -6.8377e-01, -1.5824e-01,
        -1.9630e-01,  3.2512e-01,  1.2135e-01,  1.1248e+00, -4.4165e-01,
         2.4602e-01, -3.0172e-01,  1.8367e-01, -3.9855e-02,  5.6443e-01,
         6.4541e-01,  6.9075e-01,  8.3773e-01,  1.0261e+00,  1.4161e-01,
         1.0530e+00, -3.0583e-01,  2.1768e-01, -3.6982e-01,  3.5923e-01,
        -1.5421e-01, -1.4153e-01, -7.4471e-01,  1.2389e-02, -3.8475e-02,
        -2.6032e-01, -2.5032e-01,  2.7712e-01, -4.6586e-01,  3.9677e-01,
         5.4366e-02, -3.2034e-01,  1.2217e-01, -3.3637e-01, -3.7634e-01,
         2.2026e-01,  1.9952e-01, -2.4717e-01,  5.6162e-02, -7.2480e-01,
        -3.3741e-01,  2.8065e-01,  1.4220e-01, -1.9127e-01, -3.6118e-01,
         3.4804e-01, -2.6334e-01,  7.9484e-02,  3.5472e-01, -1.1353e-01,
         6.7272e-01,  1.7160e-01,  8.8211e-02,  2.6245e-03, -1.9598e-01,
        -2.6245e-02,  4.4042e-01, -2.8718e-01, -2.9422e-01, -1.3487e-01,
         3.9480e-01, -1.9346e-02, -1.6481e-01, -3.5166e-01, -5.7023e-02,
         8.5170e-02, -5.8791e-02, -1.0894e-01,  1.7034e-01, -4.8057e-01,
         3.0568e-02, -2.8549e-01, -4.1185e-01,  1.7641e-01, -7.2199e-02,
         1.2053e-01, -9.1934e-02, -1.6889e-01, -2.7207e-01, -3.2697e-01,
         1.5454e-01, -5.3113e-01, -1.0950e-01, -3.3033e-01,  1.1311e-01,
        -1.6639e-01, -3.9367e-01, -5.2922e-01, -2.0046e-01,  4.2017e-01,
        -3.2225e-02,  1.4989e-01,  2.7115e-01, -1.9974e-01, -3.4759e-01,
         8.2749e-01,  5.0432e-01, -5.2077e-01, -4.6302e-01, -8.2349e-02,
         1.9723e-01,  3.7392e-01, -1.2051e-01,  3.2704e-01,  1.1573e-01,
         4.9227e-01,  5.5145e-01, -3.7641e-01,  5.1495e-02, -2.0000e-02,
         5.8497e-01, -4.7583e-01, -2.4613e-01, -2.1426e-01, -3.2321e-01,
        -5.2918e-01, -1.6185e-01, -2.2878e-01, -5.2369e-01,  2.7043e-01,
         1.0492e-01,  3.5401e-01, -4.5594e-01,  4.1830e-01,  1.9856e-01,
        -6.0192e-01, -7.8757e-03,  2.2616e-01, -2.7902e-01,  2.0323e-02,
        -1.9764e-01,  1.7375e-02, -2.9539e-02, -3.6906e-01,  4.3234e-01,
         3.5542e-01, -1.7595e-01, -8.3375e-02,  2.3770e-01,  3.1383e-01,
         3.6339e-01,  7.7611e-02,  1.3870e-01, -3.5695e-01,  5.8813e-01,
         5.0514e-03, -4.1852e-02, -2.6564e-01,  2.3290e-01, -1.7539e-02,
        -8.4184e-03, -8.3124e-02, -3.5526e-01,  3.2225e-01, -5.5907e-01,
         4.9754e-01, -9.2523e-02,  5.5875e-01,  5.9761e-02,  1.5652e-01,
         5.1646e+01, -7.1367e+01,  1.6208e+01,  1.9339e+00,  1.8803e+00,
         1.0215e+01, -5.1838e+00,  6.9300e+00,  3.8526e+00, -5.7006e+00,
         1.8841e+00,  4.7970e+00,  8.0430e-01,  1.4469e+00,  2.9905e-01,
         9.9251e-02, -1.5204e+00, -3.5467e-01, -1.2040e+00, -1.6821e+00,
        -1.6678e-01,  9.0562e-02, -7.9367e-01,  7.7781e-01, -3.8337e-01,
         8.0940e-01, -1.1669e+00,  6.9244e-01, -1.4025e+00, -4.4446e-01,
        -2.3457e+00,  2.1508e+00, -1.8926e-01,  8.5980e-01,  6.0867e-01,
        -7.9170e-01,  1.4642e-01, -5.5601e-02, -3.0594e-01,  5.1259e-01,
        -9.0853e-01,  1.1737e+00, -9.7938e-01, -3.2257e-01, -8.3772e-01,
        -4.7175e-01, -3.5265e-01, -1.1915e+00, -1.1916e+00,  4.6718e-01,
        -6.0675e-01, -1.0607e+00, -2.7308e-01,  6.5912e-01,  2.3327e-01,
         2.9139e-01, -1.3349e-01, -2.6414e-01,  3.5570e-01,  2.5667e-01,
         6.3362e-01,  7.6506e-01, -4.2842e-01, -1.0661e+00,  4.3104e-01,
        -9.5518e-01,  3.6428e-01, -4.5575e-01,  7.6113e-01, -1.6239e-01,
        -1.6883e-01, -4.6636e-01, -7.0135e-01,  1.2807e-01, -2.5423e-01,
        -3.5743e-01,  8.3218e-01, -2.1949e-01, -3.1515e-03, -1.9873e-01,
         1.5312e-01, -4.1784e-01, -3.8528e-01,  2.4878e-01, -9.0572e-01,
        -2.7105e-01, -1.4240e-01, -5.5592e-01,  2.9444e-01, -5.0039e-01,
         7.9035e-01,  7.8139e-02, -3.3238e-01, -4.7047e-01, -6.6330e-01,
        -1.8143e-01, -1.3258e-02, -1.2549e-01, -5.1639e-01,  3.5504e-01,
         7.2019e-01, -5.3845e-01,  1.9255e-02, -2.6537e-02, -6.1428e-01,
        -1.4139e-01,  6.0965e-02, -2.9631e-01, -5.3886e-02,  3.0063e-01,
         9.4398e-01,  6.4836e-01, -1.7295e-01,  9.0657e-02, -1.0102e+00,
         5.7308e-02,  4.7288e-01,  1.0205e-01, -7.1188e-02, -7.4910e-02,
        -1.2402e-01, -3.2910e-01, -2.4438e-01,  2.9400e-01,  6.2159e-01,
         1.5552e-01, -4.1382e-01,  9.2029e-02, -3.9798e-01,  1.8007e-02,
         6.2239e-02, -5.0853e-01, -4.1814e-01, -7.0360e-01, -1.3461e-01,
         6.5832e-02, -1.2835e-02, -5.3011e-01, -1.1989e-01,  2.9055e-01,
         2.0906e-01,  6.4985e-01, -3.4856e-01, -2.1402e-01,  6.2069e-01,
         3.4507e-01,  1.7004e-01, -2.6024e-01,  1.6108e-01,  1.6807e-01,
         1.6677e-01, -2.6984e-01, -4.8764e-02,  3.3300e-01, -2.9839e-01,
         4.9896e-01,  1.0729e-01, -3.0795e-01, -1.7608e-01, -2.8724e-01,
        -5.1603e-01,  5.8162e-01, -5.2521e-01, -5.8054e-02,  1.4038e-01,
        -3.8319e-01, -2.6516e-02,  1.5436e-01, -1.0250e-01,  9.8319e-02,
        -1.0780e-01,  4.4010e-01,  3.2462e-01, -6.0901e-02, -1.0844e-01,
         3.6953e-01, -6.5946e-02, -2.7450e-02,  3.0083e-01,  8.8620e-03,
         7.1934e-03, -9.8288e-02,  4.1396e-01,  1.8558e-01, -1.7983e-01,
         3.4885e-01,  1.8102e-01, -2.7702e-01, -2.1757e-01,  1.0331e-01,
         1.9041e-01,  1.6510e-01,  2.5094e-01,  1.9312e-01,  1.7329e-01,
         3.6911e-01,  5.3754e-01, -3.6877e-01,  2.0541e-02, -3.5845e-02]), 0)
(tensor([-8.1484e+00,  1.8634e+00, -1.2670e-01, -2.0272e-02, -4.2907e-01,
        -2.4172e-01,  5.6812e-01, -6.0899e-01, -2.1900e-01,  1.1312e+00,
         8.8256e-01,  3.3036e-01,  2.0828e+00,  1.2916e+00, -1.1005e+00,
         7.6508e-02,  8.8474e-01,  8.8508e-01, -5.1890e-01, -4.6097e-01,
         4.5040e-01, -1.2389e-01, -6.2927e-01,  6.4363e-01, -1.5075e+00,
         1.5085e-01, -6.8144e-01, -1.9383e-01,  4.4218e-01, -9.9031e-01,
         9.1416e-01, -9.4577e-01,  1.0105e+00, -1.3688e-01, -4.5532e-01,
        -5.2101e-01,  1.2382e+00, -2.2360e-01, -7.5042e-01,  3.6398e-01,
         1.3124e-01, -1.0086e+00, -6.9194e-01,  4.1226e-01, -1.7135e+00,
        -1.7124e-01, -7.1545e-01,  2.0423e-01, -3.9216e-02,  9.4539e-01,
         1.4324e-01, -7.9091e-01,  7.6108e-02,  2.4528e-02,  3.7651e-01,
        -6.2439e-01,  1.9135e-01, -2.8083e-02, -4.8321e-02,  3.1696e-01,
         3.7512e-01,  6.3666e-01, -5.8408e-01,  1.7732e-01, -6.2028e-01,
        -6.8985e-01, -1.8450e-01,  4.9837e-01, -3.1750e-01,  7.6433e-01,
         1.8914e-01, -6.4609e-01,  1.5412e-01,  2.7885e-02,  1.1428e+00,
         8.6704e-01, -2.6723e-01, -3.9787e-01, -2.5465e-01, -4.1352e-01,
         1.2248e-02, -2.0375e-01, -1.9999e-01,  3.4729e-03, -3.1312e-01,
        -1.9455e-01, -9.4344e-01,  6.8082e-02,  4.8370e-01,  1.0164e-01,
        -7.2837e-02,  6.1116e-01, -1.0359e-01, -5.4532e-02, -1.4850e-01,
        -5.2196e-01,  3.4521e-01, -6.8238e-01, -1.6800e-01,  2.3325e-01,
         2.1157e-01, -4.7161e-01, -4.7213e-02, -2.6479e-01,  1.0836e-01,
         4.7735e-02,  2.7397e-01,  1.9752e-01,  5.9011e-01,  3.7908e-02,
        -7.1324e-03, -5.1624e-01,  6.2272e-01,  3.0938e-01,  4.4970e-01,
         3.2513e-01, -7.9426e-02,  2.4264e-01, -5.0361e-01,  9.4044e-02,
        -3.3586e-01,  1.9311e-01, -1.1012e-01, -4.0620e-01, -9.4169e-02,
         5.5382e-03, -2.9106e-01,  1.6818e-01, -4.8848e-01,  5.3430e-01,
        -1.3026e-01,  3.2351e-01,  4.7282e-01, -1.8333e-01, -8.7106e-01,
         5.7570e-01,  2.1640e-01,  9.4762e-02, -2.5811e-01, -1.6221e-01,
        -9.3083e-02,  7.4453e-02, -4.3975e-01,  2.5004e-01,  3.0964e-01,
        -1.7072e-01, -1.9421e-03,  2.7132e-01,  1.5304e-01, -9.0701e-01,
         2.2813e-01,  4.9510e-02,  3.2818e-01,  2.6476e-01, -1.0154e-01,
         1.2579e-01,  2.8775e-03, -4.4571e-01,  3.4422e-01,  2.4089e-01,
        -3.8679e-01,  4.8177e-01, -3.9764e-01,  2.1327e-01,  2.0664e-01,
        -4.4379e-01, -2.1112e-01,  4.8572e-01, -9.2262e-03,  3.4456e-02,
        -1.1416e-01, -2.2682e-01, -2.3881e-01,  2.0303e-01, -1.1821e-02,
         3.4803e-01,  1.9226e-01,  1.2774e-01,  6.5349e-02, -3.0042e-01,
        -2.2899e-01,  7.0203e-03,  3.7133e-02, -1.2026e-01, -4.4470e-01,
         1.5631e-01,  1.2331e-01, -5.1108e-02, -3.3069e-01,  3.7916e-02,
        -7.4344e-01, -1.4911e-01,  1.6585e-01,  3.7299e-01, -3.0707e-01,
         5.8706e-02,  5.9699e-02, -9.4922e-02,  2.2590e-01, -2.6214e-01,
         8.0551e+00,  6.3492e+00, -2.7937e+00,  6.0539e-01, -3.6799e-01,
         3.3960e+00, -2.6281e+00,  1.4757e+00, -1.5302e+00,  1.1336e+00,
        -1.5716e+00, -1.5677e+00,  9.3062e-01, -2.3070e+00, -1.9561e-01,
        -1.2349e+00,  6.6564e-01,  8.9185e-02,  1.1248e+00,  2.9901e+00,
        -1.8729e-01,  1.9648e+00,  6.4754e-02, -3.7521e-01,  3.6633e-02,
        -2.1976e+00, -7.2524e-01,  9.3798e-01, -7.4829e-01,  1.7258e+00,
         1.5685e+00,  6.4942e-01,  8.1439e-03, -9.5753e-01, -1.9191e+00,
         2.6101e-01, -3.3786e-01,  5.4532e-02,  9.5812e-02,  1.5889e-01,
         2.0856e+00, -5.3126e-01, -2.2657e-01,  2.1003e+00, -4.9938e-01,
         1.6707e+00, -3.0880e-01, -2.5851e-02, -8.4064e-01,  1.7494e-01,
         1.6093e+00,  1.3415e+00,  3.4457e-01,  7.8391e-01, -5.2639e-01,
        -1.3816e+00, -6.0256e-01,  5.6179e-01, -2.4267e-01, -5.1250e-01,
         8.2553e-01, -3.8166e-01, -7.8252e-01,  2.4009e-01, -1.0448e+00,
        -1.4459e-01,  4.0003e-01, -3.2085e-01, -5.0616e-01, -4.2388e-01,
         9.8300e-01,  6.2043e-01,  3.0641e-01,  1.8080e+00, -2.2435e-01,
        -4.4105e-01,  2.4383e+00,  3.7165e-02, -4.2566e-02, -7.4607e-01,
         7.7487e-01, -3.3764e-01,  1.5213e-01,  7.6062e-02, -7.1901e-02,
        -2.2283e-01, -2.7919e-01,  1.4841e+00,  8.9948e-01,  1.1749e+00,
         1.7102e-01,  1.1063e+00,  6.5964e-02,  1.7096e-01, -5.3966e-01,
         1.2037e-01, -7.9133e-01,  3.1334e-01, -1.3363e-01, -4.7336e-01,
        -5.3390e-01,  1.7226e-01, -9.9862e-01, -5.6183e-01,  3.5650e-01,
        -2.9797e-01,  3.3485e-01, -3.7117e-02,  2.6317e-01,  4.5415e-01,
         3.0292e-01, -1.1377e-01, -1.5096e-01, -3.3013e-01, -5.2182e-04,
        -2.9766e-01,  1.2507e-01,  1.6402e-01,  4.9428e-02,  5.2033e-01,
         7.2113e-01, -5.9651e-01, -3.2349e-01,  8.1663e-01,  2.4267e-01,
         7.8365e-02, -4.7556e-01, -5.9787e-01, -3.1616e-01, -3.4258e-01,
        -4.0305e-01,  4.1707e-01, -3.8790e-01, -4.7608e-02,  2.0874e-01,
         6.2571e-01,  8.4605e-01,  1.2067e-01, -9.2849e-01, -2.5813e-01,
         5.3219e-01, -2.9141e-01,  1.0424e-01, -2.1370e-01,  6.1272e-01,
        -4.2519e-01,  2.6902e-01, -4.8655e-02, -2.8418e-01,  2.9594e-01,
         4.3348e-01,  8.0620e-03, -3.0965e-01,  5.0728e-01,  6.1546e-02,
        -5.0035e-01, -5.8977e-01, -1.8359e-02,  5.8358e-01,  3.2824e-01,
        -1.4291e-01,  3.1664e-02,  1.0025e-01,  5.3104e-01, -7.3950e-01,
         1.1352e-01,  3.2676e-02,  4.6979e-01,  4.0366e-01, -4.9947e-01,
         1.9010e-01,  1.3814e-01, -4.5969e-02, -4.4036e-02, -9.2882e-01,
        -6.9376e-01,  8.6932e-01, -5.0448e-01,  4.9880e-01, -3.6799e-01,
         4.1372e-02,  2.2507e-02, -1.4633e-01,  7.1622e-01,  8.5980e-01,
         5.8752e-01, -5.3900e-02,  1.4214e-01,  9.1049e-02,  3.1709e-01,
        -1.1230e-01, -3.2651e-01, -5.2696e-01,  1.7707e-01,  1.1649e+00,
        -2.0705e-01, -4.5248e-01, -2.5798e-01,  1.1167e-01,  4.1103e-01]), 1)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ packet_write_wait: Connection to 130.241.53.60 port 62266: Broken pipe
(base) Julias-MacBook:~ juliaklezl$ ssh -p 62266 gusklezju@mltgpu.flov.gu.se
gusklezju@mltgpu.flov.gu.se's password: 
----------------------------------------
Welcome to the host mltgpu.flov.gu.se
Fedora 30 (Server Edition)
----------------------------------------
Support:

 Robert Adesam, robert.adesam@gu.se
----------------------------------------

Last login: Thu Mar 26 09:24:15 2020 from 46.239.124.106
[gusklezju@GU.GU.SE@mltgpu ~]$ packet_write_wait: Connection to 130.241.53.60 port 62266: Broken pipe
(base) Julias-MacBook:~ juliaklezl$ ssh -p 62266 gusklezju@mltgpu.flov.gu.se
gusklezju@mltgpu.flov.gu.se's password: 
----------------------------------------
Welcome to the host mltgpu.flov.gu.se
Fedora 30 (Server Edition)
----------------------------------------
Support:

 Robert Adesam, robert.adesam@gu.se
----------------------------------------

Last login: Thu Mar 26 19:04:43 2020 from 46.239.124.106
[gusklezju@GU.GU.SE@mltgpu ~]$ cd lt2212-v20-a3
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 68, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 44, in train
    output = self.model(instance)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "a3_model.py", line 19, in forward
    m = self.linear(x)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1371, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [1 x 400], m2: [60 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 68, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 44, in train
    output = self.model(instance)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "a3_model.py", line 19, in forward
    m = self.linear(x)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1371, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [1 x 400], m2: [60 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 67, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 30, in train
    optimizer = optim.SGD(self.model.parameters(), lr=self.lr)
AttributeError: 'AuthorFFNN' object has no attribute 'model'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 67, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 30, in train
    optimizer = optim.SGD(self.model.parameters(), lr=self.lr)
AttributeError: 'AuthorFFNN' object has no attribute 'model'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 67, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 30, in train
    optimizer = optim.SGD(self.model.parameters(), lr=self.lr)
AttributeError: 'AuthorFFNN' object has no attribute 'model'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 67, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 30, in train
    optimizer = optim.SGD(self.model.parameters(), lr=self.lr)
AttributeError: 'AuthorFFNN' object has no attribute 'model'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 66, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 27, in train
    self.model = AuthorPredict()
TypeError: __init__() missing 1 required positional argument: 'input_size'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 66, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 43, in train
    output = self.model(instance)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "a3_model.py", line 19, in forward
    m = self.linear(x)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1371, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [1 x 400], m2: [4694 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 66, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 43, in train
    output = self.model(instance)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "a3_model.py", line 19, in forward
    m = self.linear(x)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1371, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [1 x 400], m2: [4694 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
  File "a3_model.py", line 29
    criterion = nn.CrossEntropyLoss()
            ^
SyntaxError: invalid syntax
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
4694
Traceback (most recent call last):
  File "a3_model.py", line 67, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 44, in train
    output = self.model(instance)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "a3_model.py", line 19, in forward
    m = self.linear(x)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1371, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [1 x 400], m2: [4694 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
Traceback (most recent call last):
  File "a3_model.py", line 67, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 44, in train
    output = self.model(instance)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "a3_model.py", line 19, in forward
    m = self.linear(x)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1371, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [1 x 400], m2: [4694 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
torch.Size([400])
Traceback (most recent call last):
  File "a3_model.py", line 68, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 45, in train
    output = self.model(instance)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "a3_model.py", line 19, in forward
    m = self.linear(x)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1371, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [1 x 400], m2: [4694 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
tensor([ 7.0991e+00,  5.7375e-01, -2.6268e+00,  2.3495e+00, -4.1209e-01,
        -7.3640e-01, -1.0529e+00, -4.4286e+00, -9.1233e-01, -1.0074e+00,
         2.5614e-01,  1.7449e+00, -8.1155e-01, -1.7645e+00, -7.9757e-01,
        -1.4897e+00,  3.2796e-01,  2.6263e+00, -4.1315e-01, -1.4534e+00,
        -3.9774e-01,  1.5549e+00, -2.0818e-01, -1.2111e+00,  2.7260e-01,
         1.8508e-01, -1.2216e+00,  2.6882e+00, -5.6972e-01,  9.0047e-01,
         3.9448e-01,  1.7942e+00,  9.9629e-01, -1.8093e+00,  9.8812e-01,
         1.1679e+00, -1.7697e+00,  7.3537e-01,  1.6439e-01,  2.5389e-01,
         1.1551e-01,  8.2965e-01, -4.4343e-01,  7.9534e-01, -5.7356e-01,
         5.8907e-01,  2.4204e-01, -1.9390e-01,  8.7224e-02,  5.2754e-01,
        -6.7106e-02,  3.7612e-01, -8.5829e-01,  5.2315e-01,  4.7140e-01,
         2.3024e+00, -3.0865e-01, -6.2398e-01,  3.3553e-01,  4.5744e-01,
         3.2185e-03, -3.5139e-01,  5.0938e-01, -5.1029e-01,  8.9279e-01,
        -3.0687e-01,  1.3405e+00, -2.0575e-01, -8.3511e-01, -9.7296e-01,
        -8.1852e-01,  1.7635e-01, -1.6110e+00,  3.8951e-01, -6.9320e-01,
        -4.4336e-01,  2.5203e-01,  7.5125e-01,  1.7479e-01, -7.0663e-01,
         1.0860e+00,  2.5544e-01, -6.1140e-01,  6.2444e-01, -3.4215e-01,
         1.1139e+00, -4.9632e-01,  5.6274e-01,  1.1484e-01, -1.6962e+00,
        -4.0590e-01, -1.0175e+00, -2.4547e-01, -5.5633e-01,  1.5082e-01,
         2.2232e-01, -1.0427e+00,  9.2002e-02, -3.1531e-02,  3.8487e-01,
        -2.4883e-01, -2.0273e-01,  1.8250e-01, -1.3222e-01,  1.1477e+00,
         5.6309e-01, -6.2070e-01,  2.9868e-01,  1.0381e+00, -3.9071e-01,
         3.3499e-01, -1.4263e-01,  1.2060e+00, -7.8108e-01, -3.0931e-01,
         1.5713e-02,  4.4840e-01,  7.2223e-01,  3.3405e-01,  3.8000e-01,
        -1.2525e-01, -1.7231e+00,  1.1945e+00,  1.5515e-01, -2.0152e-01,
        -7.8247e-02,  7.5871e-01,  1.2866e-01, -7.9814e-01, -2.2302e-01,
        -2.7136e-02, -2.1007e-01,  1.0044e+00,  1.0239e+00,  1.1718e-01,
        -9.0420e-01,  1.3406e+00, -4.4354e-01,  5.9144e-01,  8.4142e-01,
        -4.6516e-01, -5.3176e-02, -1.1847e+00,  1.6886e-01,  4.8309e-01,
         1.1819e+00, -5.2810e-01,  1.2854e+00,  4.5045e-01,  1.0440e+00,
        -5.5396e-01, -1.3286e+00, -3.6387e-01,  2.6657e-01,  3.0230e-01,
        -1.1762e-01,  2.2043e-01,  1.0211e+00,  2.5931e-01, -4.0936e-01,
         1.5706e+00,  1.1540e+00,  2.6063e-01, -1.3542e+00, -9.8401e-03,
         9.9799e-01,  8.9566e-01,  4.3276e-01, -1.6103e-01,  9.3591e-01,
        -6.5134e-01, -5.2743e-01, -8.5162e-01,  6.4051e-02, -2.5658e-01,
         5.1678e-01,  6.8849e-01,  3.2790e-01, -6.0800e-01,  2.6244e-01,
        -9.2450e-01,  4.3918e-01,  3.6962e-01,  1.9603e-01,  2.4792e-01,
         4.2997e-01,  7.0470e-01,  4.3009e-01,  6.1603e-01, -7.0352e-01,
         9.0932e-01,  8.4188e-01,  9.6341e-02,  2.6124e-01, -1.1769e+00,
        -1.2943e+00,  6.8355e-01, -2.8201e-01,  5.5022e-01, -6.5179e-01,
        -8.4865e+00,  2.5889e+00,  1.8051e+00,  1.7277e+00,  2.7252e+00,
        -3.4022e-01,  1.4917e+00,  7.6798e-01,  5.8243e-02, -2.3103e-01,
        -3.8530e-01,  2.5296e-01, -1.1061e+00,  1.6291e-02, -7.7548e-02,
        -9.5645e-01, -1.0433e+00,  2.6806e-01, -9.0612e-01, -2.5060e-01,
         5.7904e-01, -5.6470e-01,  4.2743e-01, -1.5559e-01,  5.9607e-02,
        -1.9494e-01, -1.9732e-02,  2.0835e-01, -2.7543e-01,  3.4033e-01,
         3.5664e-01,  1.6408e-01, -5.4377e-01,  1.0407e-01, -5.4949e-01,
         2.4877e-01,  3.5802e-01, -2.6152e-01,  1.1776e-01,  4.5736e-01,
        -4.3688e-01, -3.7927e-01, -1.3907e-01, -2.3962e-01,  2.4632e-01,
         6.5446e-01,  1.7707e-03, -3.8414e-02, -5.3276e-02,  3.2252e-01,
         3.9301e-02, -6.1658e-01, -1.2127e-02, -1.4362e-01,  1.1973e-03,
         2.2315e-01, -9.1919e-02, -8.3769e-02, -2.6747e-01, -1.2641e-01,
         5.3668e-01,  2.1751e-01,  5.1672e-01,  5.5906e-01, -6.1870e-01,
         1.9772e-01, -4.0356e-01, -2.6984e-02, -2.4135e-01, -2.3632e-01,
        -3.8323e-01, -5.7343e-02, -2.0831e-01, -1.9811e-01, -3.4275e-03,
         1.9716e-01,  1.6587e-02,  3.1867e-01,  4.3781e-01,  4.3367e-01,
        -2.1037e-01,  6.9189e-02, -2.8058e-01, -3.3029e-01, -2.3134e-01,
         3.0827e-01,  9.7509e-02, -8.1856e-02,  9.1137e-02,  5.2610e-01,
        -4.3771e-01,  1.0483e-01,  6.6557e-03, -9.1492e-02,  2.1018e-01,
         1.0664e-01,  1.1146e-02,  5.9192e-01, -9.8005e-02,  1.6156e-01,
        -4.0011e-02, -5.3625e-01, -2.3429e-01, -5.7135e-02, -1.0344e-01,
        -1.6655e-01,  1.0780e-01,  7.4850e-02, -5.8214e-01,  1.5611e-01,
        -1.5264e-01,  2.0915e-01, -6.2884e-02,  1.6089e-01, -3.2237e-01,
        -3.4900e-01, -4.9798e-01, -1.5225e-01,  1.8306e-01,  1.2500e-01,
         7.4046e-02, -4.7909e-02, -1.5850e-01,  1.0770e-01,  9.1450e-02,
         1.5624e-01,  1.4920e-01,  4.2905e-01,  2.1333e-01,  1.7044e-01,
        -1.6558e-03, -1.3023e-01, -4.7967e-02,  3.4711e-01,  1.7079e-01,
        -3.2038e-01, -1.6837e-01,  2.6433e-01,  2.6283e-01,  3.3290e-01,
        -1.3266e-01,  2.0796e-01,  1.3385e-01,  5.6039e-03, -1.5550e-01,
        -3.9902e-01, -3.9117e-01,  7.4427e-02,  4.7312e-02, -6.1391e-02,
         1.1562e-01, -1.5708e-01, -1.6069e-01,  1.2586e-01, -1.3165e-01,
        -2.8026e-02, -1.0336e-01,  1.3101e-01, -2.5253e-01,  2.8378e-01,
        -1.1220e-01,  1.7291e-01,  3.9066e-02,  4.9830e-02,  3.2764e-01,
        -5.8856e-02,  2.1094e-01,  1.4605e-01, -1.1907e-02, -6.7757e-02,
         9.2963e-02,  2.1804e-01,  1.1688e-01, -5.1439e-01, -2.5996e-02,
        -3.1922e-01,  1.9343e-01,  1.8885e-01, -1.1836e-01,  4.6459e-02,
         3.9630e-01, -3.1523e-01,  1.8193e-01,  2.3664e-01, -2.2065e-01,
        -1.1295e-02,  1.2353e-01, -3.9555e-01, -1.4565e-02, -1.6658e-01,
         3.9765e-01, -1.9777e-01, -2.3544e-01, -1.0673e-01,  8.0882e-02,
         6.4239e-02, -3.7700e-01,  8.0032e-02,  9.2560e-03,  4.5173e-02])
Traceback (most recent call last):
  File "a3_model.py", line 68, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 45, in train
    output = self.model(instance)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "a3_model.py", line 19, in forward
    m = self.linear(x)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1371, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [1 x 400], m2: [4694 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
(2, 200)
torch.Size([200]) torch.Size([200])
tensor([ 1.0366e+01,  1.4916e+00, -2.1383e+00,  7.1811e-01, -1.3889e+00,
         1.8038e-01,  3.9355e+00, -5.0104e+00, -2.3581e+00,  1.2370e+00,
         1.4306e+00,  2.7010e+00,  4.2522e-01,  1.1895e+00, -3.1721e+00,
         5.7975e-01,  3.0839e+00,  2.3701e-01, -3.3383e+00,  1.5595e+00,
         5.1892e-01,  1.1846e+00,  4.9523e+00,  2.9135e+00, -4.9776e-01,
         2.3265e+00, -1.5112e+00, -2.6061e+00,  2.9955e+00,  1.5407e+00,
        -8.7002e-01, -1.1848e+00, -1.0557e+00,  9.3379e-01,  1.3755e-01,
        -1.0032e+00, -1.0102e-01, -1.7494e+00,  3.6600e-01,  9.5774e-01,
        -1.4932e+00, -3.2520e-01, -5.1681e-01, -1.7973e+00, -5.1513e-02,
         4.7122e-01,  5.0703e-01,  1.2953e+00,  1.6346e+00,  4.5170e-01,
         8.7396e-01,  3.5975e-01,  1.2370e+00, -1.5370e+00,  2.0165e-02,
        -7.8432e-01,  1.2621e+00,  2.5239e-01,  4.6509e-01,  1.1044e+00,
        -1.8501e+00,  4.7349e-01,  1.4137e-02, -1.0810e+00, -1.0479e-01,
         1.0063e+00, -4.3240e-01,  2.6511e-01, -1.0147e+00, -7.2140e-01,
         5.5664e-01, -7.8349e-01, -8.1175e-01, -1.9807e+00, -1.2198e-01,
        -6.9989e-01, -2.7847e-01, -1.2302e+00,  4.0796e-02,  1.6831e-01,
        -1.2962e+00, -2.7340e-01,  1.4226e-01, -4.6793e-01,  2.2493e+00,
        -3.5017e-01,  9.2212e-01, -7.7843e-01,  9.1518e-01, -2.0463e-01,
         2.7131e-01,  3.4618e-01,  2.2404e-02, -1.6336e+00,  9.3881e-01,
        -3.6605e-01,  6.1487e-01,  1.1552e+00,  7.6321e-02, -4.3420e-01,
        -9.9257e-01,  2.8619e-01, -7.1767e-02, -1.3022e-01,  8.8259e-01,
         7.9983e-01,  3.0760e-01,  1.1536e+00, -1.4143e+00,  1.8218e+00,
         8.7537e-02, -1.3529e+00, -5.4328e-02, -6.7242e-01, -1.4511e+00,
         6.4190e-01, -3.6996e-01, -5.8365e-01, -9.9921e-01,  3.7911e-01,
        -8.3480e-01,  1.6505e+00,  4.7302e-02, -1.1449e+00, -7.5378e-02,
         7.3376e-01, -1.9250e-01, -1.6804e+00, -1.0586e+00, -1.1722e-01,
        -2.1585e+00,  1.1566e-01, -8.4327e-01,  2.2727e+00, -8.1422e-01,
         1.5309e+00, -6.0908e-02, -9.7390e-01,  1.2064e+00,  1.9347e-01,
        -6.4955e-01, -6.6956e-01,  2.1824e-01, -2.1855e-01, -1.6621e+00,
         1.2899e-01, -1.1905e+00, -6.4215e-03, -8.4361e-01, -1.2814e+00,
        -2.9211e-01,  9.2012e-01,  1.0646e+00, -1.4294e+00, -1.2598e+00,
         1.3099e+00,  7.3754e-01,  8.2929e-02, -5.3171e-01,  8.1970e-01,
        -1.2307e+00,  1.0869e+00, -8.9051e-01,  9.9587e-01, -1.1792e+00,
         1.4202e+00,  1.0584e-01, -1.8656e+00, -9.8771e-01, -1.0786e+00,
         2.3222e-01,  4.6404e-02, -1.0720e-01,  1.4079e+00, -4.3854e-01,
        -3.3348e-01, -1.3530e+00, -6.0861e-01, -1.6423e+00, -4.8265e-01,
         5.7856e-01,  6.0002e-01,  1.7549e+00, -6.7334e-01, -5.7349e-01,
         9.9185e-01,  5.3142e-01, -2.7175e-01,  4.2648e-01,  3.5454e-01,
         2.9836e-01,  5.1511e-01,  2.8065e-01, -9.6224e-01, -1.9826e-01,
         2.3768e-01, -8.5308e-01, -2.0206e-01,  7.3411e-01,  2.0939e-01,
         2.2074e+01,  1.9333e+00, -4.6753e+00, -7.4970e-01, -4.4108e+00,
         6.8237e+00, -5.1709e+00, -2.1858e+00, -1.7762e+00,  6.1073e-01,
         3.6408e+00, -1.0152e-01,  3.9867e+00,  1.6511e+00, -2.5195e+00,
        -1.7051e+00,  8.0143e-01, -3.3647e+00, -3.5768e+00,  6.0911e-01,
        -4.2861e+00, -3.6864e+00,  6.8200e-01,  1.3482e+00,  5.0757e-01,
         6.6674e-01, -2.2207e+00, -1.6723e+00, -9.9600e-01, -1.9632e-01,
        -4.3937e-01, -9.3873e-01,  1.7551e+00, -1.6195e+00, -1.0666e+00,
        -2.3996e-01,  2.6492e+00, -2.6555e+00, -9.8671e-01,  1.0851e+00,
         9.8641e-01, -2.7613e-01,  8.2888e-02, -1.3448e+00,  8.7834e-01,
         1.2230e-01,  7.4533e-01, -1.9268e+00, -3.3634e-01, -3.5300e-01,
         7.2288e-01, -4.3031e-01,  7.9687e-01,  3.9553e+00,  1.0792e+00,
        -1.8648e-01,  5.7511e-01, -1.6340e+00, -6.3359e-01, -2.2980e+00,
         7.6857e-01,  8.8980e-01,  1.2287e+00,  1.4004e+00,  1.1080e+00,
         4.7793e+00, -1.0942e+00,  3.5955e-01,  2.3978e-01, -6.0584e-01,
         2.2974e+00,  6.9707e-01,  8.7115e-01, -1.7938e+00,  3.9206e-01,
        -5.9696e-01,  1.7595e-01, -1.0341e+00, -2.8164e+00,  1.6067e+00,
        -2.9819e+00, -5.9540e-02,  2.5667e+00, -9.0067e-01,  8.4708e-01,
         4.1225e-01, -2.6317e+00, -1.5608e+00, -1.6816e-01, -6.3100e-01,
         9.9337e-01,  5.7206e-02, -1.1672e+00, -1.5103e-01,  3.8939e-01,
         6.0403e-01, -6.6325e-01,  2.4620e+00, -8.0621e-01, -2.0169e+00,
        -4.1331e-01,  2.2228e+00,  2.6783e-01, -4.2843e-01,  1.9417e+00,
         7.6451e-01,  1.8681e+00,  8.9334e-01,  4.1500e-01,  4.8981e-01,
        -1.4069e-02, -2.0677e-01, -2.8911e-01, -5.4385e-01, -4.5813e-01,
        -7.9265e-01, -1.8689e+00, -2.3997e+00, -6.5606e-01, -5.4675e-01,
         2.0005e+00, -7.0319e-01,  4.4093e+00, -1.6926e+00, -1.4299e+00,
        -2.1457e+00, -1.2104e+00, -5.1615e-01,  1.4938e+00,  2.6988e+00,
        -5.1505e-01, -6.6658e-01, -1.0076e+00, -2.3464e+00,  1.1378e+00,
         9.7486e-01, -1.3149e+00, -8.5525e-01, -3.8239e-01, -1.0963e+00,
        -2.5069e+00,  6.9007e-01, -1.6530e+00,  1.3577e+00,  1.0600e+00,
         4.2395e+00, -7.1562e-01,  1.5528e-01,  4.3742e-02, -8.1208e-02,
        -6.6115e-01,  1.8775e+00, -9.5786e-01,  3.5293e-01, -4.3042e-01,
         9.4869e-01, -6.3345e-01,  3.4326e-01, -2.2065e-01, -3.2184e-01,
         1.4369e+00, -1.2659e+00,  1.2525e+00, -3.9189e-01,  8.0015e-01,
         2.0666e-01, -1.4196e+00, -8.4998e-01,  5.2811e-01,  1.3199e+00,
         2.1664e+00, -1.2354e+00,  1.7696e+00, -1.9127e+00,  1.1714e+00,
        -4.6927e-01,  1.2562e-01,  2.0148e+00, -7.5442e-02, -6.5442e-01,
        -1.4673e+00,  1.5094e-01, -9.9376e-01, -1.7030e+00, -7.3792e-01,
         1.9595e+00, -2.1565e+00,  1.5575e+00, -9.6593e-01,  2.3702e+00,
         1.4790e-01,  1.3159e+00,  1.1364e+00,  2.1129e-01,  8.3461e-01,
        -8.0167e-01,  2.0460e+00, -1.0587e+00,  2.2152e+00, -8.3866e-01])
Traceback (most recent call last):
  File "a3_model.py", line 70, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 47, in train
    output = self.model(instance)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "a3_model.py", line 19, in forward
    m = self.linear(x)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1371, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [1 x 400], m2: [4694 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
(2347, 0)
torch.Size([0]) torch.Size([0])
tensor([])
Traceback (most recent call last):
  File "a3_model.py", line 70, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 47, in train
    output = self.model(instance)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "a3_model.py", line 19, in forward
    m = self.linear(x)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1371, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [1 x 0], m2: [4694 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
(2345, 2)
torch.Size([2]) torch.Size([2])
tensor([ 1.0486,  1.3673, -0.0286,  0.2241])
Traceback (most recent call last):
  File "a3_model.py", line 70, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 47, in train
    output = self.model(instance)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "a3_model.py", line 19, in forward
    m = self.linear(x)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1371, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [1 x 4], m2: [4694 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
(2, 200)
torch.Size([200]) torch.Size([200])
tensor([ 1.1681e+01,  1.4119e+00, -5.1235e+00, -1.6064e+00, -2.4455e+00,
         1.7998e+00, -4.5375e-01, -2.2131e+00, -6.2716e-01,  1.0262e+00,
        -2.8594e+00,  2.4709e+00,  1.9242e+00,  1.9678e-01, -2.4733e+00,
        -1.1574e-01, -2.7857e+00, -2.1973e+00, -2.3825e+00, -1.8883e-01,
        -2.1604e+00,  2.4153e+00, -9.7653e-01, -1.1297e+00,  3.8223e+00,
         3.1163e+00,  9.7867e-01,  1.2062e+00, -1.9374e-01, -2.2335e-01,
        -1.6287e+00, -5.5419e-01, -9.9230e-01, -1.1785e+00,  2.7422e+00,
        -1.5566e+00,  5.9543e-01,  1.9027e+00,  5.8778e-01,  9.6321e-01,
         4.9265e-01,  9.8282e-01, -4.7866e-02, -2.0125e+00, -7.3322e-01,
        -2.2270e+00, -2.5143e+00, -1.5621e+00,  1.0084e-01,  5.5855e-01,
        -4.2072e-01, -2.4174e+00,  3.0456e-01, -1.3130e+00,  7.3831e-01,
         5.9153e-01,  1.8621e+00, -7.1402e-01, -1.7445e+00,  5.8243e-01,
         6.0622e-01,  3.1164e-01,  8.4915e-02, -1.0876e+00,  7.7227e-01,
         2.9343e-01, -4.7675e-01, -4.1898e-01,  9.7253e-01,  1.9503e-01,
        -5.9413e-01,  1.7234e+00,  2.7251e-02,  4.8803e-01,  7.7781e-01,
         4.1424e-01,  7.7678e-01,  1.4676e+00, -9.6336e-01, -1.0872e+00,
        -3.9575e-01, -7.4006e-01,  1.1577e+00,  7.3118e-02, -1.4085e-01,
         1.0371e-01, -2.9602e-01,  3.6534e-01, -4.6591e-01,  4.0130e-01,
         6.6387e-01,  5.6055e-01, -9.2690e-02, -1.1538e-01, -7.9103e-01,
        -9.5159e-01,  4.4605e-01, -6.2683e-01,  8.5263e-01, -9.2870e-03,
         8.2318e-01, -8.9982e-01, -1.8873e-01, -2.4750e-02, -1.5832e-01,
        -1.1318e+00,  6.3044e-01, -4.8359e-01, -6.7520e-02, -3.8109e-01,
        -5.7831e-01, -1.7379e-01,  7.6211e-01, -1.0703e+00,  7.1999e-02,
         6.8795e-01, -2.6594e-01,  6.0831e-01, -3.6350e-01,  2.2483e-01,
         2.4835e-01,  5.6441e-02, -7.2536e-01, -6.0745e-01,  7.4832e-01,
         5.8525e-01,  2.1114e-01,  7.3850e-01, -1.4277e+00,  1.8149e-01,
         1.5688e-01, -4.7871e-01,  5.6824e-01, -1.1137e+00, -8.1372e-01,
        -1.5206e-01,  4.6049e-01, -1.1127e-01, -5.2608e-01,  8.3796e-01,
        -6.1688e-01,  2.3814e-01, -1.0137e+00, -3.8780e-01,  6.0066e-01,
        -1.0105e-01,  3.5299e-01,  1.1309e+00,  4.8638e-01,  8.9665e-01,
         4.4900e-01, -9.2896e-02,  5.2500e-01,  1.0294e+00,  5.2196e-02,
        -9.0674e-01, -3.6841e-01, -8.9794e-01, -7.1485e-01,  3.0762e-01,
        -4.2019e-01,  1.4498e+00, -2.1155e-01,  2.8034e-01, -2.4419e-01,
         3.8848e-01,  1.5963e-01,  5.0913e-01, -8.0419e-01,  5.8253e-01,
        -4.4261e-01,  7.1912e-01,  4.5273e-01,  2.8539e-01,  3.9423e-01,
         6.0722e-01, -3.7494e-01, -2.0965e-02, -8.1004e-01, -5.4516e-01,
        -6.9496e-01,  2.6545e-01, -2.1400e-01, -4.8744e-01, -7.3304e-01,
         7.1426e-01,  3.4786e-01, -1.6597e-01, -5.1241e-01,  4.3166e-02,
        -2.5683e-01, -2.7483e-01,  1.1338e-01,  6.9966e-01, -1.5185e-01,
        -9.6451e-01,  1.2119e+00,  4.4469e-01,  5.7858e-02, -2.7336e-01,
         8.5538e+01,  1.0066e+01, -1.4087e+01, -4.6061e+00,  8.1142e+00,
         7.1987e+00, -2.0344e+01,  2.0830e+00, -4.8993e+00, -1.2648e+00,
         8.5676e+00, -6.8673e+00, -7.2938e+00, -1.5887e+01,  6.2815e+00,
        -5.7691e+00,  1.1292e+01,  4.4589e+00,  7.9198e+00, -1.7058e+00,
         4.6558e+00, -1.2394e+00,  9.4002e+00,  1.2211e+00,  1.2117e+01,
        -2.6575e+00, -2.1968e+00, -3.8624e+00,  3.8868e+00, -4.3954e+00,
        -6.3722e+00,  4.9579e+00, -5.6636e+00, -4.3970e+00,  4.4328e+00,
         2.5686e+00, -1.8033e+00,  3.1221e+00, -9.2436e+00,  9.9267e+00,
         1.8201e+00, -7.6138e+00, -6.8927e+00, -6.1810e-01,  2.5208e+00,
        -5.5889e+00, -6.4088e+00,  1.0123e+01, -7.0988e+00, -1.4519e+00,
        -4.0167e+00,  4.5349e+00,  1.5787e+00, -3.7548e+00, -3.2751e+00,
         1.6129e+00, -9.3586e-01, -6.7036e-01,  6.9466e-01, -1.9481e+00,
        -3.5861e-01, -4.7822e-01, -9.8634e-01,  4.4450e-01,  3.5731e-01,
         1.2529e+00, -7.5677e-01,  2.6445e+00,  2.6936e-01,  1.0396e+00,
         7.5317e-01,  7.6402e-02, -1.5102e+00, -1.8478e+00,  9.6534e-01,
         1.5195e+00, -9.5590e-01, -4.2961e-01,  4.1797e-01,  1.1435e+00,
        -1.8671e-01,  8.2421e-01, -2.1296e-01, -2.6891e-01,  3.4807e-01,
         1.2955e-02,  2.1700e-02, -4.1312e-01, -5.1464e-01, -3.9459e-01,
         3.6572e-01,  6.3223e-01,  2.3267e-01,  8.9886e-02, -6.6620e-03,
        -7.1614e-01, -3.6015e-02, -1.9321e-01, -4.8016e-01,  6.6860e-02,
         5.9981e-01, -4.1097e-01,  3.6387e-01, -4.3722e-02,  5.6817e-02,
        -1.7008e-01, -5.0605e-01, -7.8865e-01,  4.1549e-01,  1.1390e-01,
        -3.7971e-01,  4.8120e-01, -5.8366e-01, -6.4401e-01, -7.8683e-01,
        -1.2746e-01,  4.4307e-01, -4.1724e-01, -3.7041e-01, -5.3614e-01,
         9.1806e-01, -3.1340e-01, -8.9103e-01,  1.4408e-01, -5.3987e-01,
        -1.0061e-01,  4.3401e-01,  5.6057e-01, -4.1522e-01,  4.0795e-02,
         3.8320e-02, -3.4566e-01,  9.0839e-02, -2.2694e-01, -3.2961e-01,
         6.0044e-02, -3.2245e-02,  5.6235e-02, -3.9900e-01, -6.8659e-02,
         5.4021e-01,  7.3696e-01, -1.6351e-01,  1.0661e+00, -2.9681e-01,
         8.8485e-02, -3.1088e-01, -1.8910e-01,  2.3151e-01, -6.3645e-02,
        -3.2962e-01, -1.9258e-01,  1.0770e-01,  2.8667e-01,  4.6398e-01,
        -1.5755e-01,  1.3169e-01,  4.4862e-01,  2.6414e-01,  3.1758e-01,
        -6.0301e-01, -4.5402e-01, -4.2952e-01,  3.5874e-02,  5.5162e-01,
        -5.3836e-01, -7.1347e-02, -1.7568e-02,  2.2044e-01,  2.9651e-02,
        -1.2368e-01, -7.7257e-02,  2.3676e-01, -2.3809e-01, -1.3321e-01,
        -7.0231e-02,  3.7284e-02, -3.4331e-01,  6.6826e-02, -2.8358e-01,
        -3.9088e-02,  1.5641e-01, -1.7911e-01, -8.2764e-02,  1.7015e-01,
         3.9405e-01,  2.4434e-01, -1.2021e-01,  2.6706e-01, -6.9555e-02,
         2.1861e-01,  2.4266e-01,  8.9720e-02,  2.2195e-01,  1.8686e-01,
         2.4524e-01, -4.0865e-01, -4.9193e-03, -5.8159e-02,  3.3084e-02])
Traceback (most recent call last):
  File "a3_model.py", line 70, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 47, in train
    output = self.model(instance)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "a3_model.py", line 19, in forward
    m = self.linear(x)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1371, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [1 x 400], m2: [4694 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ packet_write_wait: Connection to 130.241.53.60 port 62266: Broken pipe
(base) Julias-MacBook:~ juliaklezl$ ssh -p 62266 gusklezju@mltgpu.flov.gu.se
gusklezju@mltgpu.flov.gu.se's password: 
----------------------------------------
Welcome to the host mltgpu.flov.gu.se
Fedora 30 (Server Edition)
----------------------------------------
Support:

 Robert Adesam, robert.adesam@gu.se
----------------------------------------

Last login: Fri Mar 27 11:40:07 2020 from 46.239.124.106
[gusklezju@GU.GU.SE@mltgpu ~]$ cd lt2212-v20-a3
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
3    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
4    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
5     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
6    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2924  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2925  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2926  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2927 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2928  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
Int64Index([0, 1], dtype='int64')
(2347, 198)
torch.Size([198]) torch.Size([198])
Traceback (most recent call last):
  File "a3_model.py", line 70, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 45, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
3    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
4    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
5     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
6    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2924  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2925  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2926  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2927 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2928  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
              1
0     mccarty-d
3     mccarty-d
4     mccarty-d
5     mccarty-d
6     mccarty-d
...         ...
2924  donohoe-t
2925  donohoe-t
2926  donohoe-t
2927  donohoe-t
2928  donohoe-t

[2347 rows x 1 columns]
(2347, 198)
torch.Size([198]) torch.Size([198])
Traceback (most recent call last):
  File "a3_model.py", line 70, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 45, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
Traceback (most recent call last):
  File "a3_model.py", line 71, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 35, in train
    in1 = random.randint(0, len(documents))
NameError: name 'random' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
1787
2347
(2347, 198)
torch.Size([198]) torch.Size([198])
Traceback (most recent call last):
  File "a3_model.py", line 72, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 47, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
1706
2347
(2347, 198)
torch.Size([198]) torch.Size([198])
Traceback (most recent call last):
  File "a3_model.py", line 72, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 47, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
Traceback (most recent call last):
  File "a3_model.py", line 71, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 37, in train
    in_same = labels.loc[df[0] == labels[in1]]
NameError: name 'df' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
Traceback (most recent call last):
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexes/base.py", line 2890, in get_loc
    return self._engine.get_loc(key)
  File "pandas/_libs/index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 131, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 992, in pandas._libs.hashtable.Int64HashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 998, in pandas._libs.hashtable.Int64HashTable.get_item
KeyError: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "a3_model.py", line 72, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 37, in train
    in_same = labels.loc[labels[0] == labels[in1]]
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/frame.py", line 2975, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexes/base.py", line 2892, in get_loc
    return self._engine.get_loc(self._maybe_cast_indexer(key))
  File "pandas/_libs/index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 131, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 992, in pandas._libs.hashtable.Int64HashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 998, in pandas._libs.hashtable.Int64HashTable.get_item
KeyError: 0
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
Traceback (most recent call last):
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexes/base.py", line 2890, in get_loc
    return self._engine.get_loc(key)
  File "pandas/_libs/index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 131, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 992, in pandas._libs.hashtable.Int64HashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 998, in pandas._libs.hashtable.Int64HashTable.get_item
KeyError: 1014

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "a3_model.py", line 72, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 37, in train
    in_same = labels[labels.iloc[:,0:1] == labels[in1]]
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/frame.py", line 2975, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexes/base.py", line 2892, in get_loc
    return self._engine.get_loc(self._maybe_cast_indexer(key))
  File "pandas/_libs/index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 131, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 992, in pandas._libs.hashtable.Int64HashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 998, in pandas._libs.hashtable.Int64HashTable.get_item
KeyError: 1014
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
        1
0     NaN
3     NaN
4     NaN
5     NaN
6     NaN
...   ...
2924  NaN
2925  NaN
2926  NaN
2927  NaN
2928  NaN

[2347 rows x 1 columns]
(2347, 198)
torch.Size([198]) torch.Size([198])
Traceback (most recent call last):
  File "a3_model.py", line 72, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 47, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
        1
0     NaN
3     NaN
4     NaN
5     NaN
6     NaN
...   ...
2924  NaN
2925  NaN
2926  NaN
2927  NaN
2928  NaN

[2347 rows x 1 columns]
(2347, 198)
torch.Size([198]) torch.Size([198])
Traceback (most recent call last):
  File "a3_model.py", line 71, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 46, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexes/base.py", line 2890, in get_loc
    return self._engine.get_loc(key)
  File "pandas/_libs/index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 131, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 992, in pandas._libs.hashtable.Int64HashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 998, in pandas._libs.hashtable.Int64HashTable.get_item
KeyError: 2078

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "a3_model.py", line 73, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 36, in train
    auth = labels[in1]
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/frame.py", line 2975, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexes/base.py", line 2892, in get_loc
    return self._engine.get_loc(self._maybe_cast_indexer(key))
  File "pandas/_libs/index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 131, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 992, in pandas._libs.hashtable.Int64HashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 998, in pandas._libs.hashtable.Int64HashTable.get_item
KeyError: 2078
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
1    keiser-k
Name: 706, dtype: object
        1
0     NaN
3     NaN
4     NaN
5     NaN
6     NaN
...   ...
2924  NaN
2925  NaN
2926  NaN
2927  NaN
2928  NaN

[2347 rows x 1 columns]
(2347, 198)
torch.Size([198]) torch.Size([198])
Traceback (most recent call last):
  File "a3_model.py", line 73, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 48, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 73, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 36, in train
    auth = labels.iloc[in1, 1]
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexing.py", line 1404, in __getitem__
    return self._getitem_tuple(key)
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexing.py", line 2067, in _getitem_tuple
    self._has_valid_tuple(tup)
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexing.py", line 232, in _has_valid_tuple
    self._validate_key(k, i)
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexing.py", line 1989, in _validate_key
    self._validate_integer(key, axis)
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexing.py", line 2063, in _validate_integer
    raise IndexError("single positional indexer is out-of-bounds")
IndexError: single positional indexer is out-of-bounds
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
corman-s
        1
0     NaN
3     NaN
4     NaN
5     NaN
6     NaN
...   ...
2924  NaN
2925  NaN
2926  NaN
2927  NaN
2928  NaN

[2347 rows x 1 columns]
(2347, 198)
torch.Size([198]) torch.Size([198])
Traceback (most recent call last):
  File "a3_model.py", line 73, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 48, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
               1
363  salisbury-h
364  salisbury-h
365  salisbury-h
367  salisbury-h
368  salisbury-h
..           ...
494  salisbury-h
495  salisbury-h
496  salisbury-h
497  salisbury-h
498  salisbury-h

[106 rows x 1 columns]
(2347, 198)
torch.Size([198]) torch.Size([198])
Traceback (most recent call last):
  File "a3_model.py", line 72, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 47, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
              1
0     mccarty-d
3     mccarty-d
4     mccarty-d
5     mccarty-d
6     mccarty-d
...         ...
2924  donohoe-t
2925  donohoe-t
2926  donohoe-t
2927  donohoe-t
2928  donohoe-t

[2241 rows x 1 columns]
(2347, 198)
torch.Size([198]) torch.Size([198])
Traceback (most recent call last):
  File "a3_model.py", line 73, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 48, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
salisbury-h
              1
0     mccarty-d
3     mccarty-d
4     mccarty-d
5     mccarty-d
6     mccarty-d
...         ...
2924  donohoe-t
2925  donohoe-t
2926  donohoe-t
2927  donohoe-t
2928  donohoe-t

[2241 rows x 1 columns]
(2347, 198)
torch.Size([198]) torch.Size([198])
Traceback (most recent call last):
  File "a3_model.py", line 74, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 49, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
lenhart-m
              1
0     mccarty-d
3     mccarty-d
4     mccarty-d
5     mccarty-d
6     mccarty-d
...         ...
2924  donohoe-t
2925  donohoe-t
2926  donohoe-t
2927  donohoe-t
2928  donohoe-t

[1741 rows x 1 columns]
(2347, 198)
torch.Size([198]) torch.Size([198])
Traceback (most recent call last):
  File "a3_model.py", line 74, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 49, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
  File "a3_model.py", line 40
    if coin = 0:
            ^
SyntaxError: invalid syntax
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 78, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 43, in train
    ind2 = in_same.sample.index
AttributeError: 'function' object has no attribute 'index'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 78, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 44, in train
    print(in1, in2)
NameError: name 'in2' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
472 Int64Index([1566], dtype='int64')
(2347, 198)
torch.Size([198]) torch.Size([198])
Traceback (most recent call last):
  File "a3_model.py", line 78, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 53, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
2055 Int64Index([1213], dtype='int64')
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 51, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 41, in train
    in2 = in_diff.sample().index()
TypeError: 'Int64Index' object is not callable
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
1811               1
2462  lenhart-m
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 51, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 43, in train
    in2 = in_same.sample()
AttributeError: 'Int64Index' object has no attribute 'sample'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
1135 2810
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 51, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
168 199
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 51, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
1001 1515
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 51, in train
    label = same
NameError: name 'same' is not defined
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
1510 2058
Traceback (most recent call last):
  File "a3_model.py", line 74, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 50, in train
    output = self.model(instance)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "a3_model.py", line 20, in forward
    m = self.linear(x)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1371, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [1 x 400], m2: [4694 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
435 1017
torch.Size([200]) torch.Size([200])
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 51, in train
    output = self.model(instance)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "a3_model.py", line 20, in forward
    m = self.linear(x)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1371, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [1 x 400], m2: [4694 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
76 21
torch.Size([200]) torch.Size([200])
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 51, in train
    output = self.model(instance)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "a3_model.py", line 20, in forward
    m = self.linear(x)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1371, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [1 x 400], m2: [4694 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
772 2904
(2347, 200)
Traceback (most recent call last):
  File "a3_model.py", line 76, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 49, in train
    doc2 = torch.Tensor(docs[in2])
IndexError: index 2904 is out of bounds for axis 0 with size 2347
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
1782 1611
(2347, 200)
(2347, 200)
torch.Size([200]) torch.Size([200])
Traceback (most recent call last):
  File "a3_model.py", line 77, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 53, in train
    output = self.model(instance)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "a3_model.py", line 20, in forward
    m = self.linear(x)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1371, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [1 x 400], m2: [4694 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
4694
228 2180
(2347, 200)
(2347, 200)
torch.Size([200]) torch.Size([200])
Traceback (most recent call last):
  File "a3_model.py", line 78, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 54, in train
    output = self.model(instance)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "a3_model.py", line 20, in forward
    m = self.linear(x)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1371, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [1 x 400], m2: [4694 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
  File "a3_model.py", line 28
    self.model = AuthorPredict(200)*2)
                                     ^
SyntaxError: invalid syntax
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
1113 908
(2347, 200)
(2347, 200)
torch.Size([200]) torch.Size([200])
Traceback (most recent call last):
  File "a3_model.py", line 77, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 55, in train
    loss = criterion(output, label)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/loss.py", line 916, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1995, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1316, in log_softmax
    ret = input.log_softmax(dim)
IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 74, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 47, in train
    doc2 = torch.Tensor(docs[in2])
IndexError: index 2874 is out of bounds for axis 0 with size 2347
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 48, in train
    doc2 = torch.Tensor(docs[in2])
IndexError: index 2365 is out of bounds for axis 0 with size 2347
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
202
tensor([0.8867], grad_fn=<SigmoidBackward>)
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 53, in train
    loss = criterion(output, label)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/loss.py", line 916, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1995, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1316, in log_softmax
    ret = input.log_softmax(dim)
IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
tensor([0.4160], grad_fn=<SigmoidBackward>)
Traceback (most recent call last):
  File "a3_model.py", line 74, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 52, in train
    loss = criterion(output, label)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/loss.py", line 916, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1995, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 1316, in log_softmax
    ret = input.log_softmax(dim)
IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 73, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 51, in train
    loss = criterion(output, label)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/loss.py", line 498, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/usr/local/lib64/python3.7/site-packages/torch/nn/functional.py", line 2038, in binary_cross_entropy
    if target.size() != input.size():
AttributeError: 'int' object has no attribute 'size'
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
it does something
it does something
it does something
it does something
it does something
it does something
Traceback (most recent call last):
  File "a3_model.py", line 73, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 47, in train
    doc2 = torch.Tensor(docs[in2])
IndexError: index 2884 is out of bounds for axis 0 with size 2347
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
it does something
it does something
it does something
Traceback (most recent call last):
  File "a3_model.py", line 73, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 47, in train
    doc2 = torch.Tensor(docs[in2])
IndexError: index 2697 is out of bounds for axis 0 with size 2347
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 200)
(2347, 1)
it does something
(2347, 200)
(2347, 1)
it does something
(2347, 200)
(2347, 1)
it does something
(2347, 200)
(2347, 1)
it does something
(2347, 200)
(2347, 1)
it does something
(2347, 200)
(2347, 1)
it does something
(2347, 200)
(2347, 1)
it does something
(2347, 200)
(2347, 1)
it does something
(2347, 200)
(2347, 1)
it does something
(2347, 200)
(2347, 1)
it does something
(2347, 200)
(2347, 1)
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 49, in train
    doc2 = torch.Tensor(docs[in2])
IndexError: index 2745 is out of bounds for axis 0 with size 2347
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(498,)
it does something
(106,)
it does something
(606,)
it does something
(498,)
it does something
(498,)
it does something
(606,)
Traceback (most recent call last):
  File "a3_model.py", line 74, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 48, in train
    doc2 = torch.Tensor(docs[in2])
IndexError: index 2377 is out of bounds for axis 0 with size 2347
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Int64Index([ 925,  926,  927,  928,  929,  930,  931,  932,  933,  935,
            ...
            1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554],
           dtype='int64', length=498)
it does something
Int64Index([2130, 2131, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140,
            ...
            2884, 2885, 2886, 2888, 2891, 2892, 2893, 2894, 2895, 2896],
           dtype='int64', length=606)
it does something
Int64Index([1611, 1612, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621,
            ...
            2105, 2106, 2107, 2108, 2110, 2111, 2112, 2113, 2114, 2115],
           dtype='int64', length=405)
it does something
Int64Index([1555, 1556, 1557, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566,
            1567, 1568],
           dtype='int64')
it does something
Int64Index([1611, 1612, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621,
            ...
            2105, 2106, 2107, 2108, 2110, 2111, 2112, 2113, 2114, 2115],
           dtype='int64', length=405)
it does something
Int64Index([2130, 2131, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140,
            ...
            2884, 2885, 2886, 2888, 2891, 2892, 2893, 2894, 2895, 2896],
           dtype='int64', length=606)
Traceback (most recent call last):
  File "a3_model.py", line 74, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 48, in train
    doc2 = torch.Tensor(docs[in2])
IndexError: index 2476 is out of bounds for axis 0 with size 2347
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
            1
560  keiser-k
561  keiser-k
562  keiser-k
563  keiser-k
565  keiser-k
..        ...
920  keiser-k
921  keiser-k
922  keiser-k
923  keiser-k
924  keiser-k

[308 rows x 1 columns]
Traceback (most recent call last):
  File "a3_model.py", line 74, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 48, in train
    doc2 = torch.Tensor(docs[in2])
IndexError: index 2846 is out of bounds for axis 0 with size 2347
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
^[[B             1
925   corman-s
926   corman-s
927   corman-s
928   corman-s
929   corman-s
...        ...
1550  corman-s
1551  corman-s
1552  corman-s
1553  corman-s
1554  corman-s

[498 rows x 1 columns]
it does something
               1
363  salisbury-h
364  salisbury-h
365  salisbury-h
367  salisbury-h
368  salisbury-h
..           ...
494  salisbury-h
495  salisbury-h
496  salisbury-h
497  salisbury-h
498  salisbury-h

[106 rows x 1 columns]
Traceback (most recent call last):
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexes/base.py", line 2890, in get_loc
    return self._engine.get_loc(key)
  File "pandas/_libs/index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 131, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 992, in pandas._libs.hashtable.Int64HashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 998, in pandas._libs.hashtable.Int64HashTable.get_item
KeyError: 51

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "a3_model.py", line 74, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 44, in train
    in2 = random.choice(in_same)
  File "/usr/lib64/python3.7/random.py", line 262, in choice
    return seq[i]
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/frame.py", line 2975, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/indexes/base.py", line 2892, in get_loc
    return self._engine.get_loc(self._maybe_cast_indexer(key))
  File "pandas/_libs/index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 131, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 992, in pandas._libs.hashtable.Int64HashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 998, in pandas._libs.hashtable.Int64HashTable.get_item
KeyError: 51
^[[B[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Int64Index([1611, 1612, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621,
            ...
            2105, 2106, 2107, 2108, 2110, 2111, 2112, 2113, 2114, 2115],
           dtype='int64', length=405)
it does something
Int64Index([1611, 1612, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621,
            ...
            2105, 2106, 2107, 2108, 2110, 2111, 2112, 2113, 2114, 2115],
           dtype='int64', length=405)
it does something
Int64Index([ 925,  926,  927,  928,  929,  930,  931,  932,  933,  935,
            ...
            1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554],
           dtype='int64', length=498)
it does something
Int64Index([172, 173, 175, 177, 179, 180, 182, 183, 184, 185,
            ...
            310, 312, 313, 314, 315, 316, 317, 318, 319, 320],
           dtype='int64', length=122)
it does something
Int64Index([2130, 2131, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140,
            ...
            2884, 2885, 2886, 2888, 2891, 2892, 2893, 2894, 2895, 2896],
           dtype='int64', length=606)
it does something
Int64Index([1611, 1612, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621,
            ...
            2105, 2106, 2107, 2108, 2110, 2111, 2112, 2113, 2114, 2115],
           dtype='int64', length=405)
it does something
Int64Index([ 925,  926,  927,  928,  929,  930,  931,  932,  933,  935,
            ...
            1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554],
           dtype='int64', length=498)
Traceback (most recent call last):
  File "a3_model.py", line 74, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 48, in train
    doc2 = torch.Tensor(docs[in2])
IndexError: index 2896 is out of bounds for axis 0 with size 2347
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
it does something
it does something
it does something
it does something
Traceback (most recent call last):
  File "a3_model.py", line 73, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 47, in train
    doc2 = torch.Tensor(docs[in2])
IndexError: index 2648 is out of bounds for axis 0 with size 2347
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 50, in train
    instance = torch.cat((doc1, doc2), 0)
RuntimeError: invalid argument 0: Tensors must have same number of dimensions: got 1 and 2 at /pytorch/aten/src/TH/generic/THTensor.cpp:680
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Int64Index([812], dtype='int64')
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 50, in train
    instance = torch.cat((doc1, doc2), 0)
RuntimeError: invalid argument 0: Tensors must have same number of dimensions: got 1 and 2 at /pytorch/aten/src/TH/generic/THTensor.cpp:680
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
102
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 50, in train
    instance = torch.cat((doc1, doc2), 0)
RuntimeError: invalid argument 0: Tensors must have same number of dimensions: got 1 and 2 at /pytorch/aten/src/TH/generic/THTensor.cpp:680
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 46, in train
    print(in2[0])
IndexError: invalid index to scalar variable.
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 74, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 48, in train
    doc2 = torch.Tensor(docs[in2])
IndexError: index 2557 is out of bounds for axis 0 with size 2347
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ Abgemeldet
Connection to mltgpu.flov.gu.se closed.
(base) Julias-MacBook:~ juliaklezl$ ssh -p 62266 gusklezju@mltgpu.flov.gu.se
gusklezju@mltgpu.flov.gu.se's password: 
----------------------------------------
Welcome to the host mltgpu.flov.gu.se
Fedora 30 (Server Edition)
----------------------------------------
Support:

 Robert Adesam, robert.adesam@gu.se
----------------------------------------

Last login: Fri Mar 27 16:46:11 2020 from 46.239.124.106
[gusklezju@GU.GU.SE@mltgpu ~]$ cd lt2212-v20-a3/
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
2929
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 48, in train
    doc2 = torch.Tensor(docs[in2])
IndexError: index 2574 is out of bounds for axis 0 with size 2347
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 200)
it does something
(2347, 200)
it does something
(2347, 200)
it does something
(2347, 200)
it does something
(2347, 200)
it does something
(2347, 200)
it does something
(2347, 200)
it does something
(2347, 200)
it does something
(2347, 200)
it does something
(2347, 200)
it does something
(2347, 200)
it does something
(2347, 200)
it does something
(2347, 200)
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 49, in train
    doc2 = torch.Tensor(docs[in2])
IndexError: index 2734 is out of bounds for axis 0 with size 2347
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
(2347, 200)
it does something
(2347, 200)
Traceback (most recent call last):
  File "a3_model.py", line 76, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 50, in train
    doc2 = torch.Tensor(docs[in2])
IndexError: index 2661 is out of bounds for axis 0 with size 2347
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
(2347, 202)
it does something
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 48, in train
    doc2 = torch.Tensor(docs[in2])
IndexError: index 2595 is out of bounds for axis 0 with size 2347
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 42, in train
    in2 = in_diff.sample().index[0]
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/generic.py", line 4971, in sample
    locs = rs.choice(axis_length, size=n, replace=replace, p=weights)
  File "mtrand.pyx", line 1119, in mtrand.RandomState.choice
ValueError: 'a' must be greater than 0 unless no samples are taken
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Traceback (most recent call last):
  File "a3_model.py", line 75, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 41, in train
    in2 = random.choice(in_diff)
  File "/usr/lib64/python3.7/random.py", line 261, in choice
    raise IndexError('Cannot choose from an empty sequence') from None
IndexError: Cannot choose from an empty sequence
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
          0
0     train
1     train
2     train
3     train
4     train
...     ...
2342  train
2343  train
2344  train
2345  train
2346  train

[2347 rows x 1 columns]
Empty DataFrame
Columns: [0]
Index: []
Traceback (most recent call last):
  File "a3_model.py", line 77, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 43, in train
    in2 = random.choice(in_diff)
  File "/usr/lib64/python3.7/random.py", line 261, in choice
    raise IndexError('Cannot choose from an empty sequence') from None
IndexError: Cannot choose from an empty sequence
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2347)
Int64Index([], dtype='int64')
Traceback (most recent call last):
  File "a3_model.py", line 77, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 49, in train
    doc1 = torch.Tensor(docs[in1])
TypeError: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool.
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2347)
Int64Index([], dtype='int64')
['keiser-k' -4.973389930802514 3.2543733719087413 -0.3992503310934258
 0.7083756017785031 -2.3235061875723555 1.4239474492809543
 -0.9677288508187132 -0.08297945145690262 0.6904644889131809
 -0.4120727628120273 1.7274012629293396 -0.4924480177642533
 -0.21457518562686492 -0.5901699683694257 -1.1953831451458912
 -0.05598915801165198 1.6104440323670766 -1.0373358507025572
 -1.2851153315212136 -1.1492985248437229 0.6855172219696555
 -0.6364960403939985 -0.7888324711094484 0.3406808498082944
 -0.6102071664030045 1.5052392698433974 1.6995899887220445
 0.3527454823816066 -0.5068331481006061 -1.0012552100771808
 0.3175658357591086 -1.237225647536551 -0.004894005506807968
 -0.3399650291796535 0.2275992425987821 0.6665870289789588
 -0.9061531333313728 -0.1475501451125141 1.1129182012067007
 0.8045742834487142 0.4057639611935427 0.7371127125335527
 -0.16895576264289136 -0.13712415210152293 1.4222950876492206
 -0.3919065498901708 0.061584264970811015 0.20789423307417326
 0.34878713525569705 -0.5200554545844526 0.16439200053536426
 0.34645752308641764 1.0158121437749934 0.3085004688288769
 0.6217178853087261 0.22962677841804804 0.28207526965857505
 -0.5442037822414701 1.3069919978816955 -0.27065479754552835
 0.2721155607494741 -0.7843597011415225 -0.03742257105758117
 -0.1498072425280968 -0.6061332509591341 0.015712620287264608
 0.18002423944567322 -0.1940271784377975 -0.475114919613989
 0.4338034918271809 0.6186213409961107 -0.36364174325299614
 -0.2350218585959736 0.795875123178911 0.043861113362588085
 0.2500920487718081 -0.1347306454130283 -0.0491276885528327
 0.09837741822153878 0.5707714826357105 0.6145581805344459
 -0.5052504989986635 -0.4423636849336624 -0.08611250105445055
 -0.1908748582811727 0.14940270008865625 -0.28267424238183403
 -0.4061827461754184 0.04264036666326281 -0.014909000488233529
 -0.13311402992759175 -0.08435106159389799 0.3814650162008924
 -0.3237017174834248 -0.4650888519232869 0.3616049627060568
 -0.005016842540609186 -0.1921029476938351 0.27956255314728745
 -0.24391126435531954 0.3904632738175213 -0.2679347062546363
 -0.2144249134100241 0.10954456555001556 -0.06257307944624968
 0.3907479622994296 1.1809594272282349 0.5403042981968612
 -0.3536369797635001 -0.6992485459417135 -0.20645095313391826
 -0.3310655205959851 -0.11667557171165477 0.3997345674308612
 -0.14195311906694433 -0.4599415708474253 0.03554275056512466
 0.6755532274598427 0.07845324717242702 -1.3626873109633937
 0.3513507973399393 -0.8037033671567572 -0.2653308943783479
 0.2762627739149389 -0.021221928983322633 -0.2702352148217568
 -0.6418334631506961 -0.2659854094955402 -0.21662501475443435
 -0.2869860916000217 0.4872389878461625 -0.14960892600525616
 0.0006303189216591435 0.024402628757086944 0.3863487293601823
 0.542583904100012 0.5134744893904017 0.7570372144918306
 -0.1477563442779002 -0.693324215044921 -0.10014937558479273
 -0.3317993301340196 -0.22881186116149074 0.05752473227302856
 0.4412485580998139 -0.2576231163449131 -0.024479408032770544
 -1.1778769225558936 -0.4369301658291324 0.7454188655586835
 0.32974143926208194 0.39687523689601695 -0.5809458268209254
 0.010070424769746306 0.9630570049443627 0.6824214796464859
 0.2482751017920417 0.7602632824344977 -0.5147095604163034
 0.5033957505795037 -0.3197928692510075 0.6542183109141183
 0.6467396637400591 0.3070895468502822 0.7273644126228437
 0.022365442806846 0.17056647473621586 0.15777253428547286
 -0.32521834985159537 -0.6093667210530713 -0.23043516495809266
 -0.4005438836565979 0.6665648643602936 -0.3962060187785175
 0.02906174901628715 0.5699967843136621 0.2296288542144926
 -0.08865348355934388 -0.11699900117925567 0.505591039241146
 0.03946293572448584 0.065309068881856 0.6360375171863986
 -0.08800704520192984 0.14198916709704312 0.3391774162858049
 0.09929337600850392 -0.7052791930099898 -0.5514770505614234
 -0.29116038102626884 0.5212090188433642 -0.29131730585738674
 0.28841012285377543 -0.17092043601886114 0.19880226175503254
 -0.4377886400751411 -0.31954941551177063 -0.13921728943159994
 -0.4285312241164526 -0.10724001205100013]
Traceback (most recent call last):
  File "a3_model.py", line 78, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 50, in train
    doc1 = torch.Tensor(docs[in1])
TypeError: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool.
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2347)
Int64Index([], dtype='int64')
            1          2         3    ...       199       200       201
0     mccarty-d  12.569812  7.116670  ...  1.044004  0.414233 -1.305085
1     mccarty-d -10.287848  3.004242  ... -0.120575  0.003828  0.008953
2     mccarty-d -12.165009  3.170589  ... -0.043131  0.159112 -0.108517
3     mccarty-d  33.162786  3.473576  ... -0.307094 -0.149677  0.318996
4     mccarty-d -12.175201  3.176557  ... -0.021838  0.119506 -0.097123
...         ...        ...       ...  ...       ...       ...       ...
2342  donohoe-t  -9.629141  2.435916  ...  0.038196  0.201126  0.018585
2343  donohoe-t  -9.029024  2.322203  ...  0.069299  0.140847 -0.209329
2344  donohoe-t  -8.855967  3.062206  ... -0.007930  0.125075  0.001855
2345  donohoe-t -10.706339  2.925712  ... -0.054549  0.022303 -0.044119
2346  donohoe-t  11.300004 -4.142375  ... -0.681583 -0.174028 -0.134946

[2347 rows x 201 columns]
['salisbury-h' -11.922528979941356 2.680983928870121 2.1584486928971214
 0.15473425518265804 0.1996979638967033 -0.00856908184363634
 0.5322336588634093 0.5315555246709422 -0.1772147110757772
 0.1916711525184192 -0.4035811491617992 0.08234292152479628
 -0.19793841735108075 0.25375744209034845 -0.3162540740871434
 0.05090164039586827 0.008262884391379793 0.12049340356422805
 -0.9564425626206966 -0.34287509705556435 -0.11050289480466577
 -0.3893739555518408 -0.4395731583428739 0.6538805259219185
 0.09482208227930644 0.4351376708150512 0.13517791750944372
 0.013552677369148013 0.02168018720371689 0.15527727793381255
 -0.09591954874299764 0.06634066890631747 -0.11115850590383658
 0.4035032201621342 0.20507704006550886 -0.20075462074010544
 0.00862009048011847 0.2254927105381412 0.3166680592970175
 0.3958593529694282 -0.06457157231263895 -0.6254471995783579
 0.1287761226932989 -0.12726537268594315 0.724577374574459
 0.006115274217847889 -0.019456684919948355 0.005576663849528101
 0.0925846059774939 0.07830195559444697 -0.10056186026694222
 -0.3231245905775827 0.012695319141744741 0.00896773995638856
 -0.04798414965455969 -0.09816547442385046 -0.04839182163375271
 0.3640191451721017 -0.2023715375399412 -0.8110246402466941
 -0.09432657710112542 -0.36105273830444784 0.2268696581594946
 -0.03836085889906072 0.3889446105847838 -0.22070879439884514
 0.3425345111507925 -0.15641769061854693 -0.03853673615243253
 0.4862707385883096 0.06263020883799979 0.14682628927278266
 -0.04263606365824234 0.01718953481846039 -0.3071716675200689
 0.42459524934271226 -0.07988236767868608 -0.12073288591812555
 -0.05994915252007532 -0.4090422715593284 0.045482969461449564
 -0.07646995136945615 -0.22211709358109205 -0.20677801284346575
 -0.017851940566604815 -0.02055874205842001 0.34703375466513736
 -0.12671718460854667 -0.3220345380786152 -0.2699877108672101
 -0.1570676379744897 -0.15446448519071804 0.004656675737158418
 0.22693152409731301 -0.16835037682555093 0.028460017408914587
 0.1351735793089118 -0.006947316529189235 0.4148732796882234
 0.04589320220686243 -0.12334825020610815 -0.34531255644008585
 0.004246223368445886 -0.22594585852552854 -0.021527614163148967
 -0.3227576620135091 0.3484409746182633 -0.11367429834876598
 0.2175351693990372 -0.08980775118152874 -0.09506616469556843
 0.1473703906513412 0.06782909749481944 -0.2730417820005817
 0.02899233200678726 0.3041804387929996 -0.0451219371110086
 -0.1512489232641565 -0.21223874686144367 0.1209671054325077
 -0.08060421441457823 0.035553961787160485 0.2569637997333783
 0.209649943337996 0.05432272404485103 -0.08292089047512195
 0.01304460371113284 -0.2283542916969928 0.0021823786284045034
 0.2410060206485561 0.06542034011300217 -0.35484841927787797
 0.010011252634371607 -0.043268328244461536 -0.0976159687536418
 0.1856999802819612 0.056791780321787 0.010405238645150784
 0.06299592598597323 -0.21522659901679506 -0.0864219326421523
 0.21548918076571985 0.015555537655470037 0.056523508508047035
 -0.01235834243481755 0.2732345978093489 -0.011184202743378384
 0.09822525141305362 0.015031020442565775 0.00048473235766344815
 0.2394552375610597 0.027848166855762226 0.02724469330163222
 0.20314041462277665 0.21894396376798814 0.012368798322556444
 0.04437261914328015 0.04575230354888051 -0.12052568650452575
 -0.012201017352485905 0.039392387005926455 0.003344495378854795
 -0.059469293556723576 0.05180736792753325 0.17074695093968226
 0.1043493798781962 0.14685661346199738 -0.22436580263067846
 0.13928557563773636 -0.0031716083257000197 0.15157086736686592
 0.041847780180174966 -0.007267211584889981 -0.050645113032946575
 -0.1072266564603511 0.05391765330901952 -0.08012764850289501
 0.0907995382382719 -0.0807019037204557 0.011212532230456294
 -0.04091618072679891 0.01278252828435821 -0.14958436564504074
 0.11478530159157145 -0.12803856993480775 0.02299562979181449
 0.14995852155156006 -0.18345929725074187 -0.09830732825417984
 -0.018435321584460537 0.014738642653193303 0.17075752288376328
 0.07588193160838401 -0.08183027272630931 -0.08935155603237464
 -0.008346814732520368 0.02554765511080586 0.10286618537076174
 -0.25157116578401284 -0.03752288737013268]
Traceback (most recent call last):
  File "a3_model.py", line 79, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 51, in train
    doc1 = torch.Tensor(docs[in1])
TypeError: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool.
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2347)
Int64Index([], dtype='int64')
        0          2         3    ...       199       200       201
0     train  12.569812  7.116670  ...  1.044004  0.414233 -1.305085
1     train -10.287848  3.004242  ... -0.120575  0.003828  0.008953
2     train -12.165009  3.170589  ... -0.043131  0.159112 -0.108517
3     train  33.162786  3.473576  ... -0.307094 -0.149677  0.318996
4     train -12.175201  3.176557  ... -0.021838  0.119506 -0.097123
...     ...        ...       ...  ...       ...       ...       ...
2342  train  -9.629141  2.435916  ...  0.038196  0.201126  0.018585
2343  train  -9.029024  2.322203  ...  0.069299  0.140847 -0.209329
2344  train  -8.855967  3.062206  ... -0.007930  0.125075  0.001855
2345  train -10.706339  2.925712  ... -0.054549  0.022303 -0.044119
2346  train  11.300004 -4.142375  ... -0.681583 -0.174028 -0.134946

[2347 rows x 201 columns]
['train' -9.246027471526872 2.225109229494372 1.1883515679274543
 0.1693605600617547 -0.9515439017946884 -0.14762249668819913
 0.7036200790899276 -1.2226353071949807 -1.0488455388640183
 0.1925834690429145 -0.1030851674131862 0.8757021346367522
 0.4443005413348193 -0.4198575663097879 0.08053659809395168
 -0.34739498532653523 -0.4005136190623155 -0.23280830113415515
 0.5416187150407545 0.04784719281372856 -0.6568783766101624
 -0.15281884500885626 -0.09892021532926183 -0.06959397913275288
 0.32880647137886543 0.5940289226510518 0.4580954062211831
 -0.8167465293889642 0.29430527741220125 1.4171137017520563
 0.7246567661102512 0.2795641233673624 -0.2259500788720237
 0.9679045600471268 0.5851384256408328 -0.2222400043808503
 0.7714041903414139 0.2792302877798414 -0.33535473637773444
 -0.3290772725337829 0.2294218671935697 0.34386478963475203
 -0.7863359420906484 -0.4833075886220653 0.4966637099683037
 0.17550215827452384 0.1118058895187753 0.17664236788544346
 -0.02626718727750744 0.2794033799481393 -0.8321971870690927
 -0.4543113619184404 -0.7167773903980038 -0.4064090764093851
 0.008705774589187707 -0.7208669660623696 -0.02428982358073645
 0.3166251054467181 -0.700317941187226 -0.7462712882400226
 -0.3258095974091379 -0.6859949135941867 0.4560297863678629
 -0.20162914559865824 -0.36013641914777444 -0.4975216929518677
 0.7756800136946442 -0.03723487491088908 0.12329055026536555
 0.5538833693209998 -0.053283797251064816 -0.04156057550540453
 -0.6261402216741795 0.5776108768194889 -0.2090222368638927
 0.3336786964328507 0.2673791676413942 -0.3888658664371688
 0.24635911606515895 -0.3307712129949388 0.08385292693126112
 -0.4620670237880821 -0.09495265459778507 -0.3252704181443639
 -0.23401596172566205 0.13742306146416022 0.8461656395519538
 0.3371477671305055 0.10883848509509746 -0.712372848901934
 -0.3022582074889767 -0.6441363215326501 -0.3856369175460234
 -0.3742521032424855 0.06860656924295808 -0.13098375620073624
 0.03456235558615533 -0.3763482930190318 -0.2153734964081863
 0.4136323096496574 -0.17053766557621236 -0.020276263885548332
 -0.03263082548477303 -0.3404888714192194 -0.2898622384188769
 0.007271795659035714 1.111308216353645 -0.2179678532261364
 -0.3573904234461244 -0.0303574321547345 -0.11811775273814837
 0.7044340724529241 -0.23858047475989744 -0.6815594677148624
 0.2380813707044112 0.4425262934384887 0.3692398399713455
 -0.1889974827815732 -0.3011327435111793 0.08102518241532541
 -0.08221038993544645 0.4278878884326293 0.2567469335802079
 -0.06882111839042925 0.30408395789062365 -0.24892588913839125
 -0.1683006408812357 -0.08172142094221392 0.12539644138507414
 0.6009280921890342 -0.2292557298062229 -0.27367106940165864
 -0.5069666641613425 -0.01032232122935608 -0.06786513023506219
 0.4198336014211113 0.3298742443309026 0.16214291294671074
 0.198226711319504 0.03403743492130445 0.08048156841351997
 0.06824685294936407 0.09851786817393016 0.14853453413164486
 -0.2480493999876913 -0.03254503588342967 -0.4829155468618955
 0.1950610824937397 0.030285695325175523 -0.015591108840129238
 0.00490283529976196 0.3882833727654181 0.17472603355979527
 0.3580989753511524 0.4205693307576806 0.25602061880640337
 0.0534448700025745 -0.22323458898651408 -0.19715410012881807
 0.04275043406592933 0.08689287156453639 -0.020310092822383188
 -0.4347127128387203 -0.1676334656631667 0.044447598317823495
 -0.11830999486575625 0.1014282607563612 -0.5688811108797485
 0.0759342736687196 -0.284443492357779 0.16720085889959072
 0.05808860499034176 -0.24973515559205006 0.2892084667737644
 0.2185935957834754 0.13769300916786673 -0.14115111347373768
 -0.4933466998030526 0.05542017154022805 0.06215523035533947
 -0.2924964544884183 0.014314579846397441 -0.16862378318397614
 0.11488857791152847 -0.18721192437844045 -0.4244247254505646
 0.3030591520396892 -0.2253076846191285 -0.08709512634390576
 -0.2396450642646403 -0.013806147526997523 0.4364607823652604
 0.2655184953636341 0.27451455262264496 0.07253728156553813
 0.17467577120261996 0.0475383268046201 -0.005535237377081195
 -0.1734976125415004 -0.047154070450225946]
Traceback (most recent call last):
  File "a3_model.py", line 79, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 51, in train
    doc1 = torch.Tensor(docs[in1])
TypeError: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool.
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2347)
Int64Index([], dtype='int64')
      index          2         3  ...       199       200       201
0         0  12.569812  7.116670  ...  1.044004  0.414233 -1.305085
1         3 -10.287848  3.004242  ... -0.120575  0.003828  0.008953
2         4 -12.165009  3.170589  ... -0.043131  0.159112 -0.108517
3         5  33.162786  3.473576  ... -0.307094 -0.149677  0.318996
4         6 -12.175201  3.176557  ... -0.021838  0.119506 -0.097123
...     ...        ...       ...  ...       ...       ...       ...
2342   2924  -9.629141  2.435916  ...  0.038196  0.201126  0.018585
2343   2925  -9.029024  2.322203  ...  0.069299  0.140847 -0.209329
2344   2926  -8.855967  3.062206  ... -0.007930  0.125075  0.001855
2345   2927 -10.706339  2.925712  ... -0.054549  0.022303 -0.044119
2346   2928  11.300004 -4.142375  ... -0.681583 -0.174028 -0.134946

[2347 rows x 201 columns]
[ 1.53000000e+02  5.96114518e-01  5.16667483e+00  1.37191298e+00
 -3.99431539e-01  9.13674386e-01  7.38268992e-01 -8.70905626e-01
  9.59923609e-01 -6.53373882e-01  4.41603976e-01  2.09773826e+00
  6.14671711e-01  1.38898006e+00  1.32683223e+00 -1.08077155e+00
 -3.95135797e-01 -7.33373748e-01 -7.06134530e-01 -6.22259435e-01
  9.68404591e-01 -1.43500129e+00  1.98345119e-01 -2.14714873e-01
 -5.94280142e-01 -5.48871236e-01  8.52680618e-01 -1.14130452e+00
 -2.61349566e-01 -8.04594748e-01  4.67945296e-01  4.14191786e-01
  3.74251845e-01  8.01703537e-01 -8.25267488e-02  3.11029672e-01
  1.09512463e-01  1.51103538e+00 -9.88369909e-01 -2.54784216e-01
  1.80388052e-01 -6.33790527e-01  3.53365409e-01 -3.76118289e-01
 -1.92340717e+00  2.98061343e-01 -9.66867107e-01 -9.66562705e-01
 -5.39939356e-01  5.58846936e-01 -3.95998524e-01 -3.71194902e-01
  4.80544873e-01 -7.24111253e-01  1.81606185e-02 -1.04435533e+00
  2.18431483e-01  8.35944226e-01 -1.15683544e+00 -1.93326300e-01
  1.81195899e-01  5.00386278e-01  7.98801580e-01  1.48528788e-01
  1.09230384e-01  1.75878190e-02  5.88277009e-01  1.16127816e-01
 -1.89779322e-01 -6.80680314e-01  8.06583829e-01 -2.83941146e-01
  6.97659501e-01 -2.03428881e-01 -1.25444104e+00  9.73657987e-01
 -9.08472846e-02  3.45034256e-02  2.58218729e-01 -1.12504607e-02
 -3.38625161e-01 -4.04243759e-01  6.12800964e-01 -3.22266520e-01
  3.61397364e-01  1.74354194e-01 -1.17191186e+00  2.23178148e-01
 -2.81313852e-02  1.11943922e+00 -5.14775784e-01 -5.90556461e-01
 -4.45098804e-01 -4.69233587e-02  5.85784714e-01  1.80682749e-01
 -2.51617387e-01  1.11897294e+00 -5.39551677e-01 -3.13890592e-01
  1.13940607e+00 -1.01265575e+00 -2.65850498e-01  1.18971613e-01
  1.56153892e-01  3.16421482e-01  5.24069675e-02  4.48479302e-01
 -6.08048383e-01 -5.84770704e-01  6.81825299e-01  3.44160913e-02
 -6.00165445e-01  9.79920185e-02 -3.29984445e-01 -3.57601251e-01
 -2.24493845e-01 -6.19576047e-01  4.58404965e-01  1.15622068e-01
 -3.84314320e-02  6.03016150e-01 -3.21569389e-02 -5.68927692e-01
 -3.84159225e-01 -1.67006376e-01 -6.95127752e-01  1.28091330e-01
  3.13573841e-01 -3.59773948e-01 -5.34844089e-01 -1.66380835e-01
  3.62500785e-01 -3.33764544e-01 -6.46510338e-01 -2.49804732e-01
  3.56505780e-02  1.76102035e-01  6.13111200e-01  3.70631416e-01
 -1.73587576e-01 -1.73360886e-02  2.13224113e-01 -8.12044869e-01
  5.64358160e-01  1.94362169e-01 -7.78938917e-02 -4.55804962e-01
  4.22506265e-01  2.59243203e-01 -6.42300491e-01 -6.77551462e-02
  8.28958326e-02 -5.37071745e-01  4.18916622e-01  9.92125185e-02
  2.26065964e-01 -3.15743920e-01  1.01788892e+00 -6.80266397e-01
  1.97461155e-01 -6.66767733e-02  1.63033741e-01 -6.38233818e-01
  4.16310126e-01  4.71294356e-01  8.37363998e-01  4.33751649e-01
 -6.44798449e-01 -7.11052239e-01 -5.58374926e-02  7.55410120e-01
  1.91097666e-01  4.56797492e-01  5.15990117e-01 -2.42485577e-01
 -5.01983376e-01 -1.40663297e-01 -1.08876847e+00  2.99225109e-01
 -1.26046526e+00 -4.42686655e-02 -1.03505835e-01 -5.23778401e-01
 -3.40374911e-01  5.53865662e-01  6.10020228e-01 -1.29986294e-01
 -6.24934470e-01 -1.02582487e-01 -8.56926457e-02  2.84418159e-01
  3.63368296e-01  5.74639860e-01 -7.23523120e-01 -6.28701572e-01
 -8.49482267e-01  1.26081779e-01  1.77360629e-02 -2.56806967e-01
  4.24880785e-01]
it does something
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2347)
Int64Index([], dtype='int64')
Traceback (most recent call last):
  File "a3_model.py", line 79, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 43, in train
    in2 = random.choice(in_diff)
  File "/usr/lib64/python3.7/random.py", line 261, in choice
    raise IndexError('Cannot choose from an empty sequence') from None
IndexError: Cannot choose from an empty sequence
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Int64Index([1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724,
            ...
            2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320],
           dtype='int64', length=606)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1741)
        0         3          4    ...       199       200       201
0     train  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1     train  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2     train  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     train  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4     train  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...     ...       ...        ...  ...       ...       ...       ...
2342  train  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  train  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  train  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345  train  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  train -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
['train' 1.575178850237424 1.862737450564797 0.6098242869757706
 0.32332580623451296 -0.7891728649791706 0.7804459400625743
 0.2464547291989172 -0.5555174919217847 0.328327100586673
 -0.3366319075797288 -0.7376890603447278 -0.4329224071423107
 0.11319798448963565 0.5613089312818436 0.8854502618785217
 0.2148388990159882 -0.301368500476551 -0.3612000309815467
 -0.4308416372281637 -0.17362434502425933 0.7003447950143783
 -0.17009045466812142 0.23141067740875798 -0.050588371595830864
 -0.033223527663937484 0.10850185768215848 0.03546265786525723
 -0.3626327456067743 0.3933839818376532 0.3388719111874553
 0.2696311994168661 -0.4542724659214688 0.12104661706558208
 -0.04856699510877894 0.6526301080249258 0.22115543619952585
 0.0023550306860678914 0.1603547063899153 0.14154067186175742
 -0.01889792927867131 -0.4559388625396438 0.3699260813485961
 -0.09858343246531133 0.5391608534835531 -0.21836879315809185
 0.2736862571361524 -0.08557904908075192 -0.5688392782395113
 0.04429399195590725 0.08195966945668165 -0.011018405456396612
 -0.1390343457995253 0.23951702419700185 -0.05394672615901788
 0.2227057310941772 -0.2603311777774752 -0.00945437512492967
 -0.37025592013016784 -0.015607162545653213 0.46806919119749
 0.08169108581084329 0.206121692709696 0.4961074739745586
 -0.4817625289122739 -0.052313657807951636 -0.3006394426728009
 0.2741935434251367 -0.16143488541722628 0.0039515614357091035
 0.1057105896391352 -0.1565349192554673 0.1470519796608908
 0.008425686618965433 -0.13439813189374855 -0.1296543909781976
 -0.2891874375423911 0.2692354220408477 0.30458459061994325
 0.31242278628592995 0.06197975222468804 -0.03069380377440605
 -0.059618590348259164 0.09494534936386737 -0.0012378135056477881
 0.07345360816448065 0.12276241634700533 0.13564695842779853
 0.011130596746558152 0.2416371462737351 -0.22256263924771194
 0.10136412245912177 0.2530848647744992 -0.08030398218688835
 -0.18753697241548736 0.16956348428942264 -0.2690755021618495
 0.3987852113915704 0.14559376030336035 0.08806684134962751
 -0.10404443504128964 -0.2981337166733925 -0.09710062426906653
 0.3280406740738714 -0.0392532795548387 0.049074844103149766
 -0.11751781114881085 -0.0978572388850273 -0.0051577915833468145
 -0.09367276070971932 0.16829550760369166 0.05093195870249996
 -0.1189298554917451 -0.02294734966856132 0.08493672414332519
 -0.16932879559507594 -0.12123732410051598 -0.1552703610074216
 0.09296726950645168 -0.09627996422088876 0.1927274756576812
 -0.10756127180868734 -0.096691449128786 -0.10341630182390334
 -0.02653839862544561 -0.19453695448294214 -0.09819394585345943
 0.008157538713943152 -0.2000495327792388 0.1549239247052562
 0.03685971052909838 -0.08848789644146493 0.034572315211919634
 0.20271227454761334 -0.04894805994896414 -0.062039038397169524
 0.0909823133890364 0.11682031580230952 0.27722442423333793
 -0.11550664192994888 -0.23338366939072386 0.2124266431893304
 -0.20729141563384626 0.13218903160042608 -0.08839770972273064
 0.050533308692889314 0.022560117793588658 0.011484876837120765
 -0.27152311043414606 0.09559396061686287 -0.21791698664106054
 0.18069616314939851 0.24646800575019864 -0.14463001178373053
 0.21763165226480727 0.04167481802448186 0.1292168928931427
 0.1152854411225568 -0.0904457169324975 -0.01571528941495614
 0.08796285935831956 0.19042671212094428 0.031994142005925215
 -0.0017563158467818712 0.2120650041558389 -0.11846506093247147
 -0.03526693723477208 -0.23631652159893 -0.0719326549836811
 0.02340421558283694 0.2277844962805433 0.14196411029439485
 -0.08067935677160634 0.11822248186324487 0.1028923092429169
 -0.08532845663143733 0.2676390333065428 0.3150732950328802
 -0.20077521105027515 0.06640307838886421 0.13600210717633632
 -0.3724030631444515 0.12961558242942814 0.02037599922299084
 0.13034449911106813 0.2907186883152202 0.12300881911981985
 -0.20726959421261631 0.008816744651273023 -0.008429698103529068
 -0.0990815120408374 0.2229368669063691 -0.041429518532322615
 -0.07230429318649491 -0.0494793917221622 0.15353488301453602
 -0.037256165462623836 -0.11181441437318154 -0.27462918891049715
 -0.15623205841358434]
Traceback (most recent call last):
  File "a3_model.py", line 79, in <module>
    ffnn.train(train, args.samplesize)
  File "a3_model.py", line 51, in train
    doc1 = torch.Tensor(docs[in1])
TypeError: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool.
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ nano a3_model.py 
[gusklezju@GU.GU.SE@mltgpu lt2212-v20-a3]$ python3 a3_model.py out.csv 40
Reading out.csv...
Int64Index([271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,
            284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,
            297, 298, 299, 300, 301],
           dtype='int64')
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2316)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[ 1.02644294e+01  4.03674988e+00 -3.38414310e+00  1.13242954e+00
 -4.83856586e+00  2.05713587e+00 -1.84739452e+00  3.83188455e-01
 -7.64645843e-01  2.14958075e-01  1.65677565e-01  8.33162392e-01
  7.58931284e-01 -1.00388723e+00 -9.08900119e-01  6.22803397e-01
  2.28018731e+00 -1.62066742e+00  1.01794277e+00 -5.98137503e-01
 -1.42825478e+00 -9.83399661e-03 -6.79706078e-02 -5.32382585e-01
 -2.13610553e-01 -6.09616667e-02 -1.05334994e+00  2.39084617e-01
  1.08027469e-01 -8.23231656e-01 -1.08927124e+00  1.61637822e+00
  7.89605033e-01 -4.78669438e-01  1.17198237e+00 -4.44935706e-01
  4.73480659e-01  1.08350482e+00 -7.68864471e-01 -2.86111934e+00
  5.48560349e-01  6.21828686e-01  5.91081832e-02  1.51585248e+00
  7.07397722e-01  1.00214838e+00 -8.55713770e-01 -7.55662437e-01
 -1.18561498e+00  2.28695904e+00  3.21168832e-01 -1.64857643e-01
  1.28874199e+00 -9.42956096e-02  2.78574543e-01 -9.69590898e-02
 -6.87176986e-01  1.15220757e+00  1.34086576e+00 -1.10548110e+00
 -1.00772963e+00  1.98822276e-01  1.71327626e-01 -6.63673837e-01
 -1.20950149e+00 -1.35426013e+00  1.77731120e-01  1.54268927e+00
  8.02577011e-01 -7.96375028e-02 -1.65488458e+00 -1.09039521e+00
 -4.10759023e-01  1.25599045e+00 -1.06397297e+00 -5.05128484e-01
 -1.42332100e+00 -2.95101322e-01 -2.86421538e-01 -5.33855634e-01
  1.50384863e-01 -1.69200431e-01  1.24466187e+00  3.57352353e-01
  4.29205634e-01  1.09376467e+00  2.36356206e-01 -8.22437436e-01
 -2.05590743e-01  4.99194117e-01 -2.16646885e-01  2.36459375e-01
 -3.16848053e-01  1.08814432e-01  2.29251160e-01 -1.89290190e+00
  4.44051864e-01  1.36439663e-01  4.42602613e-01  4.01287954e-01
 -6.95496367e-01 -1.54152352e+00  1.08281068e+00  7.77344876e-01
  5.35414367e-02 -9.17783841e-01  4.87584316e-01  7.60036410e-01
 -1.89705548e-01 -8.64482952e-01  8.39674177e-01  9.55244829e-02
  1.00142019e+00  7.60314408e-02  3.66278165e-01 -6.46986373e-01
  1.08206422e+00  1.15634970e+00 -8.14285732e-01  2.09082247e+00
 -5.24576905e-01 -1.70571952e+00  3.38098822e-01  1.59033314e+00
  9.03159454e-01  8.66250289e-01  7.51904676e-01 -2.37553045e-01
  6.18493131e-01 -9.87220168e-01 -7.49939980e-01  2.62059111e+00
 -5.03234570e-03 -3.30231092e-01 -7.22043103e-01  1.12717755e+00
  1.61674316e+00  4.28177887e-01  6.19098107e-01 -1.88858980e-02
  1.44484876e-01  8.61852554e-01  1.06370436e-01 -8.39595539e-01
  1.55871790e+00 -9.19938630e-01  1.57320415e-01 -7.34755301e-01
 -4.17554266e-01  2.02577161e-01  2.09835298e-01 -1.69177275e+00
 -8.57093972e-01 -6.10655970e-01 -5.56149107e-01  2.89298942e-01
 -8.36690193e-01  5.49274179e-01 -1.27400798e+00 -7.05067539e-02
  4.19496200e-02 -7.43074940e-01  7.66812699e-01  3.36825219e-01
 -2.01224969e+00  1.48438725e-01  1.65036051e+00 -9.63391206e-01
 -2.68234790e+00  8.40589567e-01  7.18988728e-01  6.15200121e-01
  3.89496639e-01 -6.53705509e-01  8.43431662e-01 -5.63119867e-01
  1.04448901e+00  1.65877383e-01  4.84862049e-01  1.29350455e+00
 -8.77570212e-01 -4.64373038e-01 -2.59727283e-01 -7.44885302e-01
 -4.08283863e-01  2.98810371e-01  4.21831104e-01  2.04057826e+00
 -1.26179401e+00  4.89226554e-01  8.48809718e-01  9.28079759e-01
  2.11037313e-01 -6.13927667e-02 -1.01340446e-01 -8.58208828e-01
  3.20611332e-01 -1.27063800e-01 -2.85884033e-01  5.74679864e-02]
it does something
Int64Index([ 762,  763,  764,  765,  766,  767,  768,  769,  770,  771,
            ...
            1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259],
           dtype='int64', length=498)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1849)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-4.47720907  3.06290358 -0.01208266 -0.51030862 -1.41583175  1.22348653
  0.26093522 -0.8573771  -0.78573313  0.63842119  1.47174466  0.6394531
  0.59781295  0.9523823   0.79515696 -2.23592806 -1.57514515 -0.83310641
  1.60655039 -0.32751036 -1.92198251 -0.06101727 -0.17920892  1.9612765
 -0.04160781 -0.33881409 -0.23295097  1.81224352  0.02774125  0.43506125
  0.84149988  0.02217488  0.56972616 -0.4156853  -1.37143008 -0.42845685
 -0.48325089  0.76838968 -0.2719429  -0.75610929  0.96246376 -0.75732428
 -0.68157719  0.02944674 -1.06139586 -0.5424246   0.417547    0.3364401
 -0.48912779 -0.32886258 -1.22552977 -0.17746452  0.48721663  0.37082973
  0.02591749 -0.10344285  0.06482952  0.73417831  0.22226118 -1.67526421
  0.57825991  1.05204261 -1.17705664 -0.91874399  0.86995444 -0.4178859
  0.52777887 -0.07841628  0.55338578 -1.15357108  1.04313418  0.59874786
  0.61374979 -0.48517792  0.15632389 -0.67556851 -1.5509607  -0.52836255
 -0.42308831 -0.40743082  0.38878837 -0.25107138 -1.27050851 -0.46611886
  0.4869418  -1.12006437  0.05835543 -0.59144572  0.52908039  0.65060288
 -0.01314576  0.56138917 -0.49264623  1.16575462  0.46098202  0.09160617
  0.12893416 -0.53129925 -0.08169721  0.99514909 -0.70104397 -0.53901514
  1.07458303  0.68469435  0.44967945  0.5262937  -0.42812509  0.01662526
  0.14621974  0.60246091 -0.14698239  0.23629585 -0.1870004  -1.00288445
 -0.47051446 -1.29229003 -0.23597551  0.2429518  -0.24688101  0.63690856
 -0.3797146  -0.26246787 -0.26260298 -0.67785853 -0.46480491  0.47256265
  0.70088732 -0.18584666  0.17311801  0.05246579  0.31751864 -0.36786986
  0.66284784 -0.17070199  0.37139674 -0.86310594 -0.74863903  0.66574716
 -0.11253755  0.42760346  0.31180003 -0.23134918  0.07520848 -0.03597544
  0.43412332  0.29191648  0.47083939 -0.87524066  0.66308847 -0.02862603
 -0.04871502  0.16427387 -0.52442385  0.23769298  0.03618011  0.05796479
 -0.29861894 -0.68025805  0.40216304 -0.42806549  0.40107729 -0.52324735
  0.50302369 -0.44216521  0.13239664 -0.61016848  0.05634267 -0.12518824
  0.71063904  0.26528199  0.11855168  0.13910903 -0.67410351 -0.01479972
  0.30413708 -0.31870879 -0.1627867   0.74542263  0.52053432 -0.09201726
  0.41730974  0.28512012  0.4040284  -0.30539154 -0.56913836 -0.1361931
 -0.00973199  0.00676272  0.4682268   0.29593049  0.29353219 -0.31781685
  0.64560544 -0.29307246  0.20901412  0.2519528  -0.06136507 -0.67972344
 -0.66172043  0.07852827]
it does something
Int64Index([1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724,
            ...
            2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320],
           dtype='int64', length=606)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1741)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-8.16082285e+00  1.34627085e-02  8.02936530e-01 -2.66747443e-01
  7.89197776e-01 -1.59497753e+00  2.07871727e+00  1.60960758e+00
  1.45712413e-01  8.91827646e-01 -2.54058955e-01 -2.94684493e+00
  3.66525401e-01  8.05014340e-02  1.09401659e+00  3.08151546e+00
  7.28016000e-01 -1.83342255e+00 -5.55557423e-01 -1.24343562e+00
 -1.25387343e+00  9.52576077e-01 -5.45917453e-01 -1.70703021e+00
 -7.02400930e-01  2.56950474e-01  1.01902965e+00  2.14507193e+00
  1.70533626e-01  6.93279168e-01 -3.71096983e-01 -1.84551414e-01
 -3.77619782e-01  9.37369880e-01 -8.02404270e-01 -7.07458653e-02
  1.27097129e+00 -2.35599521e-01 -3.17486167e-01  1.77944564e-01
 -6.67541428e-01  1.19723650e-01 -8.34812267e-01 -4.36787542e-01
  5.44467354e-01 -7.45472476e-01 -6.42843773e-02  4.09882009e-02
 -2.77063688e-01 -5.28009291e-01  2.35180040e-01 -1.06023138e+00
 -3.32239116e-01 -4.21916608e-01  3.45984523e-01  6.61449336e-01
 -2.61499978e-03 -7.21503068e-01 -6.50443377e-01 -6.29276303e-03
  2.34002982e-01  1.41743670e-01  4.39362784e-01  4.21070503e-02
  1.12189022e-01  4.56060829e-01 -3.13796679e-01  2.61883205e-01
 -5.64886556e-01 -3.45196516e-03 -2.35777220e-01  9.21832831e-01
 -3.10788057e-01 -4.58248549e-01 -2.38776154e-01 -1.28453382e-02
 -4.33947646e-01  8.50136536e-01 -7.70528856e-01 -3.57274733e-01
 -6.92477682e-01  5.22718601e-01  2.30507121e-01 -3.08085198e-01
 -3.20929107e-01  3.76001979e-01 -1.23694204e-01  6.83201437e-01
  4.08925467e-01  6.61218482e-01 -5.94643361e-01  8.35605447e-02
  1.57986157e-01 -5.20144972e-01  2.32823846e-01 -3.85308067e-01
  7.72993404e-01  9.28085969e-03  3.55794679e-01 -4.08380750e-01
 -6.80407416e-01  8.85285554e-02  2.78137429e-01  2.63222253e-01
  1.02584164e-01  3.38079976e-01  7.04316647e-02 -1.04150247e-01
  3.86480360e-01 -8.54666976e-01  1.21630905e-02  2.75514686e-01
  1.19070260e-01  3.97945058e-01  1.85786287e-01 -1.24752863e+00
 -5.01159566e-01 -1.53561168e-01  1.34323756e+00 -1.65194014e-01
  6.14221790e-01 -9.41124128e-01  5.31108509e-03  4.23289840e-01
 -1.19576715e-01  3.42691918e-01  3.70222389e-01 -6.64455028e-01
  8.22122659e-02  7.84681224e-01  2.13788129e-01 -4.25865255e-01
  1.24903711e-01  4.17179798e-01 -7.57591206e-01  2.73619412e-01
  1.99256491e-01  7.02077239e-02  6.10343574e-01 -8.21673734e-01
 -2.83682312e-01  5.69932760e-01 -5.66161446e-02  5.65372311e-01
 -5.79374391e-01  2.02605711e-01 -3.00029791e-02  5.49238773e-01
  2.81575279e-01  6.59994283e-03 -5.68729621e-01 -1.84113417e-01
  6.18474328e-01  1.33391419e-01  3.37197307e-01 -3.34936428e-01
 -2.89689714e-01 -3.81166357e-02  9.88131097e-02  3.35244763e-01
  1.66287454e-03  2.12883045e-01  1.19964974e-01 -7.45044914e-02
  3.94020985e-01 -1.04418370e+00  2.59623013e-01  7.97473916e-01
  2.85831965e-02  3.03593320e-01  2.36542033e-02 -1.05201036e-02
 -1.59373757e-01 -2.75352108e-01  3.33030095e-01 -2.03493730e-01
 -6.99447035e-01  3.33907435e-01 -4.72325702e-01 -3.93345640e-01
 -9.51510705e-02 -5.79751333e-01  3.52887743e-01 -1.52675149e-01
 -3.50125057e-01  2.65412372e-01  3.23909452e-01 -6.04126603e-01
  9.31769722e-01 -4.04301156e-01 -1.36469216e-01 -8.43984596e-02
  1.71854692e-01  2.94891037e-01 -2.03478119e-01  1.65100239e-01
 -4.62292065e-01  2.51367273e-01  1.77342789e-02  4.59243888e-01]
it does something
Int64Index([ 762,  763,  764,  765,  766,  767,  768,  769,  770,  771,
            ...
            1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259],
           dtype='int64', length=498)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1849)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[ 6.0654939   1.3515007  -0.11622165 -0.24249813 -1.73933721  5.17409536
 -2.03531364 -2.5095569  -1.28353376 -0.04851719 -0.53397039  3.35087196
  1.26931255  0.04018815 -1.39318775 -1.17025464 -0.24715668  0.94053001
 -0.80466867  0.51181016 -2.05192062 -0.76308412 -0.26827734 -1.19808749
 -1.22618189  2.45013707  0.43547531 -0.15083632  1.56236506  1.55226624
  1.70720661  1.55733405  0.5101565  -0.73393822  0.58634924  1.84031917
 -0.5287971  -1.18756499 -0.84251015 -1.46640649 -0.39826993  0.07562446
 -1.44623458 -0.24849173 -1.88165445 -0.45918047 -0.57855674 -0.71215469
  1.13961991 -0.25925109  0.76023276  3.12660811 -0.38498054  1.30502499
  1.39528545 -1.4606292  -1.39939905 -0.17631392  1.33645632 -1.37648927
 -0.83956084  0.17343504 -0.64627324  0.01145861 -0.59034651  1.38010886
  1.14592291 -0.29717032  1.10138135 -1.84899526  0.45304641  2.63545081
  0.58541408 -2.90211434 -0.70714391  0.67944376 -0.30208239 -1.39063272
 -0.64628991  1.01357972 -0.35710127  0.64949024 -0.89530474 -0.1643146
  0.31263707 -0.68878601 -1.95958221 -0.88359256  1.95234862 -0.26622684
  0.54059399 -0.24184238  2.1404286   0.89559431 -0.2133767   0.1089355
 -0.18952187 -0.8039694  -2.51604163  2.3233844   0.12633548 -0.8370486
  1.06825466  0.81526598 -0.48645393 -0.12921097  0.43457993 -0.17670743
 -1.66315903 -0.73295825  0.20164679 -0.36797752 -0.61037437 -0.80001421
  0.26162912 -3.24424517 -1.57902822 -0.86028131 -1.08867863  2.44355728
  0.00864314  0.68372078 -0.79330149 -1.57236689 -1.60726593 -3.50375311
 -0.37930961 -0.57834558 -0.84420523  2.26433991  0.76051861 -1.58347393
 -1.59943274  0.34778876  0.38694779 -2.78918722  0.66833139  3.37037666
  0.05908267 -0.95811177  0.41976847 -1.64694163  1.25274376  1.32298747
  0.49619801  2.45262444 -1.93840242 -2.83817293  0.82094953  0.75672291
 -0.29543825 -0.32736498  2.24957568  1.07947043  2.13612737 -0.79392219
 -0.59071978 -0.52181612 -1.9511567  -0.45593003  1.52906051 -1.92791657
  0.74799171  3.81583919  0.22204973  0.70693313 -2.40265274 -0.7685398
 -0.07126971  1.02916555  0.72253912  0.84853818  1.38050547  1.17810981
  1.24213122  0.71029773  0.89951956 -1.12843432 -1.582791    1.08311992
 -0.15134872  1.2321489   0.11863778  0.59737792 -1.1313413   1.33482121
 -0.18909488  1.16897145 -1.48273224  0.92577828 -0.71298176  0.04878286
 -0.79342553 -0.13644058 -0.70944828  1.85185423  1.34571571  1.57659566
  1.27395229 -1.11005721]
it does something
Int64Index([454, 455, 456, 457, 458, 459, 460, 461, 462, 463,
            ...
            752, 753, 754, 755, 756, 757, 758, 759, 760, 761],
           dtype='int64', length=308)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2039)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-6.78870475  2.43861372  1.45150335  1.63152573 -6.33012378  0.67287432
 -2.08581994 -0.51408624 -0.88473474 -1.43100897  2.62957483  1.31728898
  0.51058361 -3.69100664  0.16360724 -0.98855456 -0.93416062 -1.08179128
  0.34112033 -0.65149086  0.43909178  1.40008035  1.75241883  0.07332779
  1.07643659  1.41871692  1.26940903 -0.91941334 -0.77909923 -1.57303821
 -0.48927566  0.20742478  0.67653897 -0.02047597  1.84461091 -0.54539688
 -0.21750736 -0.66351126  0.81794863 -1.2302177   0.04995581  1.15760522
 -0.43208617  0.12928379  0.03134011  0.08062581  0.48967637 -1.06451629
  0.74122014 -0.90975547  0.80791177  0.83931036  0.21217682 -0.9940006
  0.62627738 -0.31557664 -0.83337069 -0.08980428  0.40442465  0.08982658
 -0.91580863 -1.2588423   0.2599519   0.66800274  0.36762385  0.40558668
  0.66810473 -0.77353392  0.01251612 -0.33557381 -0.31331271  0.40602954
  0.33211538  0.26492994 -0.92691435 -0.07726187 -0.70315185  0.89609608
 -0.78604887  0.05032652 -0.24180576 -0.10729478  0.25503297 -0.82324852
  0.44630278 -0.33122433 -1.41298924  0.31046638  0.49932191  0.28873416
 -0.20623905  0.359513    0.02065177 -0.22745894  0.4826098  -0.66254823
  1.00173619 -0.80113478 -0.40148782  0.27951246 -0.64438756  0.8221891
  1.39262737  1.22283188 -0.14714232  1.40247658  0.3047685  -0.09541089
 -0.85371355 -0.49641553 -0.65266043 -0.22638273 -0.34577995 -0.00785941
  1.7323166  -1.65405673 -0.16404704  0.22142346  0.06254373 -0.21048947
  0.39304903 -0.42723656 -0.93229052  0.30584306  1.31539761 -0.01785147
  0.76606225 -0.22717057  0.36425852 -0.23764589 -0.06932036 -0.47942701
 -0.42854502  0.18904463 -0.18351942 -0.14025648 -0.37676625  0.39914743
  0.85319519 -0.62372176  0.02366332  0.63224507  0.95283342 -0.24206628
 -0.89547123 -0.8440465   0.01165576  0.79806037  0.98199934 -0.66490382
 -0.30048718  0.16152537  0.49493171 -0.29297126 -0.6079856  -0.46261372
 -0.60002708  0.07105363  0.0739009  -0.40677846 -0.31605445 -0.10706704
  0.25771262 -0.34728991  0.94512374  0.24069885  0.33944238 -0.05688433
 -0.31398134 -0.15131168  0.18669456 -0.13173164 -0.13383668 -0.28409188
  0.44795097  0.10102887 -0.8447104  -0.26185964 -0.43775047 -0.63678859
 -0.032372    0.15221181 -0.59722855  0.79626427  0.54557217  0.01955786
  0.54950798  0.27538991 -0.0647963  -0.69242337  0.53235749 -0.13291973
  0.73630424  0.43083808  0.00898362  0.06196311  0.40340007 -0.29368014
  0.45402974 -0.18974173]
it does something
Int64Index([1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311,
            ...
            1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706],
           dtype='int64', length=405)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1942)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-2.16399054e+00  3.14882879e+00 -1.60895592e+00  3.20893252e-02
 -1.20906196e+00  1.12744010e+00 -2.31231166e-01  2.80166177e+00
  3.32284680e-01  6.23695762e-01 -1.25613084e+00 -3.36078578e+00
 -1.92274346e+00 -3.01358186e-01  9.79965582e-01 -1.16275502e+00
  1.93771006e-01 -8.28207498e-02  1.39612881e+00  2.35796938e+00
 -1.18393501e+00 -2.72284631e-01 -3.62614836e-01 -2.30925192e+00
 -1.27667376e+00 -7.37108942e-01  5.43928651e-01 -1.25525857e+00
 -6.35347452e-01 -1.29994282e+00  3.47437909e-01  4.84157696e-01
 -1.94806722e+00 -1.76942872e-01  1.78907436e-01 -7.42066542e-01
  7.77635468e-02 -8.06808647e-01 -2.31558671e-01  5.22661580e-01
 -7.75397821e-01 -1.04971674e-01  2.23813370e-01 -7.80821394e-01
 -1.00839235e+00 -1.76660024e-01  6.33942025e-01  7.49888259e-02
  6.14039717e-01 -1.94270311e+00  3.81122409e-01  6.21670214e-01
 -8.97031062e-01 -6.98418209e-01  4.33022371e-01 -1.15048512e+00
 -4.02844618e-01  7.79331424e-01  2.77227047e-02 -8.56706270e-01
 -1.78674324e+00  4.76464417e-01  7.92550301e-01  1.31405910e+00
  1.41213835e+00  9.98213454e-01 -1.27091115e+00 -9.98610756e-01
  1.14182475e+00  1.58528216e-01  6.13173876e-01 -4.92891660e-01
  1.57171225e-01  3.68821797e-01  4.71500082e-01 -4.31616096e-01
  4.74824062e-01 -1.46812246e+00 -2.83865189e-01  2.86933128e-01
 -5.97766177e-01  2.07685423e-01 -1.39138090e-01  3.69156845e-01
 -1.57184623e-01 -7.68282969e-01 -8.76474437e-01  5.95052041e-01
 -8.38474596e-01 -3.68624586e-01  6.14105650e-03  4.37294811e-01
  2.35396329e-01 -8.66623851e-01  5.78609682e-01 -1.52249529e+00
  6.63709036e-01  1.43802322e-01  5.79131814e-02 -7.14630230e-01
  2.91803872e-01 -3.31193956e-01  8.27134175e-01  5.48155289e-01
 -4.27620840e-01  2.49704738e-01  4.45643328e-01  4.65622052e-01
 -6.29787210e-01  2.09298255e-01 -1.51322432e-03  8.65382929e-01
 -1.69441732e-01 -1.25979064e-01  1.14150679e-01 -2.86360520e-01
 -6.32442166e-01  3.11420011e-01  5.32980532e-01 -3.42350625e-01
 -5.88539005e-01 -2.93276334e-01 -5.64471136e-01  1.20048653e-01
 -2.43598390e-01 -3.64140760e-02 -5.78751344e-02 -7.97416310e-01
  1.23799765e+00 -4.97076358e-01  1.60837819e-01  5.39346136e-01
 -4.52111191e-01  7.93271678e-01  4.16773620e-02 -1.75272971e-01
  3.32813436e-01 -2.39856974e-01 -1.26576368e-02 -5.74562910e-01
  4.86316127e-02  5.50837849e-02  1.02405781e+00  5.83704075e-01
 -1.15208074e-01  9.85425810e-02 -4.67075743e-01  1.04100785e-01
  5.57341126e-01  5.79396367e-01 -5.25620364e-01  6.01125014e-02
  4.08730706e-01 -7.85032542e-01 -6.50209277e-01  2.49105982e-01
 -2.80401669e-01 -2.77214747e-01  1.08775634e+00 -5.28027623e-01
 -1.27219573e-01  3.88419620e-01 -5.51593206e-01  2.52308224e-01
  5.31000110e-01  9.21603117e-01 -1.16755715e-01  7.35532001e-01
 -4.17237189e-03 -1.86422484e-01  1.23133651e-02 -1.58847618e-01
 -7.58429923e-01 -4.71799512e-01  1.35139994e-01  3.10314697e-01
 -2.01869441e-01  3.33789421e-02 -1.06528973e-01 -3.48185087e-02
  4.30983496e-01  2.09252520e-01 -5.34171511e-02 -2.69143917e-01
  2.63434106e-01 -5.21914737e-01  1.30906712e-01 -1.86754437e-01
 -3.55050604e-01 -1.58569360e-01 -1.46642429e-01 -1.91616186e-01
 -8.96631493e-01 -3.72276735e-01  1.46167634e-01 -2.68604076e-01
  3.46041714e-01 -1.30053797e-01 -3.05247937e-03  2.73110066e-01]
it does something
Int64Index([454, 455, 456, 457, 458, 459, 460, 461, 462, 463,
            ...
            752, 753, 754, 755, 756, 757, 758, 759, 760, 761],
           dtype='int64', length=308)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2039)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-8.86005940e+00  3.57578976e+00  7.98051883e-01  1.45633882e+00
 -3.67814784e-01  1.72159454e+00 -1.45838545e+00  4.98501190e-01
  6.56715014e-01  7.24880253e-01 -4.65366477e-01 -1.43070566e+00
 -4.64651821e-01 -5.96473827e-01 -2.00218139e+00 -9.25324129e-01
 -1.07981675e-01 -6.29011040e-01 -1.74959544e-01 -5.16009011e-01
  1.04976652e+00 -9.31044348e-01 -5.92473902e-03  5.51371798e-01
  5.74536893e-01  1.45177927e-01  1.05651730e+00 -1.76390785e-01
 -4.70353694e-01  1.06575043e-01  3.74719018e-01  4.92374560e-01
 -6.81686227e-01 -1.39738864e-01 -3.00663808e-01  7.81778858e-01
  6.45945209e-01 -4.06495261e-01  6.16258961e-01  2.29749179e-01
  5.63712240e-01  6.26527104e-01  3.48822759e-01  6.35292948e-01
  7.21076608e-01  7.92329633e-02 -1.42083580e-02 -4.90390270e-01
 -3.71622029e-02  2.66893467e-01 -4.76647917e-03  1.42433503e+00
  3.55916646e-01  4.83526794e-02  3.33404365e-01 -3.16027416e-01
  7.17161328e-01 -1.46022246e-01  4.02728290e-01 -2.13432069e-01
  4.00272837e-01 -4.27937293e-01 -3.10183495e-01 -8.10274115e-02
  5.66457538e-02  5.26185148e-01 -3.92195670e-01  8.34846013e-01
 -5.45324150e-01  1.26388350e-01  1.24844990e-01 -1.91023766e-01
  2.29363876e-01 -1.77891689e-01  9.02114414e-02  2.77887989e-02
  6.75268450e-01 -7.35398723e-01 -8.35930483e-02  2.70688267e-01
  2.87364320e-01 -8.48357562e-02 -9.72893887e-02 -1.84645409e-01
  8.22660055e-02 -2.12772873e-01 -2.10006057e-01  4.11594290e-01
 -5.17780704e-04  7.48190375e-02  4.84481651e-01  3.07591038e-01
  2.48725652e-01 -4.10327577e-02 -2.81136576e-01  3.93692725e-01
 -2.03507814e-01 -6.61771631e-02  4.34574007e-01  7.94112686e-02
  7.74449809e-03 -1.75577964e-01 -5.29703937e-02 -2.73649415e-01
  1.27630220e-01  3.96942453e-01  7.77773283e-03  2.68998346e-01
 -2.36152144e-01 -5.92988303e-02  3.02082666e-02  1.70497576e-01
  7.09872841e-02  4.20327364e-01  2.34265764e-01 -2.02246663e-01
  6.99929681e-02 -4.58036483e-02 -7.59272151e-02 -1.55152280e-01
  1.18989193e-01 -1.97120681e-01  9.76641307e-02  4.79332025e-02
  1.36942234e-01 -1.28645312e-02 -2.68689199e-01 -2.30933629e-01
  2.15849496e-01  2.19017820e-01  5.07035946e-02  1.61514274e-01
 -1.60774629e-01  2.87156029e-01  1.29060242e-01  3.79207377e-02
 -6.17301542e-02 -2.17411991e-01 -3.96066075e-01 -6.04483891e-02
  2.06665273e-01 -2.67397901e-01 -1.87613093e-01 -1.72943514e-01
 -2.06929904e-01 -6.74339368e-04 -8.13541387e-02 -1.16482689e-01
 -1.00474279e-01  3.65936015e-01  3.68626302e-01  1.60687221e-02
 -4.28192552e-01 -7.47042187e-02  1.39356273e-02  3.69204320e-01
 -1.19919843e-02  1.71242478e-01  8.29650393e-02  8.15436302e-02
  1.52078738e-01  1.08587299e-01  1.97144031e-01  1.84258801e-03
 -7.22940862e-03  3.81536256e-01 -4.09521123e-01  7.66723472e-02
  3.03743583e-02 -3.13549015e-01 -7.61927926e-03 -1.96600577e-01
  1.39851397e-01 -2.99837717e-01 -1.57438875e-01  4.82401932e-02
  2.63545995e-03  3.32307607e-02  3.19679086e-01  2.43206724e-01
 -4.99111939e-02 -3.43669374e-01 -1.29873604e-01 -7.91344440e-02
  2.01127388e-01 -3.30892587e-01  4.19842180e-01  4.13271820e-01
  2.63566736e-01 -9.47337588e-02  2.70648542e-01 -2.59380541e-01
 -1.30795580e-01 -5.62550388e-02 -2.49440898e-01  5.02325791e-02
  4.77157455e-01 -3.14967761e-01 -1.66043846e-01  1.94557494e-01]
it does something
Int64Index([1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311,
            ...
            1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706],
           dtype='int64', length=405)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1942)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-1.13213353e+01  1.91035951e+00  1.42480118e+00 -3.92690203e-02
  1.76678283e-01 -5.71503686e-01  8.34041848e-01 -3.69039000e-01
 -1.04947835e+00  6.51671006e-01 -9.47896991e-01 -1.33815294e+00
  6.47875363e-03 -1.08343112e-01  1.57217852e+00  9.53170408e-01
  1.23878652e-01 -4.57141003e-01  1.04329519e+00  1.03736102e+00
 -1.11614505e+00 -8.88470042e-01 -4.01585194e-01 -6.02702325e-01
 -1.07632666e+00 -2.93837732e-01  9.03831587e-01 -5.25097479e-01
  9.68458545e-01  2.72286635e-01 -9.31644407e-01 -3.94640028e-01
 -1.18748875e+00  1.27105659e+00  1.06598648e+00 -8.99926362e-02
 -7.83898959e-01 -5.43995790e-01 -5.02827224e-01 -3.62038479e-01
  4.39384440e-03  5.73985785e-01  4.95894473e-01 -2.68735086e-01
  1.49956844e-02  7.56316830e-01  1.63972172e-01  3.35874111e-01
  1.84032770e-01  1.91217166e-01  3.65825090e-01  9.28994984e-03
 -2.05638543e-02 -7.34263622e-01  8.52058172e-02  1.71269385e-01
 -2.20678715e-01 -3.15975015e-01 -3.60133545e-01  1.20117650e-01
 -3.11221884e-01  1.45496520e-02  1.81627331e-02 -1.31776636e-01
 -3.10484276e-01 -2.24692798e-01 -3.21967635e-01  4.02021231e-01
  6.17987633e-01 -3.31550572e-01  7.19111411e-04 -4.24441535e-01
 -4.26298946e-01  2.25028155e-02  2.53905770e-01  9.96332845e-02
 -2.96531846e-01  1.77794591e-01  1.74738567e-01  2.37796842e-01
 -1.86442644e-01 -2.78112649e-02  4.01291353e-01 -4.92389467e-02
 -1.21799800e-02  8.95539504e-02  7.78345701e-02 -1.00752713e-01
  1.07658430e-01  2.46092088e-01 -1.44208580e-01 -9.38237133e-03
 -3.48157851e-01  1.95975117e-01  9.49717137e-02  3.18676249e-01
  3.63524429e-01 -5.02523538e-01  3.27489017e-01 -2.29780722e-01
  2.93428249e-01  3.90283483e-02  2.40600123e-01  1.87498148e-01
  1.44360830e-01 -1.21950854e-01 -8.04423733e-03  3.69044404e-01
 -2.25355725e-01 -1.67573849e-01 -4.64102450e-03 -8.03678297e-02
 -5.24444347e-02  2.58042505e-01  4.81008562e-02  4.40725432e-02
 -7.86549489e-02  1.58044339e-01 -9.98278960e-02 -2.54005227e-01
  4.09827469e-02 -1.80907827e-01  6.69932536e-02 -4.64667233e-02
  5.41439817e-01  1.35648300e-01 -3.45190301e-02 -2.26954204e-01
 -3.85544944e-01  2.00533533e-01 -5.21006348e-02 -5.19551120e-01
 -3.09551193e-01 -4.52496135e-01 -3.59026163e-01 -1.18441295e-01
  1.01656894e-02 -2.19956786e-01 -3.12885196e-01 -2.77575552e-01
  7.63291814e-02 -7.33494263e-02  4.06407251e-02  8.33897336e-02
 -7.06207319e-02  2.92033823e-02 -4.68747517e-01  3.16389577e-03
  2.48070340e-01 -9.39212690e-02 -3.76083158e-01 -8.27892882e-02
 -7.84482417e-02  1.67652575e-01 -3.46888247e-01  8.15642786e-02
  8.49671103e-02 -1.31714192e-02  3.70664095e-01  3.10853923e-01
  2.68142077e-01 -3.54356083e-01 -1.20962330e-01 -3.25798874e-01
  3.57131335e-01 -3.22153762e-01 -4.37391882e-01  8.69597873e-02
  2.49241423e-01 -3.50399161e-01 -3.66445576e-02 -3.79637373e-02
  3.37843624e-02 -1.06623565e-01 -1.58016318e-01  2.04051110e-01
  2.18141733e-02  1.31107531e-01  1.05794318e-01 -4.06230347e-01
  3.14452172e-01  2.83655302e-01 -2.56482157e-01  2.01892459e-01
  1.65449863e-01  6.51642833e-02  1.78733177e-01  1.38838021e-01
  6.65855055e-02  1.01855479e-01  1.18197171e-02  2.93248960e-02
  1.38945035e-01  1.67747485e-01  1.10329027e-01  4.51810439e-01
 -2.08156215e-02  4.74316920e-01  2.02631997e-01 -6.12419128e-02]
it does something
Int64Index([1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283,
            1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294,
            1295, 1296, 1297, 1298, 1299, 1300, 1301],
           dtype='int64')
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2318)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-9.69368660e+00  1.78363813e+00  1.03733555e+00  8.42063616e-01
  3.97470768e-01 -1.22107264e+00  1.50139309e+00  2.38997287e-01
  2.19992513e-01  1.69420206e-01 -4.20145657e-01 -4.32966397e-01
 -3.68186708e-01  6.48681391e-01  4.28107854e-01  1.40176674e-01
  3.05778872e-02 -4.44622147e-01  6.93329084e-02 -9.14463862e-01
 -1.30821692e-01 -7.73374963e-01  4.57892026e-02  1.15857876e-01
  2.76240070e-01 -4.00614783e-01 -6.31454643e-01 -1.49964167e-01
  3.84074326e-01 -1.58905686e-01  2.97862439e-01 -6.22827075e-01
  7.47225678e-01 -5.69943863e-01 -1.00424309e-02 -5.91355296e-01
  3.10690067e-01 -3.82064320e-01 -2.31230832e-02  3.42069245e-01
 -1.26618267e-01  9.21140168e-02 -4.50769925e-01  2.12125301e-01
  3.20395653e-02  6.28865862e-01 -1.48287688e-01  3.00872044e-01
 -5.50170946e-01  8.70605603e-03  4.89875627e-02 -3.55110645e-01
  1.24833456e-01  4.04783357e-01  4.08219777e-01 -6.37277280e-02
  4.02443760e-01  1.28147904e-02 -8.33441807e-02  3.70560283e-02
 -3.95294318e-01  1.64028197e-01 -7.31508719e-02 -4.01387508e-01
  7.84696174e-02  3.32348304e-01 -7.38073877e-02 -2.57818507e-02
  5.00827675e-02  7.66210093e-01  8.89649502e-02  4.21935789e-01
 -3.25341427e-02 -4.48001379e-01  1.99308112e-01 -4.53725907e-02
  3.01534752e-02 -4.29590768e-01 -6.12553442e-01 -5.38620433e-01
 -1.43344076e-01 -1.94831231e-01  3.61538418e-01  6.66267331e-01
 -2.31165598e-01  5.63078742e-02 -2.47033242e-01  1.77716753e-01
 -1.16036027e-01 -4.49326205e-01  2.31062606e-02 -2.62395554e-01
 -7.63494137e-02  4.92145410e-02  3.99330882e-01 -3.38375238e-01
  1.52981812e-01  1.92151856e-01 -3.88965612e-01 -4.50190834e-02
 -2.25691724e-01  1.45315690e-01  1.44130267e-02  3.23049558e-01
  1.35636566e-01 -2.01421807e-01 -7.52978454e-02  3.71168270e-01
  4.32024399e-01 -1.96958369e-01 -1.79893802e-02 -2.13666871e-02
 -3.56689407e-01  3.41719753e-02 -5.43324664e-01  9.54863370e-02
 -1.28695683e-03  3.21172609e-01  1.00984639e-01 -2.00457629e-02
 -2.37851938e-01  5.71197653e-01  1.90507474e-02  9.69617587e-02
  8.80791968e-02 -2.67014559e-01  8.96862993e-02  1.94443245e-01
 -2.99080109e-01  2.96100250e-01 -3.88694117e-01  9.64136471e-02
 -9.11045398e-02  1.31870502e-02  2.03073558e-01 -2.64003685e-01
  1.93129380e-02 -1.28756472e-01  2.31335117e-01  2.72398047e-01
 -3.24622488e-01  6.59983404e-02 -1.86566050e-01  1.76302942e-01
  2.44087286e-01 -1.46003899e-01 -2.20702491e-01  1.15693158e-01
  5.08060630e-02 -5.62885387e-02  4.87638278e-02  5.95976272e-02
 -6.56455294e-02  2.13534404e-01 -4.25992075e-01 -2.08929727e-02
 -1.28650712e-01  5.21263751e-01  4.14769746e-01  2.41411780e-01
  1.43809276e-02  6.28119030e-02  3.28493002e-02  2.24782332e-01
  8.14876036e-02 -1.65011731e-01  5.21644965e-01 -3.02525906e-01
  1.53120354e-01 -2.95262207e-02  4.37512634e-02 -4.96377701e-01
  1.91714596e-01  1.14970534e-01 -1.81968696e-01 -6.73239942e-02
  1.45912247e-01 -1.02611190e-01  2.57045620e-02 -3.36762278e-01
 -5.73781722e-01 -1.62861989e-01  8.14075958e-02 -6.16362504e-02
 -1.92503238e-01 -1.06013306e-01 -1.89574520e-01 -2.22779590e-01
  1.82743560e-01 -1.95220045e-01  4.29411574e-02  4.62685339e-01
  2.46653791e-01 -5.19896467e-01  3.69701551e-01  1.22777222e-01
 -1.90184808e-01 -2.22503325e-01  1.64936998e-01 -8.79733395e-02]
it does something
Int64Index([408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,
            421, 422, 423, 424, 425, 426, 427, 428, 429, 430],
           dtype='int64')
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2324)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[ 8.12420955e+00  2.91289460e+00  3.19688231e-01 -1.10880440e+01
  3.75876451e+00 -1.23323643e+00 -1.05572033e+00  2.79941934e+00
 -1.07023187e+00  1.38134955e+00  2.79557821e+00  3.13844399e-01
 -4.41519789e-01 -1.87594802e-01 -2.67725712e+00 -1.04988911e+00
 -9.88231315e-03  9.45753056e-01  1.74810432e+00  2.86855168e+00
  8.42785514e-01 -9.12922571e-01 -1.41604812e+00  6.12499381e-01
  1.13566041e+00  2.49390710e+00 -4.21398081e-01 -1.37081660e+00
  1.34369015e+00 -3.06596355e-02  6.72652608e-01  3.94703593e-01
  2.27859353e+00  1.56795443e+00  5.27232230e-01 -8.16008139e-01
 -3.90528216e-01  1.25800264e+00 -6.81860238e-01 -1.68241272e+00
  5.71151650e-01  1.59017961e+00 -3.58152895e-01 -6.95563052e-01
 -1.20766999e+00 -5.36886334e-01 -1.75466392e+00  4.15372672e-01
  7.01580973e-02  6.47694919e-01 -2.19099877e-01 -6.99611049e-01
 -8.23805954e-01  1.29889693e+00 -1.11044814e+00  1.37520364e+00
  1.94974214e+00 -1.18443404e+00 -6.71092288e-01  3.12895615e-01
  6.01341002e-01  1.80119257e+00 -4.58294754e-01 -6.85006258e-01
  2.85891517e-02  2.67726526e-01 -2.79870753e-01  5.08580004e-01
  1.00463265e-01  1.45976182e+00 -4.31666507e-01  3.52600817e-01
 -5.55401396e-01 -1.77787486e+00  7.45041971e-01  4.66173887e-02
 -5.70392108e-01 -6.78008581e-01  2.12511454e-01 -7.27038970e-01
 -4.30262011e-01 -4.52157965e-01 -1.65847056e-01  3.30637881e-01
  3.57410066e-01  3.36137616e-01 -5.45379250e-01  5.63077921e-01
  5.68005677e-01 -7.36175879e-01 -9.94449893e-01 -1.90095195e-01
 -1.34502168e+00  1.17765658e-01  1.61644662e+00 -3.16756994e-01
 -6.07962843e-02 -8.73141604e-01  1.94464885e-01  6.04164765e-01
  1.47895397e-02 -4.24718418e-01  1.02357702e-01 -5.60077909e-01
  1.31836457e+00  4.91482236e-01 -1.90124085e-01 -1.27913988e-01
 -2.67319743e-02 -4.42577989e-01  5.59982887e-01  1.01429720e+00
  4.96722014e-01  8.75051745e-01  7.21957662e-01  6.54970645e-02
  1.86339851e-01  7.24541922e-01  9.51109912e-01 -1.12664698e+00
 -9.29493085e-01 -2.37894553e-01 -3.30811168e-01 -7.80064149e-01
 -6.98902778e-01 -1.30688296e+00  8.70530007e-02 -3.18737397e-01
 -6.06454455e-01 -5.90653827e-01 -5.73214204e-01 -7.18049487e-01
 -1.70859836e-01  9.07490263e-01  6.09417412e-01  4.58877972e-01
  8.24285148e-01  4.65299030e-02 -5.35095359e-01 -1.70323546e-01
 -4.31574431e-01  1.40678360e-01 -7.75984402e-01 -1.07127890e+00
  5.55210966e-01  4.18159987e-02  1.68145770e-01 -1.00118622e+00
 -8.07805913e-02  1.36331153e+00  8.80504382e-01 -4.56001488e-01
  2.53363899e-01  1.50743288e-01 -6.94092935e-02 -1.59593787e-01
 -2.43323524e-01 -5.86363160e-01  4.90449124e-01 -5.26804935e-01
  1.88416806e-01 -1.52752224e+00  7.60546817e-01 -7.09546017e-01
  5.97063119e-01  2.55548591e-01  6.25147845e-01  3.53330440e-01
  3.33635386e-01  3.86924692e-01 -2.87472159e-01  1.24693680e+00
  2.58991274e-01  3.34328681e-02  6.71765355e-04 -1.98060155e-01
 -3.13618034e-01 -7.05790415e-01 -4.01138661e-01  1.33369751e-01
  2.99173271e-01 -4.21453345e-02 -6.77509080e-01 -8.46159657e-01
  5.42335040e-01 -9.15064548e-02  8.52281275e-02 -1.21068742e-01
 -4.28274552e-02  8.83256657e-02  4.06123627e-01 -7.42292886e-02
  8.20174965e-01 -2.91163092e-01 -9.36087562e-02 -2.49694833e-01
  2.87926559e-01  5.16030792e-01  7.33511598e-01 -7.64527973e-01]
it does something
Int64Index([454, 455, 456, 457, 458, 459, 460, 461, 462, 463,
            ...
            752, 753, 754, 755, 756, 757, 758, 759, 760, 761],
           dtype='int64', length=308)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2039)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-1.17971377  2.20048909 -0.48096203 -0.81446698  1.32193473  1.981508
 -2.04419334 -2.82128106 -0.43726262  1.94936607 -0.47966843  0.77616707
 -1.08478318 -0.03557036 -2.91011637 -3.34487218 -0.43580585 -2.07589938
 -1.59107561 -0.27844496  0.8920449   1.05317276 -0.94704788 -0.8633257
  0.05951039 -1.55040649 -0.34931796  2.23451404 -0.47057188  0.40195182
  0.09565378  0.91750972 -0.08371025 -0.17624746 -0.9667484  -1.29363198
 -2.82574569  0.03026976  0.46456742  1.15345865  0.3850987   0.14877036
  0.5949095   0.05401331  1.03624341  0.23911024  0.02126436 -0.04201474
 -1.03098137 -0.25364679  1.31808756 -0.40848092  1.49892089  1.14672405
  0.27729426  0.27537181  0.87659722 -0.25308764  0.71693361 -0.54637185
  0.44944207 -0.31196209  0.41665169 -0.65566431  1.32319406  0.61328496
  0.0714563  -0.17762462  0.39560193  1.42712951 -0.69789876  1.13207679
 -0.98813004  1.74459942 -1.07373531 -0.61743357  0.1477634   0.78298412
 -0.56482636 -0.49039356 -0.46760291 -0.01770482 -0.84345834  0.23185781
  0.82984235  0.33793763 -0.5923654   0.78705953  0.3990601   0.66714319
 -0.93992458 -0.88743835  2.19274085 -0.43158664  0.52606406  0.00924273
  1.01052992 -0.43765943 -0.0313489   0.08180799 -0.22903683  0.18794462
  0.10140313  0.0275326  -0.69503539  0.39890229  0.87693675 -0.81645513
 -0.51244654  0.52378505 -0.35397501 -1.3126046  -1.66786227 -0.26325545
 -0.0925307  -0.16474735  0.43819776  1.23615458  0.74133652 -1.4763102
  0.68607808  0.9487001   0.20279442 -0.45108053  0.06937546 -0.74847061
  0.23641544 -0.41268932 -0.48824265 -0.62501147 -0.39819999  0.01570941
 -0.13326772 -0.35268291  0.11406665 -0.13156633 -0.54929461  1.04127723
  0.07103344 -0.52350518  0.10446071  0.60763651  0.19465688  0.49743081
 -0.01253033  0.24139299  0.7557566   0.13842688  0.33532222  0.94001693
 -0.48576515  0.67598217  0.54771528 -0.98783517 -0.13029404  0.72383966
 -0.02997916  0.15813749  0.47729739 -0.68687785 -0.03682099  0.43602322
  0.80451148  0.15195266 -0.18696062 -0.11332105  0.01217864  0.57498166
 -0.35437057  0.9220398  -0.07231555 -0.10346989  0.91483582 -0.22964823
 -0.31820297  0.20689901 -0.18768464 -0.34484062  0.5319618  -0.46777547
  0.02496843 -0.10248712  0.31525127  0.09293897  0.10831412  0.40741051
 -0.25825724  0.4322226  -0.389862   -0.66511756  1.28261717 -0.04764425
  0.08690979  0.50217893 -0.32912886  0.2868122  -0.36400217 -0.42320101
  0.36591989 -0.06052296]
it does something
Int64Index([431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443,
            444, 445, 446, 447, 448, 449, 450, 451, 452, 453],
           dtype='int64')
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2324)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-9.75044801e+00  1.11754186e+00  7.62870280e-01 -6.84104279e-01
 -1.08972256e+00  1.66802048e+00  4.46096512e-01 -2.54881579e+00
  2.62319032e-01  5.61282417e-01 -1.66287745e+00 -2.12497460e-01
 -6.36108611e-01  8.60371372e-01 -2.25114046e+00 -6.44545292e-01
 -3.87302733e-01  1.08710306e+00  4.86291585e-01  3.40252220e-01
 -9.92448102e-01  7.87004713e-01 -1.81978664e-01 -9.16014545e-01
  4.35603847e-01 -7.81803047e-01 -1.19329234e+00 -4.83050661e-02
  3.21679163e-01  8.76289918e-01 -1.30072162e-03  2.03716567e+00
  2.18869335e-01 -5.37755875e-01 -4.27578962e-01  7.49851564e-01
 -2.15201605e-01  1.23703678e-01  5.34853812e-01 -1.01186958e-01
  9.90714662e-02  2.27579353e-01  1.96658182e-01  1.10658028e+00
 -3.41824650e-01  1.99886891e-01 -5.19566345e-01  2.81763790e-02
 -8.70029603e-01  1.08532535e+00  5.65272726e-01  2.30171582e-01
 -2.64545795e-01  8.73292586e-01 -3.62534069e-01  2.10846177e-01
 -3.56340355e-02  1.10137661e+00 -2.30000535e-01  2.16412975e-01
 -1.06227214e+00 -4.75213703e-01  4.97921020e-01 -2.38119393e-02
  1.60804864e-01  1.55693167e-01  5.65632850e-02 -5.66304649e-02
  7.53721536e-01  6.14336923e-01 -3.57115103e-02  4.53874610e-01
 -2.52916766e-01 -5.96010659e-01  5.73943551e-01  2.69661178e-02
  1.89877083e-01 -2.17870191e-02 -2.11857408e-01  5.34455630e-01
  1.14687100e-01  1.31941632e-01 -2.98584551e-01 -1.12357870e-01
 -1.40268625e-01 -6.89770016e-02 -4.19960568e-01 -1.61653459e-01
 -2.46698056e-01  1.05242841e-01 -2.32174353e-01  5.33921313e-01
 -2.67721335e-02  2.93228233e-01  7.55895211e-01 -5.80311138e-03
  1.86462642e-01 -1.15484702e-01  1.47424514e-01 -2.26721389e-01
  5.19725511e-02 -5.73702473e-01 -1.26951338e-02 -2.39931655e-01
  7.13131966e-01  6.20874581e-01 -1.04555758e-01  3.22721824e-01
  3.38029074e-01 -2.82020869e-01  6.20060843e-01 -3.57378387e-01
 -1.85002637e-01  1.11464819e-01 -8.02159517e-02  8.70067977e-02
 -5.98479159e-02  2.47175739e-01 -5.92314198e-01 -4.38337307e-01
 -5.17405784e-01  9.16138393e-03  3.38156477e-01  1.02932470e-01
  4.83335681e-01 -7.29029435e-01  7.92577054e-02 -1.76460317e-01
  1.92126073e-01 -3.11838248e-01 -6.15043941e-01 -3.93969511e-01
  1.68383629e-01 -4.36716084e-01  4.06527880e-01 -7.31161964e-01
 -2.98956748e-01 -3.43299599e-01  6.67225969e-01 -8.73593265e-02
  5.14941259e-01  3.16361080e-01  5.59248592e-01  4.89983124e-02
  1.17168108e-01  8.79280198e-02  5.74226089e-02 -4.61965481e-01
  4.33804162e-01 -2.09825261e-01 -1.46922201e-01 -2.81362395e-01
 -1.20257037e-01  7.50391446e-02 -1.59678441e-01 -1.22929043e-01
  4.07483715e-02 -1.89721788e-02 -2.30546287e-02 -3.34662893e-01
  4.61721719e-02 -4.28149759e-01 -2.61055833e-01 -2.88269388e-01
 -1.83354334e-01 -3.30584488e-02  2.75460342e-02 -3.95175009e-01
 -8.01826221e-02  5.49110623e-02  7.11350121e-01  2.79495224e-02
 -2.27160941e-01 -1.48249945e-01 -2.36523475e-01 -3.04290233e-01
 -7.84188856e-02  2.43851949e-01  1.86938518e-01  1.21478862e-01
 -5.03441918e-01  3.76388238e-01  7.74309910e-01 -1.09853449e-01
  2.65268837e-01 -8.80931194e-02  6.64804339e-01 -2.44607624e-01
 -1.10563748e-01  3.88010210e-01  1.42028171e-01  3.15263376e-01
 -2.43849952e-01  2.03891319e-01  3.38926492e-01 -3.17461924e-01
  8.72525128e-03  1.56714338e-01 -2.16733891e-01  3.65577009e-01]
it does something
Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,
            ...
            139, 140, 141, 142, 143, 144, 145, 146, 147, 148],
           dtype='int64', length=149)
Int64Index([ 149,  150,  151,  152,  153,  154,  155,  156,  157,  158,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2198)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-1.70162560e+00  5.75766063e+00  8.33271440e-01  1.01637229e+00
  3.82403609e+00  1.93544010e+00 -2.32031227e+00  5.24212105e-01
 -5.20735007e-01 -9.83828298e-02 -4.03222106e-02 -6.07828423e-01
 -1.96577209e-01 -8.53433228e-01  2.97985796e-01 -3.73590094e-01
 -9.75245308e-01  2.04378220e-01  1.50716864e+00 -5.42639262e-01
 -6.36174204e-01 -1.74277036e+00 -6.52757028e-02 -6.88609868e-01
  2.37073900e-01 -3.93341976e-01 -2.38951895e-02  1.66228202e+00
 -3.20500825e-02  1.01815009e+00  1.01681836e+00  4.31612098e-01
 -7.37606733e-01 -7.10979294e-03 -1.56813373e+00 -2.87879648e-01
  1.05000211e+00 -4.31948635e-01 -1.43504116e+00  2.27428387e-01
 -8.75655960e-02  2.80047280e-01  2.35812235e-01 -2.69872182e-01
  5.91569046e-01 -5.24648512e-01  4.47010444e-01  1.57965951e-02
 -5.49547318e-01  6.30322010e-01 -3.64508779e-01  1.53967966e-01
 -7.79992821e-01  4.18300294e-01  2.69171533e-01 -5.75871694e-01
  1.64135807e-01  9.83808655e-02  9.33661310e-02 -4.79336392e-01
  6.79428857e-01 -4.78948103e-01  2.18542560e-01 -1.43305725e-01
  6.87891512e-02  8.78832808e-01  5.03975387e-01 -2.07162966e-01
 -1.44794348e-01 -1.27704082e+00  3.24620244e-01  1.16850637e-03
  5.74368267e-01 -2.08494771e-01 -1.67327808e-01  1.67682893e-01
  5.68962050e-01 -8.75800830e-01 -1.47256315e-01  5.78101991e-01
 -3.16757058e-01 -2.23077982e-01  6.30306919e-01  7.45163459e-01
 -4.71556298e-01 -1.15498625e-01 -5.95486165e-01  1.40654030e+00
  1.31753093e-01  3.96724018e-02  5.81623065e-01  3.34714403e-01
 -3.42395744e-01 -1.37889142e-01  5.83691463e-02 -1.66688167e-01
 -4.03216681e-02 -4.77609511e-01 -2.51638026e-01 -2.70798690e-01
  5.11789490e-01 -2.78553460e-01 -5.31649860e-01  1.38266760e-01
 -9.68298577e-02  4.86418168e-01  9.24001787e-02  4.31833728e-02
 -3.94570074e-02  3.28267913e-01  3.51950636e-01  2.14344821e-02
  1.20636307e-01  2.06731366e-01  3.96109792e-01  5.58214365e-02
 -1.79072416e-02 -3.69003576e-01 -6.12527142e-02  2.33441408e-02
  3.46893084e-01 -1.23756496e-01  1.77241975e-01 -1.95622677e-01
 -6.94883285e-02 -2.47835538e-01 -4.92734197e-01 -7.14625312e-01
  7.63368591e-01 -5.50667994e-01  2.08536494e-01  3.28741358e-01
 -2.66288450e-01 -1.32205273e-01  1.28835966e-01 -6.58741149e-02
 -2.00505613e-01 -1.02492557e-01  1.33016122e-01  5.39461042e-01
 -5.73020148e-01  5.97937552e-02 -3.36514976e-01 -3.81778740e-01
  4.21322608e-01 -5.61512478e-01 -2.40919386e-01  8.66044239e-02
 -3.50898636e-01 -5.25507127e-01  3.26817246e-01  1.60071342e-01
  1.99312826e-01 -2.83146890e-01  1.04545158e-01  7.15684833e-02
  1.05471305e+00 -1.03165607e-01 -4.15629192e-01  2.87404995e-01
  1.09216981e-02 -5.50248867e-02 -8.40607800e-02  4.18958581e-01
 -4.51500125e-01  3.31765169e-01  5.62980855e-03  1.70897271e-01
  1.16072674e-01  3.92719611e-02  6.00560831e-01  4.34891833e-02
  1.39408268e-01  1.75281862e-01  3.37335301e-01 -8.98427845e-01
  4.85445378e-01  3.18678239e-01 -3.43264502e-01 -2.16243944e-01
 -7.47377206e-02 -1.31653761e-01 -3.60865754e-01  8.73246248e-02
  1.77086615e-01 -4.81692255e-01  3.43466897e-01 -3.45023595e-01
  8.51753085e-01 -1.61108910e-01  1.32947177e-01  3.68334894e-01
 -1.66707859e-02 -8.47805985e-03 -2.91901227e-01 -2.32562097e-01
 -4.41388403e-01  1.03968903e-01 -2.56255012e-02  1.15581230e-01]
it does something
Int64Index([302, 303, 304, 305, 306, 307, 308, 309, 310, 311,
            ...
            398, 399, 400, 401, 402, 403, 404, 405, 406, 407],
           dtype='int64', length=106)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2241)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-1.12606395e+01  2.94774378e+00  1.76125968e+00  2.40271213e-01
  7.15117951e-01  5.66886761e-02  4.76508237e-01 -1.56446416e-01
 -1.86127484e-01  2.27989866e-01 -7.93030609e-01  1.25369489e-01
 -1.81707969e-01 -1.93455845e-01 -2.88932162e-01 -1.82565128e-01
  1.10973751e-01  1.78459431e-01  4.70338287e-01 -5.47708581e-01
 -2.64272095e-01 -1.04331718e-01 -2.79646991e-01 -3.22549367e-01
 -2.63249463e-01  4.97697324e-01  3.01543185e-02 -2.46761619e-01
 -3.85467853e-01 -1.78719144e-02  4.80129897e-01  2.59295624e-01
  2.03932943e-01 -1.83026498e-01  4.09134592e-01 -3.08076768e-01
 -1.78492614e-01  5.45909716e-01  3.87890674e-01  2.66391779e-01
  4.07110827e-02 -2.13368981e-01 -5.75333422e-02 -1.49758669e-01
  4.90852544e-01  2.67888495e-01 -2.94838915e-01 -2.42853727e-01
 -7.20132021e-01  8.22100742e-01 -1.72957830e-01 -6.95564408e-01
 -1.89726305e-01 -4.64758976e-01  1.00505126e-03 -5.13556790e-01
 -6.37565156e-02  3.61880559e-01 -4.59416898e-01 -9.48027874e-01
 -3.54225331e-01 -2.31341668e-01  4.15541899e-01 -6.84119788e-02
 -8.78260507e-02 -3.00572097e-01  9.53446061e-02 -1.25862932e-01
 -5.33563394e-01  1.07002904e+00  2.63777968e-01  6.46315104e-02
  1.59710387e-01 -6.10934581e-02 -3.87790501e-01  2.78127109e-01
  2.55040762e-01 -7.45537684e-01  3.18272085e-01 -5.68936327e-01
  7.93071237e-02 -2.37656261e-01 -2.09350340e-01 -1.42378959e-01
 -2.21401753e-02 -2.33600809e-02  2.03263312e-01  1.36890960e-01
 -3.23497586e-01  1.73193683e-02  1.12660694e-01 -4.64490451e-01
 -9.57789944e-02  9.56489535e-02  5.03647579e-02  3.63804927e-01
  1.33367406e-02 -4.84406417e-01  3.62850776e-01  9.32302391e-02
  1.54909104e-01 -1.61140784e-01  3.24545359e-01 -2.16704191e-01
 -2.88930196e-01  3.80322520e-03  3.89355467e-01 -3.45771163e-02
  3.40667540e-02  1.04191493e-01 -2.44613668e-01  2.40431363e-01
 -1.13709427e-01 -3.51951509e-01 -1.79713292e-01  7.57386739e-01
  1.32792496e-02 -3.83708269e-01 -5.80283651e-01  5.51847275e-02
  1.84248291e-01  4.33699532e-01  2.15108570e-01  3.30008823e-01
  2.33628858e-01 -2.25572811e-01 -4.30119820e-02 -3.66299879e-01
  7.33061689e-02  3.58147774e-01  8.29814114e-02  5.38638794e-02
 -2.07843509e-01  2.29195334e-02 -2.88619507e-01  2.26731929e-01
  2.58278659e-01 -8.18512474e-03 -4.45232266e-01 -1.81480941e-01
 -2.28423807e-01  3.44022282e-01  1.40276451e-01  2.22539044e-01
 -9.96055688e-02 -3.11180867e-01  4.22325813e-02  2.02839613e-01
 -1.33267190e-02  3.69989562e-01 -1.65775926e-02  2.47791383e-01
  2.87418941e-02  2.78540402e-01  2.02195576e-01  5.76932125e-02
  1.26423319e-01 -2.01884730e-01 -1.28756614e-01  7.66234215e-02
 -8.51236064e-02  1.52008858e-01 -2.20318412e-01  1.52731011e-01
 -2.28454657e-01 -8.58377582e-03 -1.90074958e-01 -1.20325644e-01
  6.90752583e-02 -9.47337146e-02 -4.98610135e-02  2.10684012e-02
 -5.18828650e-01 -2.07071826e-02  2.21944837e-01  9.03281787e-02
 -1.96527338e-01 -1.68936267e-01 -7.55586904e-02 -5.64907990e-03
  1.01971227e-01 -1.02636774e-01 -1.74192356e-01 -1.29547881e-02
  2.39731532e-01 -1.36966168e-01  2.12903551e-01  8.37649211e-02
 -5.46596603e-01 -9.21709803e-02  1.88269962e-01 -1.79855612e-01
  5.87668900e-02  3.26994606e-01  2.08499137e-02  9.65378157e-02
  9.45475479e-03 -9.18217221e-02  6.45708630e-03 -3.21196936e-02]
it does something
Int64Index([302, 303, 304, 305, 306, 307, 308, 309, 310, 311,
            ...
            398, 399, 400, 401, 402, 403, 404, 405, 406, 407],
           dtype='int64', length=106)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2241)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[ 1.98265136e+01  3.13744795e+00 -4.15586290e+00 -1.10549980e+00
 -1.10443114e+00  3.26197450e+00 -4.85589742e+00 -5.60512330e+00
 -1.21104335e+00 -5.29746313e-01  1.11049700e+00  2.69156113e+00
 -1.19561222e+00  1.68508093e+00  2.63059222e-01 -1.31612399e+00
 -2.82293622e-01  3.73190629e+00 -2.14940702e+00  2.08881264e+00
  2.09021184e+00  1.14657395e+00 -5.25999982e-01  2.27718656e+00
 -8.15517935e-01  1.23844634e+00  4.79748411e-01  1.44045316e+00
  2.40095171e+00 -7.78306653e-01  2.57817909e+00 -6.41194701e-02
  1.10923196e+00  1.96714323e+00 -2.35598983e-01 -5.22037312e-01
  2.21918000e-01 -2.23559259e+00 -1.17688549e+00 -1.53757880e+00
 -1.11769029e+00 -2.90842288e+00 -4.69457131e+00 -5.56747910e-01
  1.26785334e+00  7.63732222e-01  1.90118520e+00 -6.97436750e-01
  2.85942967e-01 -2.32513006e+00 -1.15924876e+00  1.14870838e+00
 -1.44224949e+00  4.21722219e-01  1.72379296e+00 -3.41647510e+00
 -2.28512920e-01 -2.27357025e+00  1.98267885e+00 -1.72248416e+00
 -2.02421107e+00  1.62794761e+00 -3.19594339e-01 -8.50756071e-01
 -1.77851112e-02 -2.88075182e+00  2.20859085e-01 -9.55343596e-01
  1.63883309e+00 -1.58383444e-01  5.38632793e-01  1.83538527e+00
  1.78266765e+00 -1.71953956e+00 -1.82860007e-01  5.84936444e-01
 -2.02687947e-01  4.38333862e-01 -1.63478464e-01  5.37230860e-01
 -2.23622983e+00 -5.83246298e-01  6.05697449e-01 -2.23812411e+00
  4.46956473e-01 -2.03911595e+00  1.56029530e+00  1.44984308e+00
  3.05177544e-01 -6.87391541e-01 -2.30070141e+00 -1.51621119e+00
  2.67090838e+00  6.17093204e-01  1.75767949e-01  4.44192963e-01
  2.11988112e+00  9.22740017e-01 -5.44464171e-01  9.76267370e-01
  1.53644211e+00 -2.81556335e+00  4.23791047e+00  1.39741538e+00
 -1.56143200e+00 -1.94503961e+00 -2.42555553e+00 -2.82189252e-01
 -3.53983773e+00  2.88725988e-02 -1.58981201e+00  3.50164158e-01
 -1.32937703e+00 -2.15271808e+00  9.10824436e-01 -8.94803120e-01
 -2.39718163e-01 -1.12470684e+00 -4.06566725e-01 -5.41967046e-01
 -6.84603556e-02  1.15382637e+00 -4.64642944e-02 -2.26399567e-01
  8.54827785e-01  1.01153327e+00  1.26959798e+00 -1.13126563e+00
  8.95085155e-01  1.38317619e+00 -1.36302432e+00  7.25168809e-01
 -2.45435549e-01  1.01910070e+00  6.74127301e-01 -1.04206588e+00
 -9.42670111e-01  6.99965654e-01  5.89516352e-01 -1.58963890e+00
 -5.93518585e-01  2.62205775e-01  2.26491806e-01 -6.06787435e-01
 -2.16849082e+00 -1.37367218e+00  4.37649561e-01  1.51286524e+00
 -2.98196127e-01 -1.28008466e+00  1.78634471e+00 -8.75609757e-01
 -1.44756465e+00 -1.07486619e+00  5.66049815e-01 -8.73149610e-01
 -5.87709264e-01  2.46009791e-01  1.80402819e+00  6.90782753e-01
  5.20250921e-01  6.89015463e-01  8.97276122e-01 -1.26475927e+00
 -8.34429230e-01  2.27905490e-01  6.36421825e-01  8.66067475e-01
  3.42674888e+00 -1.39572993e-01 -1.77485527e+00 -1.93580822e-02
 -1.20875798e+00 -1.53647747e+00  8.53771342e-01  2.68634718e+00
 -2.23901468e+00  7.68992459e-01 -3.11964670e-01 -2.86032393e-02
 -2.05985029e-01 -8.00764592e-01  1.18566603e+00 -2.23195848e-01
 -4.84670293e-01  7.33822229e-01 -6.26866362e-01  6.49558726e-01
  2.83490379e-01  2.39281775e-01 -1.06698693e+00  6.14154174e-01
  2.90715440e-02  1.92446213e+00 -8.89739348e-01  9.15432412e-01
  5.61313405e-01 -1.04812588e+00 -5.91802104e-01  1.20413263e+00]
it does something
Int64Index([1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311,
            ...
            1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706],
           dtype='int64', length=405)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1942)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-1.10246019e+01  2.75255707e+00  1.58829551e+00  3.28404356e-01
  8.63545573e-01  5.74724794e-01  2.36917211e-01 -7.76226934e-02
  2.83756834e-02 -2.11277127e-01 -4.27470356e-01  7.53800913e-01
  4.18440138e-01  7.68524030e-01 -4.75064453e-01  6.63940274e-01
  1.19112251e-01  1.11292501e+00  7.24901634e-01  5.29084495e-02
 -7.37760518e-01 -5.02389667e-01 -6.54121852e-01 -8.85673016e-01
 -8.82885935e-01  2.58194043e-01  5.18434150e-02  1.27294019e-01
  6.02977210e-01  6.47751583e-02  2.15965702e-01  6.12596337e-01
 -1.05647380e+00  3.40511099e-01  1.00777386e+00  1.54044905e-01
 -3.56577424e-01 -1.05141510e+00 -1.04128225e-01  1.00270256e-01
  1.72945050e-01  2.49396043e-01  6.61065646e-01 -7.51684526e-03
  5.34239923e-02 -2.22505415e-01 -2.56287976e-02  5.76805729e-01
  2.02478801e-01  3.17636990e-01  4.16373024e-02  6.77623462e-02
 -1.39212380e-01 -1.27821001e-01 -4.02244802e-01 -1.43161495e-02
 -1.28413514e-01 -1.49175319e-01  5.34300290e-01  6.23293245e-02
  2.70940976e-01 -9.41507021e-02  8.47648790e-02 -4.23613622e-01
 -7.28783934e-01  1.87419935e-01 -2.42153290e-01  2.84197815e-02
  3.49361856e-01 -3.49111023e-02 -9.50724496e-02 -7.34041094e-01
 -5.29608614e-01 -2.60074375e-01 -8.58303038e-02  2.38789683e-01
  3.21432282e-01  4.25000238e-03 -2.11027775e-01  1.89075059e-01
  3.33293794e-01 -2.61260766e-01 -5.10078646e-02 -1.03338398e-01
  1.29218124e-02 -1.32618708e-01 -2.00069979e-04 -1.20483261e-01
  3.13217515e-01  2.31175945e-01  1.34541910e-01 -2.96802784e-01
 -2.49993707e-01 -2.91566609e-01 -3.92659860e-01  4.01246757e-01
  1.34079035e-01 -3.56801945e-01 -9.56409047e-02 -2.53200422e-01
  1.12710205e-01 -4.11639455e-03 -1.68956603e-02  3.79346715e-01
  4.31860061e-01  1.71413245e-01 -2.41341822e-01  4.07185323e-01
 -4.39385095e-01 -1.48608194e-01 -4.41912737e-01 -2.36951402e-01
  4.01058387e-01  2.33653995e-01  5.86090504e-01 -2.00853896e-01
  1.02767143e-01 -2.75885587e-02 -5.51629553e-01  2.25299561e-01
  2.56553091e-01  4.32905531e-01 -2.35125871e-01  8.87559069e-01
  1.19403057e-01 -4.20668171e-01 -4.07670025e-02  9.64604652e-01
 -1.13080645e-01  2.02806780e-01  4.71553161e-01  2.25369919e-01
 -1.33515010e-01 -3.96987016e-01  1.03657236e+00  2.94884504e-01
  3.69182525e-01 -3.17231677e-01  3.52969215e-01  4.72966824e-03
 -5.60064900e-01  8.71114385e-02  1.42366561e-01 -5.49298242e-02
 -8.79252180e-01  1.41017285e+00  4.77505193e-01 -1.91826575e-01
  5.85714357e-02 -3.22562730e-03  3.91873675e-01 -7.62721005e-02
  1.89465298e-01 -4.36976778e-01 -1.59350040e-01  1.75193583e-01
  1.57297443e-01 -6.50833163e-01 -1.73005248e-01 -2.41095667e-01
  5.75574871e-02 -2.56486522e-01 -1.34838337e-01 -4.01439589e-01
  7.97220952e-02  1.67721432e-01 -9.90913117e-02  2.80758141e-01
  1.04246530e+00  1.93964925e-01 -4.47140226e-01  3.32506136e-01
  3.10404509e-01  3.88861571e-01 -3.28291430e-01 -9.82368458e-02
 -5.54376226e-02 -9.51010976e-02  3.28657144e-01 -3.04179252e-01
  2.83909906e-01  3.81885746e-01  1.82928294e-01 -8.05377217e-02
 -2.83616793e-01  2.75503498e-01  1.61358405e-01  2.30204954e-02
  5.84750246e-01 -1.38605598e-01 -4.52419401e-01  1.20857096e-01
 -1.26742611e-01 -2.94787573e-01 -1.90266884e-01 -4.03868326e-01
  2.59308058e-01 -2.13611368e-01  6.80167421e-02 -3.88314509e-02]
it does something
Int64Index([1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724,
            ...
            2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320],
           dtype='int64', length=606)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1741)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-1.16276321e+01  2.83077710e+00  2.10684807e+00  2.85119478e-01
 -9.72340415e-02 -4.05900445e-01  7.72639532e-01  1.25626319e+00
 -4.55610232e-01 -2.50786827e-01  2.96611405e-02  8.54333769e-03
 -6.25147142e-01 -3.68594006e-01  8.87505066e-01  2.59388000e-01
  9.51591647e-02 -1.94235325e-01 -3.03927769e-01 -2.81606289e-01
  3.91719268e-01 -6.61278502e-02 -6.73831443e-02 -2.51307027e-01
  3.86536259e-01  2.70835606e-01  6.46846570e-01  1.60046809e-01
 -3.54221613e-02  9.58930739e-02  1.96116711e-01  2.16808891e-01
 -2.95078033e-01 -1.09661904e-01  1.14078769e-01  8.43576742e-02
 -1.62712373e-01 -3.76001960e-02  3.15551978e-01 -2.36343378e-01
  7.66599238e-02 -3.41819528e-03  3.15489509e-01 -1.84352440e-01
  2.87346767e-01  1.15230362e-01  4.11363506e-02 -6.23675394e-02
 -4.27203568e-01 -8.89590566e-02  2.30013549e-01  1.01243598e-01
 -1.64171607e-01  3.01563351e-01 -3.45933884e-01 -1.97653281e-01
 -3.23693449e-01  2.68399887e-01 -8.89063206e-02  1.68778175e-01
  2.03822488e-01  4.22449860e-02  1.73302099e-01  2.18260518e-01
 -1.37233863e-02  2.37800655e-01 -1.39287738e-01 -8.52796708e-02
  1.89869018e-02 -1.12585614e-01  1.97448487e-01 -2.74552266e-01
  5.10930777e-02  4.62737968e-02 -1.00576856e-01 -2.45893297e-01
 -2.64834100e-02  8.30227753e-02 -7.64363036e-03 -1.04012728e-01
 -4.97813307e-03 -5.39848331e-02 -3.12627003e-02 -1.86439913e-01
 -7.84982012e-03  1.33788608e-01 -1.46864909e-01  2.75243731e-01
  2.26895360e-01  5.52753051e-03  2.42688722e-01  2.38544771e-01
  2.37676291e-01  2.20785032e-01  8.79679903e-02 -2.40692303e-01
  4.07876686e-02  4.70791709e-01 -3.03901271e-02 -8.87078754e-02
 -1.62040890e-01 -2.74066691e-01 -1.67946598e-01 -2.06574051e-01
  2.02684071e-01 -1.51881888e-01  6.07143625e-02  2.08055180e-01
 -9.44773036e-02  2.97642742e-01 -2.94826965e-01  6.94641834e-02
 -1.72851411e-01  1.68684244e-01 -3.10744387e-02 -3.14590944e-01
 -6.34154557e-02 -1.06550343e-01 -2.11686149e-01  1.69432504e-01
  1.34504312e-01 -3.82979923e-01 -2.07837653e-01 -3.35540266e-01
 -1.69217203e-02 -5.51037332e-02 -6.93311774e-02 -4.77143043e-02
  1.16309639e-01 -3.49063006e-02  6.33548702e-02 -3.14218148e-03
 -8.34350961e-03 -6.55049941e-02 -1.64793863e-01 -2.84322244e-01
  2.55404679e-01 -1.75601088e-01 -4.11349239e-02  4.01865671e-01
 -1.02736527e-01 -8.43135353e-02 -2.73596332e-02  4.75276594e-02
 -3.52453203e-01 -2.87778817e-01 -3.76855018e-02  1.02465526e-01
 -9.08990954e-02 -6.05144079e-02  1.73994754e-01  4.60370059e-02
  1.93175225e-01  8.27710665e-02 -9.13334788e-02 -3.46481885e-01
 -1.28705033e-01 -6.92180987e-02 -2.02467040e-01  3.06752101e-01
 -3.74697536e-01 -6.36107999e-02  1.55837559e-02  1.59390811e-01
  7.08050479e-02  7.10438338e-02  1.56940176e-01 -4.72296540e-02
 -9.02979341e-02 -1.98572291e-01  1.90639600e-01  5.01109876e-02
  6.18469169e-02  1.02296822e-01 -2.95928234e-01 -2.11105220e-01
 -7.06571156e-02 -4.83679327e-02 -5.10705048e-02 -5.30192923e-02
  7.10375717e-02 -4.72448332e-03  6.83758791e-02 -5.50785377e-03
 -3.20482324e-01 -1.99318488e-02  1.05470293e-01 -6.87719246e-02
 -1.25944089e-01 -7.06351337e-03  1.85500634e-01 -1.74805183e-01
 -2.49460710e-02 -1.62749964e-02  2.59764085e-02 -2.89851746e-01
  1.36154969e-01  4.71289118e-02 -2.18889856e-02 -2.08369364e-02]
it does something
Int64Index([1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311,
            ...
            1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706],
           dtype='int64', length=405)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1942)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-1.10102248e+01  1.91943659e+00  1.10571471e+00  9.46661080e-01
  3.05860587e-01 -1.20254801e+00  1.62641192e+00  7.93205640e-01
 -3.97940589e-01  1.98332468e-01 -4.17008935e-01  4.04506727e-01
 -8.42076014e-01  2.04353722e-01 -1.87222581e-01  1.42205791e-01
  3.29339055e-01  1.90112515e-02 -6.10088317e-02  6.92646372e-01
 -1.87746148e-01  2.92932677e-01 -1.50060839e-01 -3.74487805e-02
 -4.28175095e-01 -4.06821784e-01  3.83424072e-02  5.46143124e-02
  7.94535806e-02 -4.85948648e-01  1.08582738e-01 -2.57473896e-01
 -6.39436699e-01 -9.50022056e-02  5.47795493e-01 -1.36418504e-01
  3.72613996e-02 -2.19534356e-01 -2.45087871e-01  7.21632867e-01
 -3.64033617e-02  3.49019294e-01  2.07702231e-01 -2.54089716e-01
  4.36389264e-01  2.30821183e-01  1.92529716e-01  3.50814786e-01
 -4.16004626e-02 -6.32961580e-02 -4.75429381e-01  8.15919729e-02
 -1.57162430e-01  5.94770311e-02  2.61365289e-01 -8.77531823e-02
 -9.05189311e-02  2.58546579e-01  1.02192632e-01  8.37978056e-02
 -1.22605488e-01 -2.01121621e-01 -9.92369072e-02 -2.76889582e-01
  1.14543963e-01  1.19939127e-01 -3.01801186e-02 -5.65620256e-01
  2.22610188e-01  4.43945340e-02  1.46556945e-01 -2.52711242e-01
 -1.08075892e-01  4.58161692e-02  1.00392892e-01 -5.20690733e-02
 -4.21625567e-02 -9.34758983e-02 -1.10327576e-01  1.05620988e-01
  9.02768294e-02 -1.43895184e-01 -2.12950250e-01  2.85874002e-01
 -3.18530828e-01 -1.74501393e-01  6.96754976e-03  2.28574510e-02
 -2.85807276e-01 -3.22216454e-01 -2.32991357e-01  3.85942248e-01
  1.97414665e-01  1.43197263e-01 -7.55086179e-03 -1.80858050e-01
  3.89488220e-02  1.42063254e-01 -2.35035417e-02  2.26035373e-01
  4.71657138e-02 -1.62386766e-01 -2.78828840e-02 -8.11899321e-02
  2.74504858e-02 -3.32772648e-01 -1.76665829e-01  8.81558478e-02
  1.78774505e-01 -3.49623747e-01  1.20155244e-02  9.07831349e-02
 -5.51932151e-02  2.30128149e-01  9.71445798e-02  4.09759111e-01
 -1.40392520e-02 -6.03646495e-02  7.04383933e-02 -2.39787955e-01
  2.03227357e-02 -1.61059905e-01  5.58042660e-02  6.03860451e-03
  1.99119454e-01 -8.20792337e-02  5.55598272e-04  2.46420485e-01
  7.43388948e-02  5.94360096e-02  2.02584009e-01 -1.93292400e-01
 -1.32055272e-02  2.57732452e-01 -3.52618914e-02 -1.20194723e-01
  1.65472657e-01  2.83830314e-01  1.67281992e-01  7.18479026e-02
  1.06775796e-01  4.98979975e-02 -9.40172573e-02  1.67805980e-02
 -3.90715483e-02 -5.73511465e-02 -2.48563276e-01  1.21959275e-01
 -6.51179746e-02  7.41511005e-02 -1.10358592e-01  5.01589460e-02
  2.56241733e-01 -6.68703612e-02 -1.92074481e-02 -3.56800211e-02
 -3.78715838e-02  1.35805430e-01 -1.14764171e-01 -9.11021115e-02
  7.30317901e-02  3.94608698e-02 -2.97552691e-02 -7.26618052e-02
 -1.58060224e-01 -7.86142397e-02 -7.55986148e-02 -5.62486326e-02
 -8.49284212e-02  3.78386877e-02  1.10703433e-01 -5.43702471e-02
  2.15228007e-01  3.92649690e-02 -6.07942486e-02  7.18290676e-02
  1.05480331e-01 -9.14208537e-02  1.45218153e-02 -1.66882336e-01
 -4.60995126e-02  3.43670503e-02 -1.72811874e-01  2.29462402e-01
  1.50229775e-01  7.69785795e-02 -3.38523628e-02 -1.13680619e-02
  1.50938558e-01  9.79081174e-02  8.18401607e-02 -9.68823550e-02
  5.90463276e-02  7.32825723e-02  5.42200869e-02 -5.33765768e-02
  1.74341934e-01  5.90596148e-02  1.81422165e-01 -1.95985353e-01]
it does something
Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,
            ...
            139, 140, 141, 142, 143, 144, 145, 146, 147, 148],
           dtype='int64', length=149)
Int64Index([ 149,  150,  151,  152,  153,  154,  155,  156,  157,  158,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2198)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[ 7.79979511e-01  5.66199679e+00 -4.67374517e-01  7.77199560e-01
  2.72859768e+00  2.91053797e+00 -2.32955790e+00  5.27680229e-01
 -5.85130727e-01  1.43134049e-01  1.94986002e-01 -1.25079761e+00
  2.26394492e-01  2.30840003e-01  7.29464353e-01 -1.21094636e+00
 -1.56848035e+00 -3.92598919e-01  1.72132680e+00  3.47815981e-01
 -1.07529552e+00 -2.06865007e+00  2.61421492e-01 -1.59302913e-01
  1.38785887e-01 -1.40286050e+00  2.53599528e-01  1.46675303e+00
 -1.92428757e-01  1.38418289e+00  8.67430870e-01  8.03279168e-01
  3.91015925e-01 -5.89309734e-01 -1.93782356e+00 -2.22041900e-01
  9.89634283e-01 -6.68721103e-01 -1.25598748e+00  9.21766585e-01
  3.74691240e-01  6.00029196e-01  5.46645894e-01 -7.87049076e-01
  6.87137319e-01 -1.53664207e+00  9.27650237e-01  2.21848397e-01
  1.24297464e-01  7.28601559e-01 -1.12288487e-01  1.81917103e-01
 -6.56896304e-01  9.83932095e-01 -2.40887416e-01 -6.26239861e-01
 -3.51423171e-01  9.05682270e-01 -3.70480928e-01 -1.01969788e+00
  1.26549166e+00 -5.48268760e-01  3.08057191e-01  3.43077748e-02
  3.56866905e-01  1.17740294e+00 -1.27193162e-01 -9.69929255e-01
 -4.81735634e-01 -1.24866265e+00  1.13215292e+00 -6.84391562e-02
  6.75877039e-01  2.98447781e-01  6.17664177e-01 -2.39530937e-01
  5.13854011e-02 -7.49938245e-01 -1.61408814e-01  9.68963753e-01
 -2.95355293e-01 -2.37204432e-01  6.92989165e-01  7.55381913e-01
 -2.93818562e-01 -7.03876233e-01 -1.15285843e+00  1.96918676e+00
  3.47652894e-01 -1.51046898e-01  8.95236481e-02  5.70281238e-01
 -4.54093616e-01 -3.56740769e-01  7.39510073e-01 -1.11281801e-01
 -1.25917878e-01 -4.07330000e-01 -6.38066354e-01 -3.11186446e-01
  1.02458921e+00 -5.31647601e-01 -6.66642293e-01  4.22182563e-01
 -2.46380906e-01  9.40185354e-01  3.41349544e-01  4.48645679e-01
  1.50343254e-01  6.50406698e-01  5.52838362e-01  2.78951784e-01
  4.92360304e-02 -8.80518304e-02  3.16926511e-01  1.29669843e-01
 -1.48545827e-02 -9.74822438e-02 -1.32085552e-01 -2.33186070e-01
  5.64438823e-01 -5.30935963e-02  1.73909851e-01 -2.29842211e-02
 -3.38272819e-01 -1.93254643e-01 -3.85312698e-01 -8.36641744e-01
  8.87772091e-01 -6.61983317e-01 -1.24450899e-01  1.75205309e-01
  8.52275126e-02 -1.80537889e-01  8.60257506e-02  3.26996835e-01
 -3.75033401e-01 -1.54652822e-02  1.48632041e-01  6.31425806e-01
 -6.72914327e-01  2.48599318e-01  7.45108650e-02 -4.48878021e-01
  5.21016265e-01 -5.93750995e-01 -1.47352308e-01  2.76662080e-01
 -2.20296231e-01 -6.87103518e-01  6.78857242e-01  4.82904241e-01
 -1.08916078e-01  1.20659489e-01 -3.68088448e-02 -1.89083518e-01
  1.40610423e+00  2.05298272e-01 -7.35362757e-01  2.87929206e-01
  3.26140784e-01 -2.55679767e-01 -9.39823045e-02  5.45368847e-01
 -3.99087822e-01  5.58088857e-01  2.90496717e-03  4.71335083e-01
  7.13799249e-02 -1.92462486e-01  6.04026978e-01 -1.47989889e-01
 -2.35372969e-01  4.25484119e-02  3.12432856e-01 -9.23221939e-01
  3.96893157e-01  3.61841242e-01 -2.97207310e-01 -1.71035688e-01
 -1.12508279e-01 -1.25169602e-01 -2.95932864e-01  6.50788981e-01
  2.13912576e-01 -5.15939342e-01  3.46465276e-01 -1.58928863e-01
  1.21235385e+00  1.39280088e-02  1.39964446e-01  2.18367417e-01
  9.50138602e-03 -3.23753911e-01 -9.81196404e-02 -4.16838145e-01
 -7.14942798e-01 -7.03684566e-02  2.25332096e-01  3.60595624e-01]
it does something
Int64Index([1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311,
            ...
            1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706],
           dtype='int64', length=405)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1942)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-1.22842254e+01  3.18232875e+00  2.33587044e+00  6.91734771e-01
  5.16328921e-01 -2.69920873e-01  8.70196966e-01  1.11226504e+00
 -3.15115638e-01  1.34391407e-01 -2.91523166e-01  2.48085656e-02
 -2.72767033e-01 -1.45066914e-01  4.24187935e-02 -3.00513780e-02
 -3.56876585e-02  1.88806745e-01 -2.33685878e-01  2.07642772e-01
 -4.32935631e-01 -1.02541974e-01 -1.24526491e-02 -1.73886678e-02
 -2.15203660e-02 -3.04034464e-01  2.01920401e-01  5.96352211e-02
  1.95860629e-01 -3.96033788e-01 -9.79778463e-02  7.96831223e-02
 -3.57125877e-01  3.32418164e-01  4.73199804e-01 -7.38079353e-02
 -8.13514138e-02 -3.84873918e-01 -8.92903541e-02  2.14432855e-01
 -1.49900854e-01  1.32251144e-01  4.11924421e-01 -3.42337563e-02
  1.92229225e-01  3.96285731e-02  8.22966497e-02  8.10724514e-03
 -4.50435205e-02 -1.53867294e-01 -1.58934283e-01  1.11449987e-01
 -1.65924606e-01  1.77120915e-02  3.65143894e-03 -8.09040864e-02
 -1.08276770e-01  2.25257728e-02  5.99672157e-02 -7.96862607e-02
  3.15479044e-02 -1.65488483e-01  1.32930072e-01 -6.79466203e-02
 -2.70158408e-01  2.50665072e-02 -1.43631285e-02 -1.83807113e-01
  1.30790878e-01  7.22951813e-03 -1.01633883e-01 -1.28927434e-01
  3.44067781e-02  6.20833882e-02 -1.09092092e-02  5.58036134e-02
  8.77622924e-02  2.72228862e-02 -1.16293142e-01  2.61032975e-02
  1.36881380e-01 -1.24334900e-01 -3.59286159e-02  8.97237367e-02
 -9.73093043e-02  6.61616783e-02  1.48125121e-01 -9.36774610e-02
  4.54370261e-02  4.22330416e-02  2.48559076e-02 -5.30877601e-02
  2.82081300e-02  9.50064665e-02 -8.97748255e-03  8.07423955e-02
  3.89350997e-02  6.95179093e-02  1.08149407e-01 -6.11111277e-02
 -4.15374411e-02  9.55195921e-03  1.31656343e-02  7.49413471e-02
  4.42708125e-02 -1.56767782e-01 -1.58086346e-01 -1.85332693e-02
 -9.98932349e-02 -9.14930567e-02 -5.83099210e-02 -2.10235219e-02
  1.36406866e-01  7.47981622e-03  4.93508677e-02  3.90318087e-02
 -4.44038811e-02 -9.75859925e-02 -1.07201508e-01  1.09843338e-02
  7.03037236e-02  6.10814977e-02 -7.41122418e-02 -6.75003879e-02
  6.53931115e-02  7.54704045e-03 -1.54763986e-02  1.63050236e-01
 -9.73060574e-02 -9.53651018e-02  8.95190914e-02 -1.26451444e-01
  1.07864234e-01 -1.44187381e-02 -7.95758809e-02  4.96872253e-02
 -1.24413150e-02  1.37602841e-01  3.15185420e-02  3.59031827e-02
  6.78436049e-02 -7.08486762e-02 -3.68544428e-02  3.11503411e-02
  1.24525185e-02 -5.31996362e-02 -1.71150819e-02 -1.17055915e-02
 -1.30666313e-01 -7.16294400e-02  3.78846478e-03 -1.08543224e-01
 -5.70512441e-02  2.40918408e-02 -3.47572715e-02 -6.88022982e-02
 -2.21852497e-02  1.04191522e-01  8.88518477e-03  1.18558903e-01
  1.50183129e-01  4.40231405e-02 -3.63374416e-02 -1.68399228e-01
 -8.32222408e-02 -1.14730021e-01 -6.77099553e-02 -2.82067685e-03
  1.35559933e-02 -1.37272913e-01  3.22400578e-02 -2.06915627e-01
  1.91727779e-01  1.89812663e-02 -7.94236884e-02  1.42896405e-02
  2.40919239e-01 -1.45200319e-02 -1.02055302e-01 -9.85698959e-02
  1.84446971e-02  8.54893504e-02 -2.89608640e-02 -3.01841322e-02
  1.01689463e-01  8.11498648e-02 -2.00574989e-02  1.64205479e-01
  1.37492266e-02 -5.94029764e-02 -2.56319349e-02  2.47829577e-02
 -7.78444023e-03  1.75985488e-02 -4.54916819e-02  9.30464735e-02
 -1.31736139e-02  3.51521132e-03 -1.29066610e-02  9.90547783e-02]
it does something
Int64Index([ 762,  763,  764,  765,  766,  767,  768,  769,  770,  771,
            ...
            1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259],
           dtype='int64', length=498)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1849)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-1.11119475e+01  2.30432787e+00  1.42426559e+00  6.35457419e-01
 -3.64889548e-01 -4.45364733e-01  7.24410524e-01  3.96991806e-01
 -4.09748604e-01  3.58634865e-01  1.12049037e-01  2.14242745e-01
  1.81599435e-01  7.89191847e-02 -3.76832128e-01 -8.87574094e-01
  5.19711275e-02  7.49275053e-02 -5.05290793e-01 -7.66508900e-02
 -5.32131942e-01  2.60094839e-01  8.60011923e-02  6.75165714e-01
  1.44837768e-01  2.02179715e-01  2.03003532e-01  6.58556691e-01
 -6.59475402e-01 -3.50679689e-01  4.29321445e-01 -2.08466503e-02
  3.84386603e-02  1.31123688e-01  1.17906322e-02 -9.05252258e-02
  8.15217316e-02  3.29092280e-01  2.67863699e-02  3.19195667e-01
  5.49120271e-01 -5.88092993e-01 -2.80997470e-01 -3.06351321e-01
 -3.97832299e-01 -6.50538182e-02  8.57550278e-02 -1.39559708e-01
 -2.92204438e-01  1.94354748e-01 -3.68399475e-02 -6.27579943e-01
 -5.33998298e-02 -4.82859194e-02  1.14458436e-01  2.37839260e-01
  4.21588431e-02 -1.89502301e-01 -1.00601536e-01  9.98706896e-02
 -6.08152646e-02  2.89365427e-01 -5.44253679e-01 -1.84706554e-01
  1.74090011e-01 -4.20093393e-01 -1.21231598e-01 -2.85713537e-02
 -1.91336752e-01  2.16060518e-01  1.99053399e-01  2.00274391e-01
  2.18821451e-01  9.26483517e-03 -3.47192583e-02 -2.40708877e-01
 -4.06892553e-02 -2.50323344e-01 -1.89634094e-01 -4.90392879e-02
  4.07733994e-01 -2.09707462e-01 -1.76710756e-01  1.08024414e-01
 -9.80413768e-02  2.55426731e-01 -2.37872001e-03  2.14892825e-01
 -7.65832989e-02  1.01104378e-01 -9.26092788e-03 -5.89185097e-02
  2.15275605e-01 -3.11971806e-02  9.83171938e-02  1.93903793e-01
  1.29141547e-01  2.11437925e-01  2.70534501e-01 -1.61907607e-01
  3.63585670e-02  5.84937838e-02  1.57382085e-01  4.01546769e-02
  6.74481013e-02 -7.66915379e-03 -1.42212373e-01 -2.86760644e-02
  6.88048956e-02 -1.47774100e-01  1.59535249e-01 -2.00570361e-01
  1.29108613e-01  1.10860837e-01 -1.65493643e-01 -2.76199496e-02
 -5.20620783e-02  8.21027461e-02 -1.42464410e-01  1.69317779e-02
  9.23480112e-02  1.87764229e-02 -1.48177482e-01 -2.92127804e-01
 -2.64459864e-01 -1.08590111e-02  5.30170254e-02  6.14642798e-02
 -1.08909001e-01 -9.85939853e-02  6.97360364e-02 -2.66991533e-02
  1.02102850e-01  9.42009544e-03 -6.40110324e-02  7.87163761e-02
 -4.91135418e-02 -2.10750692e-02 -6.41046468e-02  3.78089457e-02
 -6.22412627e-02  3.30018949e-02 -2.34600391e-01  2.42800928e-01
  1.51927303e-02 -8.48148945e-02  3.07921759e-01  9.52860924e-02
 -1.32428177e-02  3.14026268e-02  1.00294186e-02 -1.89537504e-02
  1.39556192e-01  6.14379590e-02  5.93894072e-02  9.51110656e-02
 -1.63633349e-01 -9.56604504e-02  7.28642382e-02  1.40523347e-01
  4.54050594e-02  1.96105947e-02 -8.09406249e-02  2.05940996e-01
 -1.68514779e-02  1.22461887e-01 -1.95111644e-02  2.49262971e-02
 -2.53431098e-02  1.73152329e-01  9.63536081e-02 -2.52523409e-02
  2.16203428e-01  9.37127166e-02 -2.35798131e-02  1.16762500e-01
 -8.07242999e-02  1.02659141e-01  8.10447813e-02  3.06492980e-02
  8.20915206e-02 -1.11082488e-01 -2.55030040e-01  9.30462854e-02
 -1.27961854e-02  2.30436581e-02  2.23419499e-02 -4.36257535e-03
 -4.60632810e-02  7.97842864e-03  1.48007833e-01 -1.27834588e-02
 -1.47788865e-02 -9.80292901e-03 -1.46653268e-02 -6.84311886e-02
  6.95310493e-03 -1.90128777e-01  1.10490857e-01 -1.56174195e-01]
it does something
Int64Index([1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311,
            ...
            1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706],
           dtype='int64', length=405)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1942)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[ 4.61867505e+00  3.33303407e-01 -4.74097230e+00  3.28880918e+00
 -1.72814370e+00 -3.49276822e+00  1.35264267e+00 -4.69824956e-02
  1.06790458e+00  1.74911684e-01 -6.23578424e-01  2.26280560e-01
  9.71364991e-01  9.32892832e-01 -2.06437422e+00  1.90107382e+00
  2.79411334e+00  2.95888991e+00 -4.00659528e-01  2.93928696e+00
 -2.20435732e-01 -4.08263935e-01 -5.79183001e-01 -2.84958784e-01
 -1.82081802e+00 -1.25576034e+00 -4.19497914e-01 -3.17784073e-01
  2.11111211e+00 -5.38228856e-01  3.87072925e-01 -8.02280575e-01
  1.73349747e+00 -1.44010376e-01  5.30483797e-01  1.26148336e-01
  4.42781697e-01 -1.99771706e+00 -5.74745025e-01 -6.47046572e-01
 -5.57014026e-01 -4.83425933e-01 -6.16417363e-01 -1.26236339e+00
  1.32240208e-01  6.85128511e-01 -9.93811374e-01 -2.86725846e-01
 -2.42408036e+00  9.98240679e-01  1.53255086e+00  7.21733297e-01
  1.25375708e+00 -1.05972658e+00  2.14279080e-01  9.21541640e-02
  9.24545902e-01 -4.37273992e-01  9.43982994e-02  3.77770490e-01
 -1.99803548e+00  5.74290600e-01 -6.34316688e-01 -1.14871181e+00
 -6.28839763e-01  3.52514405e-01 -6.21571632e-01 -3.23988803e-01
 -6.33069078e-01  1.00602947e+00 -1.40453371e+00  9.60449478e-02
  1.90668385e-01  7.17650759e-01  1.64674020e-01 -7.32454237e-01
 -3.72325859e-01 -9.60035381e-01  4.69351243e-01 -2.55545700e-01
 -2.50060595e-02 -4.50160626e-01  2.45221008e-01  8.52575168e-01
  3.85616922e-02 -9.70291368e-01 -5.63491176e-01  8.74492351e-02
 -8.47631325e-01  2.19502306e-01  6.90434466e-01  1.34690831e+00
  4.00427450e-01  3.96893690e-01  5.77469430e-01 -3.57996653e-01
  4.23123477e-01  7.14693055e-01  3.19208064e-02  4.28323281e-01
 -2.75880782e-01 -4.70289270e-01  6.79903721e-02 -1.52970776e-01
  2.65542672e-01  4.66998984e-01 -9.90804573e-01  4.40252743e-01
  1.21016051e+00  4.70408325e-01  8.81259451e-02 -2.00646985e-01
  1.43081789e-01 -7.55660366e-02 -9.07170933e-01 -1.89838901e-01
 -4.70269897e-01  1.13415010e+00 -2.26579208e-02 -2.96073136e-02
  5.31679613e-01 -2.74836646e-02 -3.22281101e-01  1.13149036e+00
  2.21954483e-01  2.95385454e-01  1.33436736e-02 -8.10365314e-01
 -9.71749350e-02  1.03742981e+00 -2.28626532e-01  4.77639616e-01
  5.84040738e-01 -8.12145718e-02  3.28843196e-02  2.20373395e-01
  9.83781900e-01  8.64231280e-01  3.16193423e-01 -9.42583604e-02
  1.74330068e-01  5.11778521e-01 -1.48635605e-01 -5.17231931e-01
  1.21431033e+00  4.09229199e-01  2.35324750e-01 -1.41234728e-01
 -7.49287128e-01 -5.41837846e-01 -3.07585775e-01 -7.70366532e-01
  2.60300950e-01  8.17263142e-01 -3.39329277e-01 -1.20058813e-01
  7.84853366e-01 -2.40764119e-02  1.29263043e-01 -3.79630816e-01
  5.45592046e-01  5.66214810e-01 -6.10038308e-01 -4.78207157e-02
 -1.32692984e+00 -4.56209368e-01 -8.42282959e-01  6.42973202e-01
  7.63931345e-01 -3.12520069e-01  2.93252957e-02 -4.55140015e-01
 -6.31960631e-01  7.82785731e-01 -1.20176997e-01  5.38665451e-02
 -1.46220131e-01 -1.93881728e-02  4.05265408e-01 -3.91420209e-01
 -4.56272721e-01 -1.73244477e-01 -2.57994290e-01 -1.81025553e-01
  6.58249938e-01  1.56713686e-01 -3.23822015e-01  1.42211021e-01
 -2.12226963e-01  1.73474122e-01 -4.57904129e-03  1.52946358e-01
  4.09355807e-01  3.47885325e-01 -7.97264744e-02 -3.07800603e-01
 -1.21201965e-01 -1.09364253e-01  2.36006429e-01  3.49082871e-01]
it does something
Int64Index([1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724,
            ...
            2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320],
           dtype='int64', length=606)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1741)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-1.21182646e+01  2.68596257e+00  2.52686342e+00  5.92030584e-01
  5.92551489e-01 -4.41782611e-01  7.91607373e-01  1.01428331e+00
 -6.45201777e-01  4.34653910e-01  8.79025206e-02 -4.43486602e-01
 -2.20262723e-01 -3.63102663e-01  1.65113730e-01  9.12328046e-01
 -2.36575533e-01 -3.33091267e-01 -2.81727041e-01 -3.35347040e-01
 -1.94430400e-01  1.20009460e-01  2.50586525e-02 -1.15384399e-01
 -1.89497070e-02 -8.00716039e-02  2.05732494e-01  1.55669532e-01
 -1.24649513e-01  1.69522355e-01  4.69010935e-02 -1.75983923e-02
 -1.98625176e-01  2.66801370e-01 -3.36594024e-01  1.68116533e-01
  3.74703035e-01  2.86587588e-02 -7.51578893e-02  4.89076722e-02
 -2.21920948e-01 -2.87233702e-01  1.69647942e-01 -1.16401512e-01
  4.38055717e-01 -7.16635161e-02 -6.43071788e-03 -1.10274481e-01
 -3.93066753e-01 -1.41022189e-01  1.30839528e-01  5.57140422e-02
 -1.64521089e-01  1.10035001e-01  5.12546446e-02 -1.39722234e-01
 -2.13275200e-02 -1.26132956e-01 -1.26789441e-01 -1.18430014e-01
  1.56301728e-01  1.02285850e-01  1.39553826e-01  3.54468431e-01
 -1.67700978e-01  3.78890170e-01 -4.75692280e-02  3.22788288e-02
 -5.12110257e-01 -1.95639323e-01 -8.93203436e-02  5.47518600e-02
 -1.22556164e-01  3.10798454e-01 -1.96051759e-02  1.12891093e-01
 -5.59366464e-02  3.16598384e-01  1.23076128e-01 -2.01114680e-02
  2.19071072e-02 -3.76908774e-02 -9.34698753e-02 -8.36808903e-02
  1.89028975e-01 -5.49276261e-02  1.69114752e-01  2.37454614e-01
  6.22253852e-03  7.95253708e-02 -1.35423077e-01 -1.65697191e-01
  2.36140247e-01 -4.15428898e-01  6.23553526e-02  8.87908734e-02
 -3.04531368e-03 -4.33182442e-02 -1.16666988e-01 -1.10358066e-02
 -2.64980768e-02 -2.33720758e-01  2.69910811e-01  2.46045806e-02
 -7.56801284e-02  1.07191577e-01  1.76212793e-01 -1.19117974e-01
 -1.92199548e-01  2.62825931e-01  1.13244246e-01 -3.37404902e-01
 -2.15067079e-01  1.50293135e-01  1.50593271e-01 -2.50427984e-01
  3.58298428e-02  3.62400164e-01  1.26491351e-01 -4.77775081e-01
  2.63981159e-01 -2.65059400e-01 -1.20618880e-01 -5.61102027e-02
  6.43448153e-02 -2.90209393e-02 -3.39726941e-01  7.87487995e-02
  8.26358501e-03 -3.03745725e-01  7.96538552e-02 -1.97725756e-01
  2.71679249e-01 -1.62013365e-01  2.00187960e-01 -9.89381191e-04
  1.35311466e-01  5.11272279e-01  1.80080122e-01 -2.69560810e-02
 -2.98155389e-01  7.58567250e-02  1.34457958e-03  3.26011824e-01
  4.40108762e-01  1.69289648e-01  5.99193277e-02 -1.85984878e-01
 -4.25636678e-02  2.75656982e-01 -3.77413977e-01  5.08842404e-01
  4.99037684e-02 -1.63945854e-01  1.61727273e-01  1.67566000e-01
  4.70474643e-01  2.81563272e-02 -1.32168781e-01  2.36886460e-01
 -1.50856009e-01  1.21979733e-01  6.66449163e-02  2.23772102e-01
  9.51165332e-02 -2.11071566e-01  2.64286385e-01  6.59030515e-02
 -1.22124756e-01  2.70241379e-01 -2.08565495e-01 -5.64163883e-01
  5.59104786e-01 -1.34919433e-01  2.23728740e-01 -1.05718101e-01
  2.18202989e-01  2.46963862e-01 -1.57724811e-01 -2.96086465e-02
 -1.82668559e-01 -3.79596902e-01  5.92184386e-01  6.44026172e-02
  1.03947134e-01 -7.17162302e-02  1.22592165e-01 -3.18504754e-01
  5.11703441e-02  1.23239305e-01  7.15563067e-02  1.35036280e-01
 -5.28349495e-04 -1.75695507e-01 -1.15780561e-01  1.85017101e-01
 -2.35582314e-01  1.44047472e-01 -1.14429209e-01 -7.76351127e-02]
it does something
Int64Index([ 762,  763,  764,  765,  766,  767,  768,  769,  770,  771,
            ...
            1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259],
           dtype='int64', length=498)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1849)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[ 1.83894527 -0.53669104 -4.22685582  1.66323689 -0.3678426  -0.54368378
  1.1511579  -1.8893189   0.59996897  0.34348484 -0.05428672  0.26964094
 -1.0953753   0.97401655 -1.80952354 -1.62177641 -2.23197551  2.15717463
  0.58514437 -0.26064644  0.12283533  1.42223196  0.17026266 -2.31207648
 -1.45437598  1.50358446 -1.08981837  0.16520877 -2.01895042  0.19935275
  1.55991457  0.19336755 -0.94953122 -0.63116391 -0.53462614 -0.00664334
  0.25640609 -0.01987837  0.55686611  1.71457623  1.27649356 -1.36837392
 -1.04644693  1.27548363 -2.32387066 -0.33408693  0.59617069  0.55435336
 -0.14704875 -0.58078402  0.2756048   0.4044902   0.12188371 -0.70812523
  0.2445728   0.11449806  0.67921351 -0.38885751 -0.55455764 -0.36391915
 -1.23540346  0.89611369  0.44439894  1.36704765 -0.00716984  0.10790053
 -1.06782587 -0.59062629  0.49796249 -0.49514945 -0.16407702  0.70976929
  0.74502937 -0.26054443  0.43720736  0.82428547  0.6338847  -1.45589823
 -0.10807024  0.15296044 -0.39203936  0.68472842 -0.78085399  0.60416489
 -1.06687516  0.34525884 -0.43910839  0.10559281 -0.46431659 -0.42607287
  0.47078742 -0.19135303  0.19587853 -0.22606093 -0.35476208  1.38712216
 -0.64536071 -0.45564636  0.83109128 -0.20650348  0.17732348 -0.18694259
  0.61875618 -0.15497214  0.45373237  0.50643213 -1.26064261  0.04146174
 -0.07455815 -0.26780008 -0.07097722 -0.52880499  0.02573003  1.39243949
 -0.60088587  0.84656956  0.06030889 -0.94885633 -0.81855983 -0.04424137
 -0.58387297  0.33491475 -0.40550116 -0.24972269  0.24976011 -1.02192647
  0.06939035 -0.29113295  1.15564811  0.37436103  0.08758747  0.87292523
 -0.93658537  0.38655634  0.60942397  0.21873321 -0.67978541  0.04773208
 -1.01034388  0.11078274  0.35983278  0.95444757  0.04665454  0.998084
 -0.50298815 -0.19630822  0.03253771 -0.38598647  0.43709425 -0.35708825
 -0.03817196  0.03585598 -0.0064129  -0.94161834 -0.32295243 -0.11663864
  0.30194757 -0.13064808 -0.69884818 -0.56107208 -0.41375253  0.75283168
  0.25976046  0.09351998  0.32661327 -0.30043615 -0.08196094 -0.29865663
 -0.02452064  0.11230174  0.0792924  -1.14278757 -0.2653558  -1.07869282
  0.74677419  0.41386314  1.05977964  0.47337974 -0.28218089  0.22685803
  0.81401221 -0.19891     0.24544748  0.19256148  0.40123267 -0.16529462
 -0.19189378 -0.21271788 -0.11208371 -0.48969673 -0.39009531 -0.49375664
 -0.08264012 -0.08198474 -0.75723519 -0.52466238  0.5285349   0.00905611
  0.00854133 -0.51606748]
it does something
Int64Index([302, 303, 304, 305, 306, 307, 308, 309, 310, 311,
            ...
            398, 399, 400, 401, 402, 403, 404, 405, 406, 407],
           dtype='int64', length=106)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2241)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[ 3.37279819e+01  1.54469883e+01 -6.39439777e-02  5.61944109e+00
  2.23616155e+01  1.24883452e+01 -1.98253567e+01 -1.09510470e+01
  2.19835434e+00  2.66696757e-01 -1.54918967e+00 -8.03428830e+00
 -6.49407599e-01  1.01155915e+01  6.35570824e-01  6.52101271e+00
  3.18926561e+00  6.94592871e+00 -9.26428549e+00 -1.03857874e+01
  5.49670354e+00 -1.02928409e+01 -7.63854406e+00  1.26854090e+01
  1.88239443e-01  6.90441088e+00 -4.68985682e+00 -3.23553328e+00
  3.81372986e-01 -1.59781838e+00  4.87469137e+00 -6.60930445e+00
 -8.16142440e+00  1.93218776e+00 -9.45099078e-03 -7.54243364e+00
  2.26390945e+00 -9.46129593e+00 -1.07232933e+00  5.88533602e+00
 -6.27065793e+00 -4.40341059e+00  3.84609511e+00 -6.08525934e+00
  2.62218142e-01 -1.84982220e+00  2.18284160e+00  7.73850672e-01
 -1.04833583e+00  6.57602193e+00  4.60979699e+00  1.03699831e+00
  2.72459311e+00  1.42472534e+00  3.53479517e+00  6.26076907e-01
 -1.01481785e+00 -2.87043428e+00 -1.84974578e+00 -3.52285001e+00
  6.19120297e-01  9.29933014e-01  1.56490163e+00  2.30887892e+00
  5.95008360e+00 -1.96637759e+00 -2.10644413e+00 -7.50564047e-01
  3.24813637e-01  1.99537828e+00  8.51151244e-02 -9.57229565e-01
  2.53200274e+00  5.91203891e+00 -4.41834407e+00  3.34897210e+00
 -2.10664630e-01  1.09092542e-01 -4.47575474e-01 -1.68070807e+00
  6.43523199e-02 -2.17644161e+00 -2.08581116e+00 -2.97986670e+00
  2.40326222e+00  3.81813844e+00 -5.17022450e+00 -1.42257425e+00
 -1.27812415e+00  1.21262929e+00  2.02108545e-01 -7.05984842e+00
  6.50872963e+00 -4.75459357e+00 -1.39445244e-01 -2.85985955e+00
  2.60033950e+00 -8.40492511e-01 -3.77362301e+00 -1.65638534e+00
  3.54372862e-01 -1.42587860e+00  5.68922908e+00 -1.78665857e+00
  1.52189991e+00  5.27333025e+00 -3.94533495e-01 -1.61296594e-01
  1.14647920e+00  2.91077577e+00  1.83226588e+00 -3.00550196e+00
 -2.75846018e+00  2.68332540e+00  2.84040601e+00 -2.03196397e+00
  2.10965214e+00  4.48103917e+00  9.67818953e-01 -3.43398973e+00
  1.35647469e-01  5.90082706e-01 -8.17167224e-02 -2.28935582e+00
 -5.97368728e-01  3.19438726e-02 -1.30897322e+00  1.67328541e+00
 -2.49062681e+00 -2.95515319e+00 -1.66014154e+00  7.72565986e-01
  2.98411669e+00 -5.38221914e-01  9.96808231e-01  2.58735142e-01
 -8.99219297e-01  1.62327667e+00 -1.02619005e+00  2.08704725e+00
  2.34552102e+00  1.05762815e+00  1.27019531e-01  1.22233170e+00
 -7.89980312e-01 -7.05633616e-01 -1.14663570e+00  1.08343446e+00
 -1.19470247e+00  1.98467903e-02 -1.23148467e+00 -2.79463931e+00
 -2.15132554e-01  7.31036539e-01  7.66190958e-01  1.34828584e+00
 -3.49104206e+00 -2.74375491e+00  1.71486356e+00 -1.32954368e+00
  1.01494757e+00 -1.42787414e+00 -9.95069567e-01  1.15202686e+00
 -2.24448883e+00 -8.76460695e-01 -4.71663205e-01 -1.59767774e+00
  4.50678568e-01  1.33193002e+00  1.38413475e+00  1.56858097e+00
  4.19764271e-01 -1.26763943e+00 -8.13932996e-01  6.22343902e-01
  1.64213999e+00 -1.23353487e+00  1.39195917e+00  1.06822181e+00
 -3.76834594e-01 -1.20217297e-01 -2.01492063e+00  3.36950579e-01
  2.75187375e-01  1.49756439e+00  1.53609743e+00  6.32217645e-01
  1.27844572e+00 -4.61661999e-01  1.15517837e-01 -5.66100414e-01
 -1.32864518e+00 -4.47668720e-01  2.15777742e+00 -4.22018297e-01
 -1.12273983e+00  8.38309184e-01 -4.00938161e-01 -8.26840787e-02]
it does something
Int64Index([431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443,
            444, 445, 446, 447, 448, 449, 450, 451, 452, 453],
           dtype='int64')
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2324)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-9.27678485e+00  2.08874446e+00 -2.41448211e-01  7.32879888e-01
 -3.94073830e-01 -7.57133616e-01  9.97519476e-01  1.63233892e+00
 -6.13660687e-01  4.36626065e-01  1.02986666e-01  4.87477439e-01
 -5.01281851e-01  7.61375170e-01  6.18958467e-01 -8.52411791e-01
  4.06368808e-02 -3.62786350e-01 -2.58502416e-01  1.64876957e-01
 -6.08497803e-01  3.72561136e-01 -4.67190276e-01  2.83694306e-01
 -4.16401405e-01  1.33095697e-02 -1.72428164e-01 -6.57771449e-01
 -2.00303373e-01  9.03745707e-01 -1.23244926e-01 -1.27420899e-02
 -8.70245422e-01 -2.75492719e-01  1.67846701e-01  7.07726635e-02
  3.89761634e-01  2.55584979e-01  4.39281399e-02  1.20230461e-01
 -4.50998905e-01 -4.68706078e-02 -1.24393305e-01 -4.42127315e-01
  3.14285852e-01  6.24252903e-01 -4.19162230e-02  4.30013360e-01
 -3.25393340e-01 -3.11834103e-01  2.25607036e-02 -3.42292799e-02
  2.20252294e-01  1.71772112e-01  1.20505186e-01 -1.92063258e-01
  1.44548135e-01  6.95963075e-01  1.40246420e-01  1.48104184e-01
  4.93871388e-01  3.35458468e-01  3.04777292e-03  1.80045644e-01
 -3.61801018e-01  6.63902086e-01 -2.62028886e-01 -6.29053611e-02
  1.58914594e-01 -5.17169151e-02  6.90179776e-01 -9.72470573e-02
 -1.64881873e-01 -2.36084980e-01 -1.35659412e-02  3.39237651e-01
 -2.26780205e-01 -3.53934991e-01  7.63233190e-02  6.45536841e-02
 -3.82331836e-01  4.83045802e-01 -2.29033838e-01  3.82129970e-01
 -1.55321836e-01 -2.51982426e-01  3.98870321e-01 -6.32272548e-02
  9.83383440e-02  1.55368685e-01  2.76808901e-02  1.18108489e-02
  7.23121946e-02 -9.00015021e-02  2.88132611e-01  1.76936626e-01
  1.02705491e-02 -2.65469551e-01 -2.56417050e-01 -2.72358921e-01
  3.61815847e-01  2.50700669e-01 -1.12215534e-01 -6.12638022e-03
  6.13176100e-02  1.21639392e-01  3.90199103e-01 -3.04119465e-01
 -1.69234671e-01  2.73117676e-01  3.07257055e-01  4.30103037e-02
 -3.91002553e-02 -2.03163789e-01  9.61683940e-02 -1.71622749e-01
  3.16306946e-01  2.52173307e-02 -8.36041527e-02  5.66811386e-02
 -9.75175066e-02  1.11023447e-01  2.36762741e-01  1.22508634e-01
 -2.29799060e-01  2.41088447e-01  5.57116174e-02  3.61420892e-01
 -1.05290651e-01 -1.18728220e-01 -1.32087796e-02  4.40868466e-03
  3.86178733e-01 -1.56323053e-01  2.30203897e-01  4.01968052e-01
  2.44725662e-01 -2.83562906e-01  1.01880258e-01  1.89722849e-01
 -2.00942288e-01  1.52481677e-01 -2.05881442e-02 -2.33986792e-01
  1.01207845e-01  1.38619444e-02 -3.63183941e-01 -1.67646183e-01
 -1.27754250e-01 -7.64764945e-03  4.47369750e-02  1.45608082e-02
  1.60933017e-01  1.89663858e-01  1.76076998e-01  1.35068204e-01
  1.10999268e-01  4.12696956e-02 -6.16445362e-02 -1.70405219e-01
  4.72085577e-01  4.90817020e-02  2.44218571e-01 -2.39388567e-01
  1.04293104e-01 -7.86028607e-02 -2.12810642e-01 -1.60547801e-01
  2.44862351e-02 -1.69409812e-01  1.67854400e-01 -2.69808874e-01
  1.99249055e-01 -1.67418477e-01  4.96388654e-02 -2.24352290e-02
  1.58794495e-01  1.31644266e-01  1.23912620e-01  1.74917917e-01
 -4.61032653e-01 -3.33071292e-01  1.40065510e-01 -2.03461636e-02
  2.41871060e-01 -5.57502005e-02  3.63031874e-01 -2.14471006e-01
 -1.16184476e-01  2.15459411e-02 -5.44665264e-02 -2.22682574e-01
  4.89950047e-02 -1.88203396e-01  9.80883817e-02  1.96775853e-02
 -2.89582598e-01 -5.18328366e-02  7.80865584e-02  1.78598933e-01]
it does something
Int64Index([ 762,  763,  764,  765,  766,  767,  768,  769,  770,  771,
            ...
            1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259],
           dtype='int64', length=498)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1849)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-1.00406031e+01  2.87446184e+00  1.64728762e+00  6.30450667e-01
  1.32241152e+00 -4.07419865e-01  3.34348583e-01  3.84922389e-01
 -5.71205224e-01  1.25557458e-01 -8.21685721e-01  3.82437442e-01
 -6.03433003e-01 -3.26760815e-01 -5.42163252e-02  2.25893115e-02
  5.21967205e-01  1.02221903e+00 -5.05383578e-02 -1.05629779e-01
 -5.38366474e-02  4.66377270e-01 -5.78440794e-01 -4.17246590e-01
 -1.21291187e-01 -6.49987286e-02 -3.40324354e-01  3.83449800e-01
 -3.34860000e-01  4.88148316e-01  2.12328848e-01  2.48159494e-01
 -3.71887950e-01 -4.20716606e-01 -5.31764883e-01  3.25400504e-01
  2.04781238e-01  3.52825258e-01 -7.63867710e-02 -1.05493875e-02
  1.98549150e-01 -1.71374708e-01  5.16739741e-01 -1.14240862e-01
 -3.40121232e-01  3.08252410e-01  4.29023367e-01  1.02973598e-01
  3.90520055e-01  5.12652083e-01 -5.62214980e-01 -1.19027951e-01
  2.45175603e-01 -2.73007100e-01 -2.59893649e-01  4.90473396e-01
 -5.85514762e-01  5.73546483e-01  5.25373499e-01 -2.54155178e-01
  3.01304215e-02 -3.53524169e-01 -6.72040401e-01 -1.47333791e-01
 -2.09381182e-01  7.30905187e-02  1.65102457e-01  3.72310492e-01
 -1.78484808e-01  3.29458844e-01 -1.61131793e-01 -4.37185469e-02
 -1.48419808e-01  5.30398053e-02 -5.67575736e-02 -3.05566845e-02
 -3.98228967e-01 -2.11196357e-01  9.07899439e-04  9.77260691e-02
  1.15417423e-01  7.52236237e-02  4.45661602e-02  1.20813006e-01
  3.21802483e-01  3.55686058e-02 -7.24846288e-02 -3.36843772e-01
 -3.28602623e-02 -1.57468717e-02 -5.62446772e-02  2.58644616e-01
  2.53470931e-02 -1.79602060e-01  9.65816103e-02 -3.28589859e-01
 -1.51080781e-02 -1.85095231e-02 -6.79819948e-02 -1.17758959e-01
  1.24239350e-02  2.02517679e-03  1.17175002e-02 -1.89775429e-01
 -2.94766065e-01 -3.37784828e-01  1.57468682e-01 -3.21623775e-01
 -2.16960714e-01 -2.04541542e-02  2.11907929e-01 -1.40123391e-01
  1.84890698e-01 -3.86699614e-02  2.33714601e-01  2.37491952e-01
 -3.38373747e-02  8.59093688e-02 -1.01786752e-01 -1.76850225e-01
  1.13066886e-01 -6.65451600e-02 -4.96684065e-01 -1.28002413e-02
 -3.01625398e-01  2.94322562e-01 -1.40442999e-01 -1.67186282e-01
 -3.12661954e-01  3.21830243e-02 -3.18763224e-01  2.69841082e-01
  1.58663998e-01 -1.11090730e-01 -5.86060421e-02  4.42148234e-01
  2.07337218e-01  7.44461760e-02 -3.60868319e-01 -2.90778175e-01
  5.52415837e-02 -3.08488869e-01  1.63348813e-01 -3.59115256e-02
 -2.43549052e-01  4.73274269e-02  3.93635411e-01 -1.69276830e-02
 -2.89997107e-01  4.91526846e-02  3.51171502e-01  1.90782503e-01
 -4.88406406e-02  1.48547524e-01 -5.58022311e-02 -5.96641153e-02
  1.54514560e-01  1.38649515e-01 -3.68550028e-01 -2.88146896e-01
 -2.60246598e-02 -3.54812654e-03 -7.92071981e-02  1.03253517e-01
 -7.44474433e-02  2.54706908e-01  3.14913498e-01  3.45327635e-02
  4.17773777e-02  1.51266366e-02 -1.34087297e-01  1.01044885e-02
 -1.65855036e-02 -3.04202324e-02 -3.60218612e-01 -1.39389455e-01
  3.54049690e-02 -4.59297508e-02 -4.31993720e-01 -6.76787347e-03
 -5.30633807e-01  1.48502882e-01 -2.82743823e-01  2.71442132e-01
  2.63030428e-02  8.31342463e-02  2.05399929e-01  2.77251840e-02
 -1.65668007e-02  2.42344933e-01  1.72963832e-01  1.88390304e-01
  4.00933635e-02  3.20712470e-01  4.01095084e-01 -1.58212477e-01
  1.50723555e-02  3.59749538e-01 -2.29187526e-01  3.13304566e-01]
it does something
Int64Index([302, 303, 304, 305, 306, 307, 308, 309, 310, 311,
            ...
            398, 399, 400, 401, 402, 403, 404, 405, 406, 407],
           dtype='int64', length=106)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2241)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-9.77871470e+00  3.99590264e+00  1.85474609e+00  9.40762493e-01
  1.78677601e+00  5.06073184e-01 -1.76210645e-01  8.88501716e-01
 -1.84218909e-01  5.57521254e-02 -1.17784692e+00  4.77628649e-02
  2.93221391e-01 -3.81977707e-02  2.59014616e-01  4.81618310e-01
 -3.90671186e-01 -8.27318626e-02  2.70991727e-01  4.35167077e-01
  6.41253301e-02 -7.51987032e-01 -2.15297961e-01 -3.12434240e-01
  1.24333926e-01  7.88974157e-01 -1.55272355e-01 -4.31881360e-01
 -4.27274866e-01  2.15450744e-01 -1.07924600e-01  3.37450954e-01
 -2.33599847e-01  1.83260891e-01 -7.30032410e-02  1.78530439e-01
  6.63557159e-02  7.22984865e-01  2.76128847e-01 -2.16700933e-01
 -2.87060480e-01 -1.16446186e-01  2.80732640e-01 -2.58203903e-01
  6.59871729e-01  3.09255739e-01 -5.06728428e-01 -1.75350066e-01
 -1.61004291e-01  6.71251258e-01  1.22261095e-01  2.23404004e-01
 -5.50270403e-03  3.62535485e-03 -1.66011340e-01 -8.49109398e-01
 -3.04411697e-01  3.90145458e-01 -7.70754758e-01 -1.07372637e+00
 -9.29067141e-02 -5.95392029e-01  3.91557644e-01  1.70287791e-01
  3.85787893e-01 -1.31578939e-01  4.63564951e-01 -4.50062422e-01
 -5.97502386e-01  8.87855553e-01 -7.54356794e-02 -4.33904366e-02
 -3.54033072e-02 -1.78199262e-01 -3.28258449e-01  2.09106584e-01
  2.22252811e-01 -3.63462587e-01  5.25735634e-01 -5.43558156e-01
 -2.46186143e-01 -1.87660017e-01 -3.39847579e-01 -1.68263238e-01
 -1.69058053e-01 -1.61210398e-01  9.11845551e-02  2.46168815e-01
 -3.81536341e-01 -1.87242974e-01  1.06915048e-01 -4.97753952e-01
 -2.06960987e-01  3.06672786e-01 -5.91378428e-01  1.65244715e-01
  3.57009517e-02 -2.79322463e-01  2.72775262e-01  4.74230964e-03
  1.79833878e-01 -2.37885328e-01 -3.07435719e-02 -2.24436103e-01
 -8.28513810e-02 -6.26034586e-02  1.03143444e-01 -1.37234743e-01
 -3.57538418e-02  5.08070208e-02 -1.38249518e-01  3.57305076e-01
  2.58617849e-01 -9.46999606e-02 -3.41151633e-03  5.80210099e-01
  2.76829418e-02 -4.45540979e-01 -2.32861529e-01  4.72470175e-02
  1.86799807e-01  2.55824371e-01  2.32711153e-02  5.71673128e-01
  6.85492306e-02  6.97690471e-02  8.50911869e-02 -3.15002128e-01
 -9.60140082e-02  4.32623465e-01  2.68273371e-01 -3.41004734e-01
 -6.34367074e-03 -3.49084488e-02 -2.13480979e-01  4.08216891e-02
  3.16626765e-02  6.65373986e-03  9.82922706e-02 -1.49344913e-01
 -4.88792983e-02  2.61918638e-01  1.32270843e-01 -2.10484814e-01
 -8.96627970e-02 -4.61517326e-02 -2.02834331e-01  5.03080620e-02
 -6.36692619e-02  1.56546526e-01 -6.43117518e-02  8.77766748e-02
  1.04703134e-01  2.24056513e-01 -1.74723343e-02  9.54605417e-02
  2.84850212e-01  1.13896781e-01  1.16913023e-02  1.10552122e-01
 -2.11377435e-01  5.96245295e-02  1.58914640e-02  2.38364889e-02
 -1.54552617e-01  1.48495817e-01 -9.02966976e-02 -1.91850281e-01
 -1.88260129e-02 -7.40334458e-02 -1.50854763e-02  1.55209205e-01
 -2.77995733e-01 -4.44756120e-03 -4.50589359e-03  1.17565573e-01
 -1.16026545e-01 -2.20015956e-01  1.19162347e-01 -1.83059596e-01
  8.34435400e-02 -1.32905963e-01 -1.13657310e-01  2.27837375e-01
 -1.32987383e-02 -2.34943230e-02  9.90052361e-02  2.93135230e-02
 -2.83182609e-01 -2.65750796e-01  2.92082064e-01  8.76000442e-02
  1.05868458e-01  6.94613857e-02  1.81515280e-02  1.64713085e-01
 -1.74655113e-01 -7.53585443e-03 -4.71838472e-02 -2.33036339e-01]
it does something
Int64Index([ 762,  763,  764,  765,  766,  767,  768,  769,  770,  771,
            ...
            1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259],
           dtype='int64', length=498)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1849)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[ 1.72282660e+01  7.31885864e+00 -1.51633843e+00 -1.62769522e+00
 -1.11568859e-01  2.55200810e+00 -1.03889987e+01 -1.70825313e+00
 -3.58679654e+00 -2.37841295e+00  1.03179634e+01 -5.65757693e-01
  1.61985031e-01 -1.71971371e+00  4.16071080e+00 -5.72856668e+00
  7.44032020e-01  3.36561186e+00 -7.02346523e-01  2.49941660e+00
 -1.39673433e-01  2.45320435e+00 -3.51445318e+00  2.24484311e+00
 -2.14594097e+00  2.43089174e+00 -4.84174911e-01  2.28875949e+00
 -1.71958635e+00  2.59698555e+00  1.13012340e+00 -3.13038123e+00
 -4.42602425e+00  6.78971128e-01 -2.97649985e+00  2.14269666e+00
  8.28945700e-01  1.87335973e+00  2.49093540e-02 -2.52952046e-01
  2.07756606e+00  3.43048159e+00  4.88922907e+00  9.92854288e-01
 -8.37912992e-01  3.00449410e+00  3.56220126e-02  8.83990221e-02
  3.74529288e-01  2.21235180e-01  1.59838955e+00 -2.93649639e+00
 -2.09130054e+00 -9.24919338e-01 -7.06781529e+00  1.42505402e-01
 -4.06443899e+00 -3.12393940e+00  9.02306025e-01  1.18365350e+00
  1.38775577e+00 -4.17525389e+00 -1.40618678e+00 -3.55778510e+00
 -2.70089599e-01  2.25206145e+00 -2.34727841e+00  3.37904052e+00
  2.15137501e+00  4.28510712e-01  1.07247438e+00  3.41143735e+00
 -4.55648894e-01  8.35923284e-01  5.90427323e-02 -5.62358840e-01
 -5.84764353e-02 -2.62176369e+00  8.04773755e-01 -7.04824722e-01
 -3.75155858e-01  5.66941199e-01  3.06039961e-01 -6.44882152e-01
  5.06145803e-01 -1.29009131e+00 -1.35800812e+00 -2.33030028e+00
 -2.59938247e+00  6.60934240e-02 -2.03812404e-01 -8.16590767e-01
 -5.84446395e-01  1.55118608e-01  1.13276977e-01 -1.23004023e+00
 -2.03235405e-01  9.30497709e-01  1.13943848e+00 -6.54705276e-01
 -3.14025545e-01  2.73164737e-01  5.13711794e-02  6.13362585e-01
 -7.04283528e-01 -9.22039710e-01  9.97012266e-02 -1.26129748e+00
 -1.11905624e+00  4.81760463e-01  4.41468802e-01 -4.76824832e-01
  6.97756839e-01  9.81184637e-01 -1.57803772e-01  4.15309905e-01
  3.29892710e-01  4.68399538e-01  1.76173042e-02  3.84603810e-02
 -1.67311883e-01 -8.48287232e-02  6.23332637e-02  1.68371892e-01
  6.13293172e-01 -5.23133312e-01 -2.74092446e-01  4.77032265e-01
 -4.89837677e-01  6.28521872e-01 -8.69175819e-01  2.80579774e-01
 -4.60686250e-02  8.57562873e-03 -3.29543448e-01  3.72091547e-01
 -3.67915325e-01  3.78645300e-01  6.18179141e-02  1.05738258e-01
 -4.08751158e-02  4.25960562e-01  4.00002431e-02  5.98622016e-01
 -4.75174592e-02 -8.48157815e-02 -3.14357332e-01 -6.64397863e-02
  5.24104730e-01 -3.18702527e-01 -3.61955377e-01 -1.43218706e-01
 -3.96909814e-01  1.86885258e-01  4.40480073e-02 -3.43044383e-01
 -3.95476416e-01 -2.17452400e-01  2.51467758e-01  4.29605604e-02
  2.42146470e-01  2.84664846e-01 -1.32065357e-01  2.29599600e-01
 -1.00263011e-01  1.74987023e-01  5.92537520e-02  2.49995123e-01
  3.16086857e-01 -2.60146587e-01 -5.30880730e-01 -2.85729855e-01
 -1.03331505e-01  1.78701530e-01  5.15701056e-03 -9.53197915e-03
  1.86388782e-01  3.06352744e-02 -2.47498318e-01  3.08329909e-02
  9.24170784e-03 -1.52656374e-01  1.04031365e-01  4.92957256e-02
  2.10747115e-02 -6.26527355e-03  1.35173605e-01 -1.92425461e-01
 -2.90965185e-01  1.40174610e-01 -6.65801335e-02  3.89286655e-03
 -2.02452933e-01 -1.08520277e-01 -2.32814065e-01  2.14375375e-01
 -1.52001964e-01 -6.06502407e-02  2.84061375e-01 -2.73349558e-01]
it does something
Int64Index([1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311,
            ...
            1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706],
           dtype='int64', length=405)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1942)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-7.11677651e+00  3.03466660e+00  8.34290199e-01  1.27574526e+00
  1.55206704e+00  1.27074508e-01  7.90757681e-01  1.10011702e+00
 -4.39146854e-01  5.61957042e-01 -4.93489509e-01 -5.21025888e-01
 -3.50899393e-01  4.24060257e-01 -1.48033886e-01 -3.81800583e-01
 -6.89194320e-01  3.37423457e-01  2.10012409e-01  4.07751812e-01
 -1.01641332e+00 -4.88457555e-01 -1.17326593e-01 -2.70614836e-01
 -7.47864899e-01 -5.05070702e-01  3.09814307e-01  6.79126477e-01
  2.02416004e-01  1.23827789e-01 -2.69960372e-01  5.17152553e-01
 -5.11299611e-01 -2.43788047e-01  5.56391399e-01 -2.81832018e-02
 -6.43780679e-01 -5.91014229e-01  1.06424446e-01  8.36237733e-01
 -3.81035208e-01  1.93821678e-01  1.47931754e-01  1.40407010e-01
 -3.92862288e-01  2.61911395e-01 -3.48306794e-01  3.43053110e-01
  7.35826380e-02 -3.10944064e-01  1.34327895e-01 -3.90219825e-01
 -6.57716374e-01 -4.36948013e-01 -1.18644103e-01  5.06444760e-01
  3.44836787e-01 -2.02868458e-01  5.02832418e-01 -2.73017853e-01
  1.78769982e-01 -3.91830561e-02  2.07527437e-01 -4.34219155e-01
  4.14370280e-02  7.76813209e-02 -4.68501419e-01  5.97624871e-02
  1.54363436e-01 -6.53865554e-02  3.57248880e-01 -4.25496979e-01
 -2.11124127e-01  4.43758823e-01 -1.12859790e-01  7.20017910e-02
  6.04181608e-01 -6.38806378e-02  8.45990241e-02 -1.74351146e-01
 -3.13460359e-01 -3.97200021e-02 -2.47589935e-01 -1.96513640e-02
 -1.55389781e-01  1.73710904e-01  3.42600800e-01  9.99281864e-02
  2.25784364e-02  3.83057785e-01 -4.40291834e-01 -2.42752013e-01
  1.41720750e-01  1.17570203e-02  4.57718279e-02 -2.29769501e-01
  2.92531292e-01  1.64228805e-01 -1.10164654e-02 -4.26241464e-01
  1.17406278e-01 -2.16851267e-01  3.04632331e-03 -1.09896609e-01
  1.24324905e-01 -2.63217534e-01 -2.52878487e-01  4.71970651e-01
  4.46419334e-02  3.58396306e-01 -2.79528146e-01  7.31833470e-02
 -2.06543725e-01 -9.83152950e-02 -1.63066757e-01 -5.76393650e-01
  4.17289354e-01 -3.89766394e-01 -3.76754895e-01  4.21310468e-02
  4.11104615e-01  2.00538959e-01 -2.16530853e-01 -3.43288316e-01
 -7.79658625e-02  9.05615404e-02  2.21879150e-01  9.78872383e-02
 -3.15290730e-01  6.23185469e-02  3.22217584e-02 -1.78965261e-01
  4.73813302e-01 -6.96453945e-02  3.07924310e-01  4.57721374e-01
 -2.12331850e-01  4.54132743e-01 -2.33111546e-01 -7.79445532e-02
 -3.98390568e-01 -7.26296174e-02 -3.38750381e-01 -1.29425296e-01
  1.56580360e-01 -3.30224444e-01  2.69981328e-01  8.61902265e-02
 -1.47516868e-01 -1.05199275e-01  2.76422142e-01 -3.17561615e-01
 -1.20874170e-01  4.57746419e-01  2.65508011e-02 -9.04783628e-02
 -2.54876477e-01  2.68877031e-02 -5.18125634e-01 -4.12680552e-02
  4.54054299e-01  7.29558071e-02  2.82077267e-01  2.85490738e-01
  2.63899722e-01 -4.99255329e-02 -3.62787576e-01  2.07862765e-02
  6.81080182e-02 -3.76946766e-01  6.72972896e-02 -3.21509432e-01
  3.64933741e-01 -1.61611226e-01  2.76918807e-01  2.26946534e-01
 -3.52739557e-02 -2.12480950e-01  1.96399534e-01 -1.59661587e-01
 -1.79775528e-01  2.77307777e-01  2.93142805e-01  3.06065892e-01
  4.88596288e-02 -1.32622194e-01 -6.48366230e-02  1.69935192e-01
  8.39427945e-02 -2.73663982e-02  1.55074369e-02 -3.53574769e-01
 -1.61157737e-01  3.04991286e-01 -8.67545310e-02  2.75860259e-02
  1.23836495e-01  3.31387299e-01  2.27211960e-01  2.01785009e-01]
it does something
Int64Index([1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311,
            ...
            1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706],
           dtype='int64', length=405)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1942)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-8.77114230e+00  3.30662331e+00  1.67339203e+00 -4.08232987e-01
  1.23442267e+00  4.06665157e-01 -4.71484635e-01  1.55763938e-01
  1.23263030e-01 -6.18467239e-01 -9.10524551e-01  7.06449681e-02
 -1.13761807e-02 -1.46404527e-01  2.48288867e-01  9.09523508e-01
 -4.00551039e-01  4.69254021e-01  1.01823387e+00  1.14790457e+00
 -4.82194030e-01 -3.96874685e-01 -3.44950960e-01 -9.09547528e-01
 -1.18336288e+00 -1.90971552e-01 -5.07243660e-01  2.79450076e-01
  2.74595066e-01 -9.61080248e-01 -4.66857511e-01  3.24230883e-01
 -7.01768042e-01  3.01218505e-01  9.98413069e-01  5.88297554e-02
 -3.93906456e-01 -8.53477973e-01 -6.59784843e-01 -4.85011385e-02
  3.10084143e-01  7.74263275e-01  9.29091432e-01 -4.20212918e-02
  6.92939881e-01  2.26141568e-01  3.64526499e-01 -3.75029654e-01
 -1.14863462e-01  8.59594791e-01  1.17000885e-01  7.46047460e-01
  1.91008996e-03 -1.04396843e-01 -6.61763013e-02 -7.41102952e-03
  3.00102400e-01 -3.82422599e-01 -1.92617253e-02 -7.19188150e-02
  2.61909190e-01 -7.23384713e-02  1.28442283e-01 -1.21311443e-01
 -8.18694669e-01  5.11793552e-01  1.36471761e-01 -3.53609676e-02
 -3.20414493e-01 -8.37984140e-02 -4.43781402e-01 -3.04137420e-01
  8.54524023e-03 -2.16852086e-01 -3.95894120e-01 -3.76681663e-01
  6.05434424e-01  1.28293384e-02  2.08507494e-01  4.25024219e-01
  3.38120647e-02  2.59836880e-01 -2.51090665e-01  1.52409839e-01
  2.64887791e-01  4.90004977e-01 -4.75634095e-02 -2.34877917e-01
  9.57744861e-02  3.23634877e-01  6.62408178e-01  1.24400424e-01
 -1.33703463e-01  3.72894833e-01 -7.25211626e-01  2.99358662e-01
  1.60609295e-01  2.48774834e-01 -9.57296094e-02 -1.23955330e-01
 -3.10207064e-01  2.18478979e-01  8.19955286e-02 -1.56905853e-01
  1.56026018e-01 -2.82010532e-01 -6.67319118e-01 -4.98035620e-02
  3.45316756e-01 -3.93620018e-01 -8.25649398e-02 -3.62183795e-01
 -1.84080632e-01 -8.39000317e-02  7.70870808e-01  1.08581096e-02
  9.41594013e-02  8.32762022e-02 -2.88648239e-02 -3.05514575e-01
 -5.32311576e-01 -3.40192763e-01 -4.46007915e-01  7.93159118e-01
 -1.48399712e-01  3.05900958e-01  5.00628214e-01 -3.93163725e-01
  1.09431731e-01  3.25014996e-01  3.84631632e-01 -3.01706684e-01
  8.56391870e-01 -6.72034633e-02 -3.58053417e-01  8.67398777e-02
 -2.68758691e-02 -1.17708732e-01  2.19983501e-01  9.08322044e-02
 -7.04594998e-02 -7.59587253e-02 -1.64599321e-01  3.34310329e-01
  6.27660931e-02 -6.36114196e-01 -2.03518553e-01 -6.01008598e-02
 -4.29784027e-01  1.79418725e-01 -1.20173594e-01  4.80543404e-01
  4.06014677e-02  6.71301510e-02 -1.47035025e-01 -1.76456086e-02
  3.75739096e-01  9.97676396e-02 -1.62895200e-01 -1.18441578e-01
 -6.16428059e-02 -2.98270927e-01  2.40969554e-01  1.11563714e-01
  1.47281966e-01  1.66526978e-01 -6.68372969e-01  5.64622020e-01
 -2.10128943e-01 -4.70607798e-02 -9.31142290e-02 -6.05201201e-02
 -5.79904739e-02 -2.06153868e-01 -9.82379452e-02  2.67724379e-02
  4.75231109e-03  2.54253922e-01  2.03864372e-01  3.31535893e-01
  3.90733180e-01  2.01275336e-01  2.09175676e-01 -3.24660537e-02
 -8.38825541e-02 -1.09068225e-01  1.31353179e-01  2.01069496e-01
  1.60377863e-01  1.22277289e-01  3.98618058e-01  2.07955500e-01
 -4.16147254e-01  4.61162306e-01 -1.26037812e-01  2.91249654e-01
 -1.88203890e-01  5.07873604e-01  5.73733045e-02  4.42870056e-01]
it does something
Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,
            ...
            139, 140, 141, 142, 143, 144, 145, 146, 147, 148],
           dtype='int64', length=149)
Int64Index([ 149,  150,  151,  152,  153,  154,  155,  156,  157,  158,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2198)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-1.21650087e+01  3.17058915e+00  2.16998721e+00  5.43564533e-01
  4.62241505e-01 -3.70968246e-02  8.52462647e-01  1.05243659e+00
 -2.73831317e-01  2.05151046e-01 -1.35683473e-01  1.96222786e-01
  1.41418080e-02 -2.73856549e-01 -2.58688409e-01  1.49201648e-01
  6.34492969e-02  6.41091564e-01 -4.82729003e-02 -2.62720018e-01
 -4.51897088e-02  3.47915501e-02 -1.62364865e-01 -2.43236100e-01
  1.24242895e-01  1.76626457e-01  2.16794704e-01  1.43170264e-01
  1.61442050e-01 -1.31308029e-02  1.85220880e-01  6.69628631e-02
 -4.87675231e-02 -2.23511627e-01 -1.54539984e-01  3.38300601e-01
  1.84456805e-01 -1.38345975e-01 -2.99639872e-01 -6.99372429e-02
 -3.05802596e-01 -2.19459332e-01  1.93448330e-02 -2.46824112e-01
  3.52414079e-01 -5.82457405e-02 -1.25988538e-01  1.15971011e-01
  2.32878083e-02  2.60504816e-01 -1.63904800e-01 -9.92525711e-03
 -1.53938764e-01  2.90609920e-01 -3.16571692e-01 -1.57653982e-01
 -8.27536592e-02  9.00464630e-02 -7.67446903e-02 -6.36302403e-02
  2.28671345e-01  1.11348188e-01  7.00809583e-02  3.97228552e-02
 -6.33387828e-02  2.14184307e-01 -7.84417550e-02 -1.21247507e-01
  3.32348684e-01 -8.78409359e-02 -3.14925889e-01 -1.07672088e-01
  8.01467008e-02 -2.31373753e-02  9.47456165e-02 -1.53299599e-02
 -1.60492273e-02 -1.07752507e-02 -2.12836050e-01 -1.66849639e-01
  8.90841901e-02 -2.74968058e-02  3.87592483e-02  1.39578081e-01
 -1.01479859e-01 -9.35237129e-02  1.37629042e-01 -3.68543347e-01
 -7.65041774e-02 -1.14429999e-01  6.28541078e-02  2.34116603e-01
  4.19933483e-02 -1.38707174e-02 -1.96890609e-01 -1.06321571e-01
 -1.44094780e-01 -1.07709657e-01  8.09139553e-02 -1.10455555e-01
  2.49909926e-01 -1.78547182e-02 -7.85054288e-02  9.21988318e-02
 -4.63949061e-02  9.36794655e-02  1.16460346e-01 -1.15240555e-01
 -1.01175935e-01  6.47366860e-02  1.61553366e-01 -1.83982822e-01
  5.60364322e-02  3.14164634e-01  7.60821472e-03 -4.81230455e-02
 -3.78663110e-01  1.03189900e-03  2.52556234e-02 -1.80186787e-01
 -2.92139311e-03  1.97219948e-01  1.90456564e-02  1.09152205e-01
 -1.78046398e-01 -1.72462257e-01 -2.53493835e-01 -9.53505975e-02
 -9.78902189e-02 -1.22430336e-01  2.96970008e-02  9.04264840e-02
  1.01301557e-01 -9.27462783e-03 -2.02119644e-01 -2.10716885e-01
 -2.19700481e-01  7.42241804e-02 -1.16652220e-01 -4.89719183e-02
 -1.11279294e-01 -2.63336453e-02  1.74436080e-01 -1.15565295e-01
  8.93270535e-02 -1.50699200e-01 -6.09365171e-03  2.42064886e-01
 -7.02094493e-02 -1.67008902e-01  1.84643942e-02  1.58162782e-01
 -1.07623143e-01  5.44130258e-02  1.25024997e-01  2.98339576e-02
  8.57051339e-02 -1.51462238e-02  3.35046412e-02  1.34562278e-01
 -2.01778447e-01  2.27360825e-01  6.16600574e-02 -7.47463677e-02
 -9.82233517e-02  4.21647148e-02 -7.08181848e-02  1.01555115e-01
 -1.51596342e-01 -5.63487695e-02 -2.83512418e-02  3.32976132e-02
 -5.18497319e-02 -8.01129485e-02  1.50470767e-01 -7.23769819e-02
 -1.42507045e-01 -5.41623087e-02 -5.90245202e-02 -9.05350727e-02
 -1.49322493e-01  2.06002864e-01 -8.40450263e-02  1.54711777e-01
 -1.21763030e-01  8.35601643e-02  5.41496252e-02 -2.13954423e-01
 -7.26916965e-02  1.59632235e-01 -1.52486561e-01  7.72275087e-02
  8.49016202e-02  1.34611057e-01 -2.27879945e-01 -8.18137886e-02
  1.25079765e-01 -4.31312960e-02  1.59111572e-01 -1.08517284e-01]
it does something
Int64Index([2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331,
            2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342,
            2343, 2344, 2345, 2346],
           dtype='int64')
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320],
           dtype='int64', length=2321)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[ 63.22804514 -11.0262716  -20.80541679   4.0318645   -9.2066299
 -10.16940056  13.27937841 -10.29269318   6.28822632  -7.88004199
   4.4744295    2.47600801  -4.93772501   2.32155083   2.02572096
 -10.18500204   4.60323533   5.17325397  -0.48338499  -7.99301608
  -4.89400253  -1.20984523   3.44065213   3.02813856   5.13112149
  -6.00508569  -1.63431683   0.72215466   1.70112046  -4.22939941
  -3.21944502  -0.85884297   0.5887725   -0.6062709   -4.34845758
  -4.73700741   6.98866374   1.97691396   2.10770261   3.22262848
  -2.11152299   0.72740058  -1.62086102  -1.58720369   0.57640318
   4.01959862  -0.95389208   0.86108252  -5.24720152  -0.40315752
   1.77462732  -2.9889962   -3.74885281   3.49119711   3.6386391
   0.66685481  -2.85111247  -2.94387676   0.13756335   4.87539818
  -1.46600493  -6.90105065   1.93862672   0.61358021  -0.65114113
   2.19038981  -1.00034909  -0.29387742  -2.53738101  -0.97029102
   1.95531254   2.19766455   1.06431327  -0.74004686   2.04495499
  -1.21008144  -0.29473469  -2.51106936  -2.59147877  -0.40279341
  -0.71423534  -3.66104347   1.57100748   1.74996936  -4.46467831
   1.72100144  -1.73369269  -0.64745365   1.49176183   2.97895419
   1.26424957  -1.16687216  -0.14179805   0.83325507  -1.72256724
   1.931686    -4.3696827    0.28701108  -3.00036558  -0.34044914
   2.35581693  -0.77128692  -3.06832487  -1.32805901   2.71215564
  -0.31621477   0.50698014   1.11333059  -0.24578573  -0.58029008
  -1.03939085  -0.60672942  -0.96581803  -2.62759726   5.39305305
   1.89486203  -1.53146187  -2.95165542  -2.8611546   -1.16567551
   2.14138266  -1.75094603   1.86641188  -2.4150016   -1.16464276
   1.89513329  -2.80155906  -2.39405157   0.43754651  -1.94611435
   1.31685032  -1.04558955   0.12976066  -3.4053626   -1.5185442
   0.14593147   2.94518747   1.24780893   1.59973901   0.26722756
  -0.8459837   -3.0703152    0.45974403  -0.58756544  -1.54781601
  -0.75542002   0.91028955   1.62103368   0.29299276  -0.79612148
  -2.09332137   1.0092416    0.58201331   0.18495457  -1.71554281
   0.74739561  -1.82000939  -0.15971323   0.31210976  -1.03110098
   1.99801298  -0.33207041   2.81307185  -1.94292932  -0.9737868
   1.07947075  -0.10171826  -0.46674674  -1.93823034  -1.7460975
   1.3788486    3.73553677  -0.82353925  -0.60452068  -2.59698166
   1.04214528  -3.08804114   2.0976291    1.40080928   2.57480867
   0.64468751   0.06478288  -0.73442433   1.35183275  -2.67007231
   0.39158316   1.11013556  -1.84873011   1.83274011  -3.96446237
   1.35776078   1.96766518   0.21215871  -1.09835821  -0.81039709
   0.41337504  -0.07783978   2.12488701  -0.32333976  -0.77592793]
it does something
Int64Index([1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311,
            ...
            1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706],
           dtype='int64', length=405)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1942)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-1.19754829e+01  2.73801819e+00  2.11684642e+00  5.84280794e-01
  4.61020693e-01 -5.48207960e-01  9.61547331e-01  6.18180641e-01
 -1.40194434e-01 -1.22753186e-01 -5.20529976e-01  2.29343766e-01
  2.72742290e-02 -1.68538425e-02  1.03890569e-02  4.49402757e-02
 -2.66359016e-01 -3.10719425e-01 -2.98552137e-01  5.64372951e-01
 -1.20218707e-01 -5.12244402e-01 -4.08258787e-02 -2.11860029e-03
  2.65367543e-02 -6.43177791e-01  1.16890847e-02  3.45825993e-02
  1.42914006e-02 -1.58881402e-01 -1.63307715e-01  2.40384202e-01
 -4.39071824e-01  1.45231548e-01  4.72741624e-01 -1.22508053e-01
 -4.72878986e-01  1.56037065e-01  1.55546272e-01 -1.18693076e-01
 -2.96090834e-01 -2.66745243e-01  4.66709852e-01  3.78688714e-01
 -3.58873191e-02 -8.67479798e-02  1.76030041e-01  1.40448368e-01
  4.22551635e-02 -1.17519973e-01  2.66662934e-01  3.76395672e-01
 -2.76013174e-01 -7.01331109e-02 -4.54747303e-01 -1.69220713e-01
  4.91819579e-02  1.59370013e-01  3.54072060e-02 -1.09447133e-01
  2.13783733e-01  1.40383228e-01  3.35300586e-02 -2.58403380e-01
 -1.81947389e-01  1.83121862e-01 -2.98250319e-02 -3.68047495e-01
  3.28891256e-01  1.29692849e-01 -1.39214871e-01 -1.78660321e-01
  1.05472718e-01 -2.63413498e-01 -1.14536284e-01 -1.21165270e-01
  1.58887862e-01 -6.72402282e-02 -5.02975035e-02  2.76364683e-03
  1.56213967e-01 -9.64757599e-02 -2.96457617e-01  1.89649322e-03
  2.36699365e-01  1.08956941e-01  1.81636753e-02 -2.44446124e-01
  2.31299875e-01 -1.41354972e-01  8.60351209e-02 -2.43780942e-02
  1.49944601e-01  8.11998837e-02 -2.25417006e-01 -4.02885648e-02
 -2.93885436e-02  1.30890131e-01  3.62387913e-02 -1.07266516e-01
 -2.57306007e-02  1.38835434e-01 -1.71476086e-01  1.24624415e-01
  3.69119862e-02  7.09457086e-02 -8.44670895e-02  5.47028798e-02
  5.38245072e-02 -1.57613514e-03 -1.12286108e-01  2.37687478e-02
  5.31644872e-02 -6.34447061e-02  1.49367949e-01  1.84165997e-01
  1.69970663e-01  2.44110007e-02 -1.50664260e-01 -1.15583125e-04
  9.69458137e-02  1.68414390e-01  1.22465406e-01 -1.78923466e-01
  6.61460006e-03 -1.48850805e-01 -4.20298837e-02  2.75567180e-02
  1.35856324e-01 -1.84665014e-01  5.99534049e-03 -5.06842029e-02
  5.37013335e-02 -4.42921849e-02 -2.33022438e-02 -4.77888827e-02
  5.92355075e-02 -9.28470656e-02 -1.69131723e-01  7.94489595e-02
  3.34445862e-03 -1.45974453e-01 -1.13564615e-01  3.37319146e-02
 -4.03049774e-02 -9.00460224e-02  1.63859369e-01  1.24970651e-01
 -9.58452673e-02 -1.72280394e-01 -7.89894103e-02 -8.29372123e-02
 -3.12339357e-02 -1.34900299e-01 -2.20506496e-04 -4.39547309e-02
 -1.59149217e-01  1.44197593e-01 -1.07435075e-01  1.22108303e-02
  5.63836918e-03 -9.46704931e-02 -4.07804639e-02  6.30219204e-02
  1.43909601e-01 -2.07291571e-01  9.74394785e-02  1.14958104e-01
  8.65842355e-02  4.85784031e-04  6.00603322e-03 -1.62529596e-01
  1.73256162e-01  2.39458184e-01 -8.25067109e-02  7.64206423e-02
 -5.18802000e-02 -1.27768293e-01 -7.89249840e-02  1.08121897e-02
 -5.00331874e-02  4.52233028e-01  2.16327179e-02 -1.19292865e-01
  2.23627375e-01 -5.87523253e-02 -5.46213416e-02  9.72009543e-02
 -2.95295836e-02  1.37106091e-02  1.21661828e-01 -5.70981526e-03
  1.13067494e-01  8.21005927e-03 -2.59489411e-01 -1.24589748e-02
 -8.75838860e-02  1.95761084e-01 -4.71506768e-02 -1.97051823e-01]
it does something
Int64Index([431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443,
            444, 445, 446, 447, 448, 449, 450, 451, 452, 453],
           dtype='int64')
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=2324)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-1.22809458e+01  3.17385944e+00  2.33719157e+00  6.90348621e-01
  4.93664434e-01 -2.89129864e-01  8.84087124e-01  1.10667760e+00
 -3.26815649e-01  1.26770517e-01 -2.31245189e-01  8.04520484e-02
 -2.67356479e-01 -2.95191520e-01 -1.01160795e-02  1.61435507e-02
  6.51294859e-02  1.26105662e-01 -3.83511190e-01 -7.72154270e-02
 -1.97125150e-01  3.46216439e-02 -1.54466355e-02  1.40963718e-01
  1.02001030e-01 -1.81992617e-02  1.85343037e-01  7.69292731e-02
 -6.06922058e-02  2.49428650e-02  5.02343188e-02  1.19476245e-01
 -9.87638373e-02  8.15888200e-02 -4.16846995e-02  1.78609660e-01
  1.56718698e-01 -5.88479702e-02  1.77350628e-02  6.66596556e-02
 -1.59889071e-01 -1.29652785e-01  1.07305287e-01 -1.42598655e-01
  3.39153477e-01  4.80169906e-02 -1.25229369e-02 -3.75670952e-02
 -1.76780250e-01 -1.02220416e-01 -1.09751295e-01  5.30107000e-02
  1.38338899e-02  4.38846370e-02  3.59891832e-03 -1.29955822e-01
 -8.55237595e-02  1.69652637e-01  1.18093563e-03 -1.42196147e-02
  1.11345065e-01  2.00862173e-02 -4.11369346e-02  9.25829630e-02
 -6.87370216e-02  1.40295886e-01 -1.48702548e-02 -1.57298161e-01
  2.05831536e-02 -7.52620796e-02 -1.89780655e-01  5.94819916e-02
  6.72752142e-02  8.03702062e-03 -4.68195361e-02 -8.35681337e-02
  1.27027949e-01  7.73084830e-04  8.18890604e-03 -1.17309987e-01
 -6.46987479e-02  4.60150764e-02 -2.23472709e-03 -4.14781983e-02
  3.05273379e-03 -2.18711589e-02  1.33079787e-01 -3.64281280e-02
  8.91982869e-02 -6.78752175e-02  6.72200351e-02 -7.26491897e-03
 -6.15646212e-03 -2.20053819e-02  2.51416634e-02 -5.98677551e-02
 -1.27981607e-01 -1.90938210e-02  9.18986354e-02 -7.26651378e-02
  2.32574847e-02 -1.20937914e-01 -4.27365122e-02  3.05402958e-02
  4.98329389e-02  2.83498222e-02 -2.52559554e-02 -4.70213746e-02
 -9.23442318e-02 -3.22943898e-02 -2.22688932e-03 -1.13586864e-01
  1.04128149e-01  1.24319333e-01  1.26168014e-01  1.79119290e-02
 -1.37518228e-02 -6.93716526e-02 -1.06328230e-01  4.56626909e-02
 -1.20789415e-01  1.53044522e-01 -6.23536515e-02 -2.12151784e-02
  2.53740713e-02 -2.42596582e-02 -5.57689668e-02  8.47282367e-02
 -1.10865661e-02 -1.47293212e-01  8.74883983e-02 -3.11729969e-02
  3.86010141e-02 -3.33558106e-02  1.89940437e-02  1.32888595e-03
 -1.35848351e-01 -9.80978111e-03  1.15391724e-01 -4.79494305e-03
 -3.35774743e-02  2.74635269e-02 -4.57969487e-02 -3.30303887e-03
  7.24582569e-02 -2.57837500e-01 -5.65879201e-02  1.08813101e-02
  8.59802418e-03  1.90576677e-02  6.53996607e-02 -8.65027704e-02
  4.31230018e-02  3.70401592e-02 -1.30127914e-01 -8.81811310e-03
  2.37667998e-02 -4.18410163e-02 -5.39163690e-02 -2.42387720e-02
 -3.44024538e-02  1.67724626e-02  3.88166696e-03  9.08200943e-02
 -4.80357645e-02 -7.57803421e-03  1.11404026e-01  5.21331032e-02
 -1.90938545e-02  6.33891249e-02  1.38762701e-01 -1.42187349e-01
  1.82468518e-01 -7.90805861e-02 -3.06513155e-02 -5.81389872e-02
  1.07917898e-01 -2.94277196e-02 -8.46152765e-04 -3.24454801e-02
 -6.13588531e-02 -2.12168704e-02  1.12876324e-02 -1.74656385e-03
  1.55369246e-01  1.26805154e-01  2.18723110e-01 -8.53423684e-02
  1.17594705e-01  1.97218892e-02  2.80830217e-02  1.55623713e-01
  1.96125908e-02 -1.14290579e-01  4.28332009e-02  3.47143340e-02
 -4.09526471e-02 -7.93478707e-02  1.02991287e-01  3.23226657e-02]
it does something
Int64Index([ 762,  763,  764,  765,  766,  767,  768,  769,  770,  771,
            ...
            1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259],
           dtype='int64', length=498)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1849)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-9.32380247e+00  2.62370434e+00  1.02505614e+00  7.14005817e-01
 -2.31364744e+00  1.03067846e+00  6.11735012e-01  7.26586575e-01
 -3.20679106e-01  2.59143652e-01 -5.55078614e-01  1.69914136e-01
 -3.96256481e-01 -9.40180234e-02 -8.99879688e-01  6.45018263e-01
  8.81037665e-01 -1.57639606e-01 -4.12219692e-01  7.58751495e-01
  1.92215233e-02  8.17348539e-01 -8.51420428e-01  1.74932642e-01
  2.50509898e-01  4.33424995e-01  2.35536073e-01  6.97739705e-01
 -3.07793557e-01  4.44940367e-01  9.11408187e-02  5.32877821e-01
 -1.72644561e-01 -8.70986549e-02 -2.75561609e-01  6.52826834e-01
  4.97257103e-01 -1.89669252e-01 -5.51096058e-01  2.93884154e-02
  7.62697622e-01  1.48352741e-01  2.86635297e-02  7.63517896e-01
 -8.31720207e-01  3.11158973e-01  2.60819316e-01  5.25791562e-01
  2.10557530e-01  6.49483775e-03  1.80106949e-02  2.81255326e-01
  2.57250475e-01 -9.42526617e-01  3.08486817e-01 -2.51456882e-01
 -1.66390927e-02  2.57038602e-01 -2.41274694e-01 -4.77640974e-01
 -2.88238812e-01  1.90927757e-01 -8.29858742e-01 -1.90002193e-01
  2.75545410e-01 -5.00136310e-01  1.53113586e-01  7.32277559e-01
  3.56907596e-01 -3.09047040e-01  1.88158210e-01 -1.96016042e-01
  7.21452233e-02  9.59639290e-01  3.87405706e-02  2.81083060e-01
  2.64303587e-01 -1.42086253e-01 -5.37391761e-01 -2.55998227e-01
  3.71120001e-01  1.43395873e-01 -1.30622590e-01  1.32086112e-01
 -2.17444782e-02 -2.54437946e-03 -1.52463834e-01  9.41982735e-02
  1.67563116e-01 -5.72849932e-02  3.73363247e-01  1.89950798e-01
  1.19319511e-01  3.05828953e-01 -4.15441352e-04  2.24760395e-01
  9.41795615e-02 -5.64559686e-01  2.12621482e-01 -7.77664901e-02
  1.38215055e-01  3.02786139e-01  2.88379990e-01 -4.39275384e-01
 -3.12505145e-01  2.52768447e-01 -3.27190567e-02  4.72240687e-01
  3.09760532e-01 -4.55143224e-01  3.54294108e-01  1.77883777e-01
  2.13693703e-01  2.63086635e-01  6.57019423e-01  1.27228197e-02
 -1.07618939e-02 -3.13377172e-01 -1.60938842e-01  3.11990400e-01
  2.11065351e-01 -2.37212333e-01  4.36215776e-02  1.96488328e-01
  5.73827949e-01  3.61579280e-01 -1.16941555e-04  2.28368719e-01
 -1.52562349e-01  1.78592207e-01 -1.71672527e-02  3.91309106e-01
 -1.85320656e-01 -4.39384389e-01 -5.28752670e-01  2.06871820e-01
 -4.98097418e-01  1.01006643e-01 -9.09793642e-02  3.30664292e-01
 -3.35017116e-01  4.57578515e-01 -1.85038823e-02  3.74255421e-01
  2.18131586e-01 -4.26945798e-01  2.58806751e-01 -1.90234795e-01
  2.01294484e-01  5.18736958e-01  5.53902402e-02  4.65141514e-02
  5.65763436e-02 -7.95953258e-02  6.24035655e-04  1.08124117e-01
  1.79479876e-01 -3.02937195e-02  2.16940757e-01 -4.29306116e-02
 -1.10382709e-01  2.16756660e-01 -3.89477472e-01  2.17804775e-01
 -1.46084495e-01 -3.50956512e-01  2.01669344e-02  4.53762365e-02
 -6.10756775e-02  1.93106493e-01 -1.88766125e-02  4.21940635e-02
 -2.43822215e-02  7.00533029e-02 -2.67378423e-01 -6.62202435e-02
  4.83262480e-02 -2.25681839e-01  1.05803742e-01  5.62633439e-01
 -1.63268837e-01 -5.24184650e-02  3.10306311e-02 -9.67263692e-02
  5.62240793e-01  1.00911277e-01 -6.34734491e-02  5.25637659e-02
 -2.43382763e-01  2.32549649e-01 -3.43156606e-01 -3.67358700e-01
  2.08057958e-01 -4.18341322e-01 -2.89647194e-02  2.50031326e-01
  1.13311898e-01 -1.31689748e-01  7.73715702e-02 -4.89502553e-01]
it does something
Int64Index([ 762,  763,  764,  765,  766,  767,  768,  769,  770,  771,
            ...
            1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259],
           dtype='int64', length=498)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1849)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-9.71644787e+00  1.41220231e+00  2.77276167e-01  1.92093039e+00
  1.54788901e+00 -2.09797594e+00  5.08728855e-01  4.00880278e-01
  3.87555775e-01 -1.82384693e-01 -8.41948597e-01  4.04721259e-01
  2.25498556e-01 -3.73273135e-01 -3.01088993e-01 -6.88403272e-01
 -8.16572387e-01  8.38997835e-01  1.74247526e-01  6.35864610e-02
 -1.08604690e-01 -8.76087848e-02  2.30515113e-02  9.07871354e-01
  6.59370498e-01 -2.04834186e-01 -6.22380067e-01 -1.79594963e-01
 -5.10922131e-01 -1.74620451e-01  2.34235113e-01  2.44334051e-01
  1.83732756e-01  1.82429623e-01 -6.83406865e-01 -4.61067353e-01
 -1.95704297e-02  4.13657567e-01 -8.57448377e-02 -8.10118437e-03
  6.46965359e-01 -2.61208048e-01 -1.85993629e-01 -6.48710296e-01
 -9.45710571e-01 -2.37524763e-01  1.31051211e+00  7.22941198e-01
 -6.10086170e-01 -2.96028594e-01 -1.38463914e-01  2.80358002e-01
 -1.16066452e-01  5.02943874e-01 -1.71955645e-01  1.87283364e-01
  6.95283176e-02  9.55409175e-01 -1.82121083e-01  3.50235135e-02
  4.48676779e-02 -5.83727957e-01 -5.88017505e-01  1.76767020e-01
  2.55778062e-02  6.21914994e-02 -2.38393595e-01 -7.55845637e-01
 -1.64019738e-01  1.48042552e-02  9.80547137e-02  3.06405755e-01
 -2.90458301e-01 -1.20672604e-01 -9.40077922e-02 -4.30215565e-01
  2.23965408e-02 -8.49226652e-02  6.37801491e-02  4.85100896e-01
 -9.78436861e-02  2.10211247e-01 -1.26264263e-01  2.61976002e-01
 -3.99005006e-01 -5.87367687e-01  4.09084018e-01  2.49428539e-01
 -3.53462935e-01  2.25335933e-01 -1.59367409e-01 -2.78933280e-01
 -2.45695995e-01 -2.60301052e-02 -2.74600780e-01  3.32026971e-01
 -4.49721049e-01  4.20113448e-01 -9.13718494e-02 -1.89615106e-01
  2.71736802e-02  1.38456670e-02 -1.11826436e-01  5.41541014e-02
 -4.41362976e-01  7.78216584e-01 -5.16377940e-02  1.14236425e-01
  4.03630962e-01  5.45899057e-02  1.52510131e-01 -1.00169263e-01
  2.21200755e-01 -6.63694109e-02  1.93380689e-01  1.33734612e-01
  1.56916898e-01  1.26848458e-02 -1.58854599e-02 -3.61475939e-01
 -3.99193258e-01  1.98475527e-01  3.73285680e-01 -1.77096315e-01
 -3.52985412e-01 -1.66072887e-01  4.90748107e-02 -5.68395148e-02
  5.73356708e-01 -1.87825218e-02 -1.85114083e-01  3.82079619e-01
  3.51966819e-02  2.27062425e-01  5.55357752e-01  4.21383197e-02
  2.95696127e-01 -2.12585749e-01  4.41323172e-01  1.70311711e-01
  6.73163482e-01 -1.22542013e-01 -1.64802031e-01 -5.92490860e-03
 -2.19580209e-01 -4.44411154e-01 -1.88687546e-01  1.54631806e-01
 -1.38149253e-02  2.11424686e-01 -3.22806468e-01 -2.78107518e-03
  1.95083581e-01 -1.16622661e-01  1.12823778e-01  6.91978252e-02
  1.37265968e-02 -1.99829235e-01 -1.13452508e-01  2.14859082e-01
  8.55684993e-02 -9.39984647e-02  1.42910652e-01 -1.68311807e-01
 -3.33904189e-02 -1.80363195e-02 -8.55797593e-02 -6.39892102e-02
  6.83786958e-02  4.68045743e-02 -2.49380621e-01 -1.88599701e-01
 -6.72669815e-02  4.78369743e-01 -4.37728763e-02 -2.30681290e-01
 -1.39140724e-01  6.17726505e-01 -1.55877584e-01  1.84602197e-01
  7.70070340e-02 -2.02534564e-02 -2.86352909e-01  1.22531937e-01
 -5.22888072e-02  1.60874838e-01 -4.25671498e-01  2.26132232e-01
 -1.44121698e-01 -2.41952520e-01 -2.92328234e-04  3.13468164e-01
  4.70199497e-02  1.91790351e-01 -8.75218089e-02  5.19303953e-02
 -1.25426312e-01  8.39345450e-03 -1.23950067e-01 -8.83194787e-02]
it does something
Int64Index([1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724,
            ...
            2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320],
           dtype='int64', length=606)
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346],
           dtype='int64', length=1741)
            2         3          4    ...       199       200       201
0     12.569812  7.116670   0.672104  ...  1.044004  0.414233 -1.305085
1    -10.287848  3.004242   1.850065  ... -0.120575  0.003828  0.008953
2    -12.165009  3.170589   2.169987  ... -0.043131  0.159112 -0.108517
3     33.162786  3.473576 -10.436043  ... -0.307094 -0.149677  0.318996
4    -12.175201  3.176557   2.190085  ... -0.021838  0.119506 -0.097123
...         ...       ...        ...  ...       ...       ...       ...
2342  -9.629141  2.435916   1.131983  ...  0.038196  0.201126  0.018585
2343  -9.029024  2.322203   1.036373  ...  0.069299  0.140847 -0.209329
2344  -8.855967  3.062206   1.082282  ... -0.007930  0.125075  0.001855
2345 -10.706339  2.925712   2.382563  ... -0.054549  0.022303 -0.044119
2346  11.300004 -4.142375  -5.703444  ... -0.681583 -0.174028 -0.134946

[2347 rows x 200 columns]
[-9.49274363e+00  2.05927439e+00  1.11904009e+00  1.31481734e+00
 -1.49569098e+00 -3.66809041e-01  9.08802916e-01  8.37772430e-01
  4.40350711e-01 -8.15810054e-02  1.00823924e+00 -1.48433740e+00
  7.59872838e-01  7.33041820e-01  5.27006267e-01  1.04045390e+00
  3.06434828e-01 -1.34455331e+00 -3.40683828e-01 -6.07868903e-01
  7.29256151e-01 -9.33652332e-01  4.88329114e-01  5.39799978e-01
  1.75270960e+00 -8.49464203e-01  7.64992775e-01 -2.95782543e-01
 -9.49537490e-01 -6.60058716e-01  7.57249395e-01  9.17699067e-01
  3.56608445e-01 -3.42081312e-01  2.57879227e-01 -7.63119159e-01
 -1.89254136e-01  5.33218679e-01  4.49118965e-01 -4.43788984e-01
 -9.42782392e-03 -2.84180884e-01  6.31968940e-01  3.31819022e-01
 -6.76508444e-01 -4.53496316e-01  7.01418793e-02 -9.96430278e-02
 -8.42678661e-01  3.71980054e-01 -6.82557567e-02 -9.50158427e-01
 -4.12989091e-01 -2.42059559e-01 -4.74338625e-01 -5.04921965e-01
 -1.57587374e-01  4.29289299e-01 -2.27617127e-01  2.02101


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Train and test a model on features.")
    parser.add_argument("featurefile", type=str, help="The file containing the table of instances and features.")
    parser.add_argument("samplesize", type = int, help="The number of text pairs used to train the FFNN.")
    # Add options here for part 3 -- hidden layer and nonlinearity,
    # and any other options you may think you want/need.  Document
    # everything.
    
    args = parser.parse_args()

    print("Reading {}...".format(args.featurefile))
    data = pd.read_csv(args.featurefile, header = None)
    train = data[data[0] == "train"]
    train.reset_index(inplace=True, drop=True)
    test = data[data[0] == "test"]
    train.reset_index(inplace=True, drop=True)

    ffnn = AuthorFFNN()
    ffnn.train(train, args.samplesize)

    # implement everything you need here
    

